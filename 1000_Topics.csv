Title,Score,Id,Url,Comment_Num,Created,Body,timestamp
Would this be a good idea for a StyleGAN dataset (cartoon/cartoonish anime characters)?,10,figdjf,https://i.redd.it/83fajcab8mm41.png,2,1584210728.0,,2020-03-15 00:02:08
Preprocessing Video to Feed into CNN?,4,ficp9h,https://www.reddit.com/r/MLQuestions/comments/ficp9h/preprocessing_video_to_feed_into_cnn/,1,1584187357.0,"I've trained a number of CNNs using labeled images for classifiers and whatnot. This time I have videos with annotations labeling every second of video. I've never used a video for this task before. Is the gist of it that I just need to preprocess by effectively slicing the video up into individual images and just use those images, or is there some other trick to this in order to use the video directly? The annotations are basically one line in my csv per second of video. Thanks for the help!",2020-03-14 17:32:37
How would you preprocess features like these?,2,fic8hz,https://www.reddit.com/r/MLQuestions/comments/fic8hz/how_would_you_preprocess_features_like_these/,2,1584185068.0,"Any ideas or important steps to take given the number of zeros, imbalance or distribution will help.

https://preview.redd.it/i2iftdahwjm41.png?width=1374&format=png&auto=webp&s=3e35c783c22607055b829ddf7294e1767bf9ed9e

https://preview.redd.it/8hgdl2nhwjm41.png?width=1378&format=png&auto=webp&s=6a070dd6bb586a1c322dbe42f58e69084f31452e

https://preview.redd.it/l8siw64iwjm41.png?width=1416&format=png&auto=webp&s=bf19eba9a8e885e404aed77bff73ec72b9d93a58

https://preview.redd.it/ygdzk2hiwjm41.png?width=1416&format=png&auto=webp&s=e00ed682b7b239c6f66464b5cda87f9d88a77fb5",2020-03-14 16:54:28
"Discard pooling layers during inference, but use them to train.",16,fi1dyh,https://www.reddit.com/r/MLQuestions/comments/fi1dyh/discard_pooling_layers_during_inference_but_use/,1,1584142107.0,"Hi fellows,

I want to detect a sequence of digits in more or less realtime from a video stream. For that I defined my own network, without any flatten or dense layer.

    def create_model_new(input_shape, num_classes, training = True):
    
        model = Sequential()
        # conv 1
        model.add(Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu', padding='same', name='conv1', input_shape=input_shape))
        model.add(BatchNormalization()) #(epsilon=1e-06, mode=0, momentum=0.9, weights=None)
        model.add(LeakyReLU(alpha=0.1))
        model.add(MaxPooling2D((2, 2), padding='same'))
        # conv 2
        model.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='same', name='conv2'))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=0.1))
        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
        # conv 3
        model.add(Conv2D(128, (3, 3), strides=1, activation='relu', padding='same', name='conv3'))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=0.1))                  
        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
        # conv 4
        model.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='same', name='conv4'))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=0.1))                  
        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
        # conv 5
        model.add(Conv2D(num_classes, (2, 2), strides=1, activation='sigmoid', padding='valid', name='conv5'))
    
        model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False),metrics=['accuracy'])
        
        model.summary()
            
        return model

I trained with MNIST 28x28px images, the inference should be with a much bigger resolution. Like 1080x1920 or maybe 720x1280. So I just initialized my placeholders for the training with None, to feed a bigger image during inference. To illustrate the inference and training shapes, I just give you the summary() for my input shapes, but remember I train it with (None,None,1)!

    For Inference:
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv1 (Conv2D)               (None, 1920, 1080, 32)    320       
    _________________________________________________________________
    batch_normalization_243 (Bat (None, 1920, 1080, 32)    128       
    _________________________________________________________________
    leaky_re_lu_243 (LeakyReLU)  (None, 1920, 1080, 32)    0         
    _________________________________________________________________
    max_pooling2d_237 (MaxPoolin (None, 960, 540, 32)      0         
    _________________________________________________________________
    conv2 (Conv2D)               (None, 960, 540, 64)      18496     
    _________________________________________________________________
    batch_normalization_244 (Bat (None, 960, 540, 64)      256       
    _________________________________________________________________
    leaky_re_lu_244 (LeakyReLU)  (None, 960, 540, 64)      0         
    _________________________________________________________________
    max_pooling2d_238 (MaxPoolin (None, 480, 270, 64)      0         
    _________________________________________________________________
    conv3 (Conv2D)               (None, 480, 270, 128)     73856     
    _________________________________________________________________
    batch_normalization_245 (Bat (None, 480, 270, 128)     512       
    _________________________________________________________________
    leaky_re_lu_245 (LeakyReLU)  (None, 480, 270, 128)     0         
    _________________________________________________________________
    max_pooling2d_239 (MaxPoolin (None, 240, 135, 128)     0         
    _________________________________________________________________
    conv4 (Conv2D)               (None, 240, 135, 64)      73792     
    _________________________________________________________________
    batch_normalization_246 (Bat (None, 240, 135, 64)      256       
    _________________________________________________________________
    leaky_re_lu_246 (LeakyReLU)  (None, 240, 135, 64)      0         
    _________________________________________________________________
    max_pooling2d_240 (MaxPoolin (None, 120, 68, 64)       0         
    _________________________________________________________________
    conv5 (Conv2D)               (None, 119, 67, 10)       2570      
    =================================================================
    Total params: 170,186
    Trainable params: 169,610
    Non-trainable params: 576
    _________________________________________________________________
    For training:
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv1 (Conv2D)               (None, 28, 28, 32)        320       
    _________________________________________________________________
    batch_normalization_247 (Bat (None, 28, 28, 32)        128       
    _________________________________________________________________
    leaky_re_lu_247 (LeakyReLU)  (None, 28, 28, 32)        0         
    _________________________________________________________________
    max_pooling2d_241 (MaxPoolin (None, 14, 14, 32)        0         
    _________________________________________________________________
    conv2 (Conv2D)               (None, 14, 14, 64)        18496     
    _________________________________________________________________
    batch_normalization_248 (Bat (None, 14, 14, 64)        256       
    _________________________________________________________________
    leaky_re_lu_248 (LeakyReLU)  (None, 14, 14, 64)        0         
    _________________________________________________________________
    max_pooling2d_242 (MaxPoolin (None, 7, 7, 64)          0         
    _________________________________________________________________
    conv3 (Conv2D)               (None, 7, 7, 128)         73856     
    _________________________________________________________________
    batch_normalization_249 (Bat (None, 7, 7, 128)         512       
    _________________________________________________________________
    leaky_re_lu_249 (LeakyReLU)  (None, 7, 7, 128)         0         
    _________________________________________________________________
    max_pooling2d_243 (MaxPoolin (None, 4, 4, 128)         0         
    _________________________________________________________________
    conv4 (Conv2D)               (None, 4, 4, 64)          73792     
    _________________________________________________________________
    batch_normalization_250 (Bat (None, 4, 4, 64)          256       
    _________________________________________________________________
    leaky_re_lu_250 (LeakyReLU)  (None, 4, 4, 64)          0         
    _________________________________________________________________
    max_pooling2d_244 (MaxPoolin (None, 2, 2, 64)          0         
    _________________________________________________________________
    conv5 (Conv2D)               (None, 1, 1, 10)          2570      
    =================================================================
    Total params: 170,186
    Trainable params: 169,610
    Non-trainable params: 576
    _________________________________________________________________

So my output for a FullHD image is 67x119x11. I also added a image pyramid to detect sequences at different scales. For now my detection results are not that good.

[convolved result image](https://preview.redd.it/6zk9omzijgm41.png?width=1920&format=png&auto=webp&s=3e64183e5cb639aec5e04e2ea80019d1c313ca7a)

I also implemented a sliding window approach, for validation of my network, it works good and detects all digits in the image. What should be the case after a test validation score of 99.2%. To detect the background I just added a 11th class, it consists of 30000 CIFAR-10 images, so 5 times the number of images for the rest of the classes.

[sliding window result image](https://preview.redd.it/sns7yhqnjgm41.png?width=1920&format=png&auto=webp&s=51474913f5c7b9441a7adcae40ad5c4ec0d3756d)

**So I asked myself, whether I can discard all pooling layers during inference, but keep them during training? (to still receive 1x1x11 during training) How can I load the model discarding all pool layers?**

Thank you very much for your time and input.",2020-03-14 04:58:27
Voice imitation in singing using AI,6,fi179e,https://www.reddit.com/r/MLQuestions/comments/fi179e/voice_imitation_in_singing_using_ai/,3,1584141410.0,"Im a music producer by profession with a university level programming expirience. 

I have an idea on creating a software to manipulate audio waveforms, specifically of human voices and use AI to make it sound like another person or tweak it and so on.

Such tools are already in development from what ive seen but not so much in singing/music context.

Now my question is, how doable is this for me ?
Logically i actually understand whats happening, how voice timbre works, how pitch works, how vowels works, how harmonic distribution plays a role. 

But to translate this into some form of ai based programming, i have 0 clue.

I see resources and they say to learn linear algebra and probability and Calculus first.

While i have studied them in my degree, i would hardly say im any good at them besides 'clearing those courses'

And i dont know how much of that is usefull to my problem, or i would just end up using some library that wont require me to go bottom up

Im having an awfull time deciding where to jumpstart in this.

Google search related to ML is saturated and i dont know what tools/methods should i use to approach my specific problem related to audio

Is this even doable at all?

Any guidance would be greatly appreciated.",2020-03-14 04:46:50
question: using f1 score,2,fi5dm8,https://www.reddit.com/r/MLQuestions/comments/fi5dm8/question_using_f1_score/,2,1584156921.0,"can someone explain what the f1 score is computing/checking here

     f1_score(identical, distances < t) 

i think its looking at ""identical"" cases with distances less than the threshold value, then its computing the f1 score based on those two values (1. identical 2. distances < t",2020-03-14 09:05:21
What am I doing wrong here: calculating partial derivative of Cost with respect to activated neuron1,3,fi33au,https://www.reddit.com/r/MLQuestions/comments/fi33au/what_am_i_doing_wrong_here_calculating_partial/,1,1584148460.0,"I have a perceptron with only one hidden layer. The input, hidden and output layers all have two neurons each.
 
____________


Considering the first neuron in the hidden layer: When computing the partial derivatives during back propagation, how can you calculate the partial derivative of cost with respect to the activation value of this neuron? 


Cost function explicitly depends on the activated values of the two neurons in the output layer (a3, a4), but only implicitly to a1 and a2 (activated values of two neurons in hidden layer)
 
____________


Note: weighted sum = denoted as z
 
activated value(a): value of z after applying sigmoid function
 
__________


Please see drawing here:


https://imgur.com/qE1IUHM



...and advise if we need to denote a3 and a4 in terms of a1 and a2 for the partial derivatives.",2020-03-14 06:44:20
Interpretations of Matting Laplacian Use in Deep Style Transfer,2,fi50k5,/r/computervision/comments/fg994c/interpretations_of_matting_laplacian_use_in_deep/,0,1584155571.0,,2020-03-14 08:42:51
Help Needed- Image Labeling Bounty (compensation available),2,fi4cum,https://www.reddit.com/r/MLQuestions/comments/fi4cum/help_needed_image_labeling_bounty_compensation/,0,1584153154.0,"&#x200B;

https://preview.redd.it/twh08xvhhhm41.png?width=740&format=png&auto=webp&s=0550645ab257fe197ef266c130aca58e8563cc9d

Greetings! We are offering the opportunity for AI, Machine Learning, and Data Science enthusiasts and professionals to join our image tagging bounty. It is completely free to join, and you can earn compensation (paid in cryptocurrency) for completing the bounty. No previous technical experience is required.  

For this challenge, we are asking the community to appropriately classify a simple image based on what you see within the image. Each image will only a few seconds to complete, and the entire bounty can be completed within a few hours.  You will simply draw a box around the object pictured in the image, and then select from a drop down menu what you see in the image. We would love it if you joined us!  

**Your time is valuable, and that's why we're giving 15,000 KAT to every participant who successfully completes the bounty.**  

**🤖Bounty Details**

👉Registration begins: 7:30 PM UTC+7, March 13th, 2020 

👉Registration closes: 11:59 PM UTC+7 March 27th, 2020 

👉Labeling Period Begins: 00:00 AM UTC+7, March 28th, 2020

👉Labeling Period Deadline: 11:59 PM UTC+7, April 12th, 2020  

&#x200B;

✍️To sign up, visit the official bounty page by visiting  [https://app.kambria.io/bounty/5e68936c54c01e8af7952989](https://app.kambria.io/bounty/5e68936c54c01e8af7952989) 

If you would like to participate in this bounty, please register and sign up at your earliest convenience. **Spots are limited, so do not wait!**",2020-03-14 08:02:34
[Q] YOLOv3 & OpenCV dnn Error,2,fi2z2l,https://www.reddit.com/r/MLQuestions/comments/fi2z2l/q_yolov3_opencv_dnn_error/,0,1584148028.0,"Hey Y'all

Having trouble with loading tiny YOLOv3 into OpenCV's DNN?

Following [this tutorial](https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/) trained on my own dataset from the following line

    layerOutputs = net.forward(ln)

I get the following errror:

    cv2.error: OpenCV(3.4.2) /io/opencv/modules/dnn/src/layers/concat_layer.cpp:94: error: (-201:Incorrect size of input array) Inconsistent shape for ConcatLayer in function 'getMemoryShapes'

I think it has something specific to do with YOLOv3 & perhaps that I'm using tiny yolo?

Any help would be greatly appreciated! Thank you!

&#x200B;

**Edit:** After fooling around I tried it with full YOLO & coco weights & it worked - I suspect something is wrong with my cfg file then?  Here's [the cfg file](https://pastebin.com/QEeE032R) if you think it may be the problem. Curiously when testing the real Darknet (./darknet in terminal) it runs runs perfectly fine? 

&#x200B;

Thank you for your help!",2020-03-14 06:37:08
Adding new data to model,1,fi5gf8,https://www.reddit.com/r/MLQuestions/comments/fi5gf8/adding_new_data_to_model/,0,1584157212.0,"Hello

 
My question is this- How do I run this simple SVM model on new data?

 

The new data will not have the target column ""sb"", so how can I tell it to try and predict that value if its not in the new data set?

 

 

The new data will be gathered directly form the database but without this target column.

 

I already have the model saved using Pickle but when I call the model, it expects the data to have the same number of rows, when dealing with transaction data, the amount of customers will change, so WTF?

 

Thanks in advance!

 

My code:

 

df=pd.read_csv(""c:/users/myusername/desktop/test2.csv"")

 

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df, df.sb, test_size=0.3,random_state=109) # 70% training and 30% test

 

clf = svm.SVC(kernel='linear') # Linear Kernel

 

#Train the model using the training sets

clf.fit(X_train, y_train)

 

#Predict the response for test dataset

y_pred = clf.predict(X_test)

from sklearn import metrics

 

# Model Accuracy: how often is the classifier correct?

print(""Accuracy:"",metrics.accuracy_score(y_test, y_pred))

 

#Accuracy: 1.0

print(""Precision:"",metrics.precision_score(y_test, y_pred))

 

#Precision: 1.0

print(""Recall:"",metrics.recall_score(y_test, y_pred))

 

#Recall: 1.0

The data Just has a few columns, ID, sales, trans, trans during spring, summer ect., age",2020-03-14 09:10:12
I want to do some material science related project....use if some ml and this is the best place to get some ideas.,0,fi8q1i,https://www.reddit.com/r/MLQuestions/comments/fi8q1i/i_want_to_do_some_material_science_related/,0,1584169610.0,Of*,2020-03-14 12:36:50
When is the dataset too small?,10,fhvdev,https://www.reddit.com/r/MLQuestions/comments/fhvdev/when_is_the_dataset_too_small/,16,1584110039.0,"Hello,

I have a dataset of around 46 observations and 26 features. I would like to ask, is it too small to use models like random forest or xgboost? When is the dataset too small in general?",2020-03-13 20:03:59
Question on Autoencoders for anomaly detection,2,fhxuid,https://www.reddit.com/r/MLQuestions/comments/fhxuid/question_on_autoencoders_for_anomaly_detection/,4,1584125964.0,"Autoencoders are sometimes used for anomaly detection. Two methods used are loss difference (taking the reconstruction error and using that to determine if it is an anomaly, which I understand) and latent space clustering methods, which I do not understand.

In latent space clustering, you train the AE on the inlier data only, then train some second model on the **latent representations** of the outliers vs the latent representations of the standard data, which theoretically should be different and easy to classify, even with some linear model. My question for this is, why would this work, and is this a reliable technique? 

When encoding some signal (lets say we're working with images of peoples' faces, and the outlier pictures have some yellow dot in the background), the best encoding format would learn the variations of the features of just the inlier data - so for this example it would encode things like skin tone, eye location, etc. of just the regular faces. If we are learning just the variations in the inlier data, isn't there no real reason for the latent space of the outliers to be any different than the latent space of the inliers, since the varying factors of the outliers are not learned at all? Essentially what I can't wrap my head around is that the factor that makes a signal an outlier does not have to be a varying factor in the inlier group, and thus there doesn't really need to be a reason to learn it at all. 

This is actually the reason that loss difference methods work, where the AE learns the structure of the inlier data and fails to reconstruct some outlier properly, and when the reconstruction error spikes, one can properly conclude that there is an outlier.

Even if the outlier factor has something to do with a learned inlier feature (example, large eyes taking up 50% of head in outlier group vs inliers being regular headshots), isn't there still no real reason the latent space should be any different? The sub-signal that makes the entire signal (lets say sub-image of an image) an outlier still just gets thrown through the standard calculation for an inlier signal, and can output as whatever - there is no reason the latent representation specifically has to be distinct from the inlier representation for this, especially when it hasn't trained on this trait before. It can just ""fold"" this over the inlier manifold and project as just a regular point just fine. How come I see these methods come around sometimes? Thanks for the help.",2020-03-14 00:29:24
Deep learning guided image-based droplet sorting for on-demand selection and analysis of single cells and 3D cell cultures,2,fhwyr3,https://www.reddit.com/r/MLQuestions/comments/fhwyr3/deep_learning_guided_imagebased_droplet_sorting/,5,1584120655.0,"3 points to keep: 

• Real-time cell classification. 

• Spheroid enrichment. 

• Machinelearning for sorting objects with different morphologies",2020-03-13 23:00:55
What are AI Engineer’s Job Responsibilities?,1,fhz9ye,https://www.artiba.org/blog/the-artificial-intelligence-engineer-career-roadmap-all-you-need-to-know,1,1584133257.0,,2020-03-14 02:30:57
What are some of the challenges you face when solving real-world computer vision problems?,5,fhrps8,https://www.reddit.com/r/MLQuestions/comments/fhrps8/what_are_some_of_the_challenges_you_face_when/,4,1584091997.0," 

Engineers/Researchers who work on computer vision tasks that run inference on real-world data (e.g. images from a user's mobile phone) - what are some of the challenges you currently face?

Here's a poll to make things easier (I'll share the results here later).  
[https://forms.gle/aCeRY7eojU3AGTx8A](https://forms.gle/aCeRY7eojU3AGTx8A)

Also, feel free to start a discussion below if you want feedback/solutions.",2020-03-13 15:03:17
Implementation of attention for sequence-based prediction,1,fhxrwe,https://www.reddit.com/r/MLQuestions/comments/fhxrwe/implementation_of_attention_for_sequencebased/,4,1584125555.0,"Hello MLQuestions

I am trying to implement the architecture found in [this paper](https://dl.acm.org/doi/abs/10.1145/3240323.3240397?casa_token=IeI4hOjHbwYAAAAA:fAqxpPagGkGj8zYXUGvp-TX0kcevN1jLT72SsqfwinNCa0fxyc6SfJQVNDqGsMVOyeO4rPliFQQvXQ) for music sequence based recommendation. The architecture takes as input a sequence of songs and their tags and predicts the next song in the sequence. The structure is seemingly straightforward with embeddings of songs and tags going through the following flow:

embedding > Bi-GRU > attention layer

Context vectors produced by the attention layer for songs and tags are then concatenated before going through the rest of the architecture. My question is regarding how the attention layer should be implemented. The authors explain that the inputs (H\_i) for the attention layer is the concatenations of the unidirectional hidden states of the Bi-GRU, and that the attention layer outputs a context vector as a weighted sum of the inputs:

sum\_i(α\_i\*H\_i)

My question is: How should the weights (α) for the hidden states be defined? I have seen plenty of examples of attention implementations in seq2seq models using an encoder-decoder structure, where the state of the decoder is also used as input for the attention layer. However this architecture must obviously be different as there is no decoder involved. However, I have not had much success in finding examples of attention layer implementations without a decoder.

Based on my understanding of how attention is applied, my best guess is that the weights should be implemented using a tanh activated shallow neural network with only the concatenated hidden states as input:

tanh(W\*H\_i+b)

the output is then passed through a softmax to get the weights for the attention layer. Does this seem somewhat correct? Any help would be greatly appreciated.",2020-03-14 00:22:35
What should I do? Should I pursue my masters here?,1,fhxhmh,https://www.reddit.com/r/MLQuestions/comments/fhxhmh/what_should_i_do_should_i_pursue_my_masters_here/,11,1584123882.0,"So I am working as a research assistant in some lab. Here professor always avoids having a meeting and whenever I ask anything about the topic he avoids it or says something wrong because he doesn't know the topic well. And in my lab not a single guy is good at what they are doing and on top of that they are unwilling to even discuss if I am stuck somewhere. 

And my advisor is quite popular but he is forcing me to do MS here even though in past there have not been much good results. I didn't know all this as this is my first experience as a research assistant. 

And I have worked here for 8 months and I thought that I can push this on my own as far as possible and something will come out. But I am losing my hope day by day. I don't know what to do. Even if you have any miniscule advice I would love to hear.
I am working in GNN.",2020-03-13 23:54:42
Support Vector Questions,1,fhw2j8,https://www.reddit.com/r/MLQuestions/comments/fhw2j8/support_vector_questions/,1,1584114523.0," Hi all, I'm new at ML and am stuck on this question. I'm not even sure how to approach it. Any help would be greatly appreciated! 

""Assume we have only two features in our training dataset that is already classified into class C1 and class C2. The transposes of the feature vectors are given below for each class:

C1: \[2 6\], \[1 1\], \[3 4\], \[3 2\], \[-4 8\], \[-1 3\], \[2 2\]

C2: \[-5 -7\], \[-2 -3\], \[-1 -2\], \[3 -7\], \[1 -3\]

Giving details and derivations, determine the (i) number of support vectors from each class (ii) the support vectors (iii) the equation of the hyperplanes (straight lines in this case) defining the sides of the margin (iv) length of the maximum margin (v) equation of the maximum margin linear classifier.""",2020-03-13 21:18:43
What are some good sources for learning Stream Processing and Complex event detection?,3,fhr83i,https://www.reddit.com/r/MLQuestions/comments/fhr83i/what_are_some_good_sources_for_learning_stream/,3,1584089931.0,,2020-03-13 14:28:51
Modern Subspace Clustering Algorithms,5,fhndcu,https://www.reddit.com/r/MLQuestions/comments/fhndcu/modern_subspace_clustering_algorithms/,0,1584075081.0,"Hi, guys.

I do research to find best subspace clustering algorithms. Do you know any influent recent papers with comparison and general overview of them. I have already read **Subspace Clustering for High Dimensional Data (2004)** [**https://www.kdd.org/exploration\_files/parsons.pdf**](https://www.kdd.org/exploration_files/parsons.pdf)**,** but it kind of old paper.

Thank in advance !",2020-03-13 10:21:21
WGAN failing to converge,3,fhle3l,https://www.reddit.com/r/MLQuestions/comments/fhle3l/wgan_failing_to_converge/,12,1584067943.0,"I am trying to train a WGAN on a dataset of 100 images from a total of 10 classes and am following details from the original paper.



No matter what I do, the losses refuse to converge. 


When I keep both of them level(same processing power/layers/capacity) then the DLoss begins as a small negative value (_0.00something) and never leaves that area while the generator loss constantly decreased.



When I Strengthen my generator, the problem persists and that happens no matter what I try.



When I make the discriminator stronger, both the losses seem stuck at negative values close to zero.



No matter what I try there is a failure to converge",2020-03-13 08:22:23
"Working implementation of Bender et al. ""Understanding and Simplifying One-Shot Architecture Search""",1,fhqjfp,https://www.reddit.com/r/MLQuestions/comments/fhqjfp/working_implementation_of_bender_et_al/,0,1584087126.0,"Do anyone know of a working implementation (published code) of the work described in:

Bender, G., Kindermans, P., Zoph, B., Vasudevan, V. & Le, Q.. (2018). Understanding and Simplifying One-Shot Architecture Search. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:550-559

I have tried to replicate the results myself for some time now, but I am still unsuccessful. I have not found any published implementation.",2020-03-13 13:42:06
Has anybody ever managed to get a hardware company (or maybe any other company) to sponsor/donate/provide hardware to use?,2,fhk9gi,https://www.reddit.com/r/MLQuestions/comments/fhk9gi/has_anybody_ever_managed_to_get_a_hardware/,3,1584063775.0,"I'm a PhD student and I was wondering if anybody has ever had any luck with getting free hardware to use (e.g. GPU's, HDD's or SSD's, RAM).",2020-03-13 07:12:55
How can I get the YFCC-100M dataset of Yahoo?,4,fhglz9,https://www.reddit.com/r/MLQuestions/comments/fhglz9/how_can_i_get_the_yfcc100m_dataset_of_yahoo/,2,1584049772.0,"I found many blog posts introducing the dataset YFCC-100M.

However, the links from these posts did not work or exist.

Even though I joined Yahoo's WebScope, it does not provide the YFCC-100M dataset.

I found a way to download the data via AWS-S3 ([https://multimediacommons.wordpress.com/getting-started/](https://multimediacommons.wordpress.com/getting-started/)), but I'm not familiar with AWS-S3.

Is that the only way to get this dataset?",2020-03-13 03:19:32
Is kmeans still the SOTA for customer segmentation?,0,fho6u6,https://www.reddit.com/r/MLQuestions/comments/fho6u6/is_kmeans_still_the_sota_for_customer_segmentation/,11,1584078050.0,"Also read about latent class analysis which seems interesting but not sure it works with large datasets (eg using spark)...
What do you use?",2020-03-13 11:10:50
What is your Go-To method for making a ML/DL model if you want to train imbalanced image dataset?,10,fhcopd,https://www.reddit.com/r/MLQuestions/comments/fhcopd/what_is_your_goto_method_for_making_a_mldl_model/,5,1584027454.0,,2020-03-12 21:07:34
COVID-19 in retinal imaging,2,fhfbm1,https://www.reddit.com/r/MLQuestions/comments/fhfbm1/covid19_in_retinal_imaging/,1,1584043729.0,"I read in an [article](https://www.aao.org/headline/alert-important-coronavirus-context) that COVID-19 can cause conjunctivitis.

Q: If this virus does affect the eye, is there any retinal images dataset with COVID-19 that maybe we could use for automatic detection?",2020-03-13 01:38:49
Need help with issuing actions or notifications after a model classifies an image.,1,fhigb2,https://www.reddit.com/r/MLQuestions/comments/fhigb2/need_help_with_issuing_actions_or_notifications/,0,1584057176.0,"Hi!

I am working on an anomaly detection and notifier system. In this project, I want to use my PC as a server, where a model would be classifying the CCTV footage inputs. I developed the model using keras and OpenCV.

My question is, is there any way to issue a notification to nearby android phones, assuming bluetooth connects them to the PC, if the model detects any anomaly? Can I do some integration with android studio, and develop some dedicated app?

It would be great to have some insight. It is a college project. And I am asked to make it useful.",2020-03-13 05:22:56
Activity recognition using binary sensors.,6,fh9gb1,https://www.reddit.com/r/MLQuestions/comments/fh9gb1/activity_recognition_using_binary_sensors/,3,1584009940.0,"Hello,
I am currently trying to develope a LSTM neural network to classify activities based off sensor data. I have linked an image of an example of this data:
https://www.google.com/search?q=aruba+binary+sensor&safe=strict&client=ms-unknown&prmd=isvn&sxsrf=ALeKk03LQwfXzhUxkH11-QrUZ1Rd9zecSA:1583980694992&source=lnms&tbm=isch&sa=X&ved=2ahUKEwipvJ_185PoAhXMh1wKHfNxB_kQ_AUoAXoECA0QAQ&cshid=1583980842834#imgrc=7pXvrnGeukDL5M

I am at a loss currently as the information I have found online does not clearly explain how I can go about this. Feature extraction seems to be the hardest part, I understand that you can window time series data but nowhere explains a way to do this to effectively use the data I am using. I am rather new to python, but I understand model building and neural networks. 

Could anyone suggest any ways to overcome this problem. You would really be helping a fellow reddit user.
Thank you.",2020-03-12 16:15:40
Variable Selection before LASSO?,2,fhd7hk,https://www.reddit.com/r/MLQuestions/comments/fhd7hk/variable_selection_before_lasso/,6,1584031102.0,"I've seen a couple of studies (that had an initial total of >150 features) use random forest to conduct variable selection before using LASSO on the selected variables. The variables they selected were the top 10 most important features in the Random Forest model.

I've tried to figure out why this method has been used but coming up short. Doesn't LASSO already knock features out during model development? Or is the Random Forest making it more likely that LASSO will only select the absolute most important variables?",2020-03-12 22:08:22
How can I integrate embeddings from XLM- RoBERTa with transformer seq2seq model?,8,fh30z4,https://www.reddit.com/r/MLQuestions/comments/fh30z4/how_can_i_integrate_embeddings_from_xlm_roberta/,0,1583984620.0,"Hello everyone, I am a new researcher on the field of deep learning. Please help/example/guide me on feeding embeddings from XLM- RoBERTa to transformer seq2seq model? Thanks!!!",2020-03-12 09:13:40
Doc2vec and Kmeans and Dbscan,4,fh600m,https://www.reddit.com/r/MLQuestions/comments/fh600m/doc2vec_and_kmeans_and_dbscan/,1,1583995679.0,"
I recently got into the area of ML, and I am trying to solve a problem.

I have a text corpus of around 50000 paragraphs, and the average length in words of each is approx. 120 words.

I first cleaned up the articles from stopwords, tokenized and given them to doc2vec to train. I used 100 epochs, a 46 or 100 vector size, and a min_rep of 2. I kept alpha at default.

After it trains, i have 2 ways I can cluster, kmeans and dbscan.

**Kmeans**

I set an arbitrary clusters of 7, and I reduced with pca to 2 dim, and the visualization is just one circular shape with dense center and the farther you go from it the less points

**dbscan**

Same visual, if i feed it the vector directly it returns a [-1 -1 ...] labels which means it is noise. If I give it the pca of the vector it gives like 27 clusters but they on top of each other


What am I doing wrong?

What should I do to get sensible clusters",2020-03-12 12:17:59
Members of the machine learning team,3,fh42zg,https://www.reddit.com/r/MLQuestions/comments/fh42zg/members_of_the_machine_learning_team/,6,1583988494.0,"for any machine learning project, I always do the work myself from development to deployment. My question is:

What are the various roles in a machine learning team?",2020-03-12 10:18:14
Why does softplus always causes problems if I use it in the last layer?,1,fh7vwd,https://www.reddit.com/r/MLQuestions/comments/fh7vwd/why_does_softplus_always_causes_problems_if_i_use/,1,1584003385.0,"I have tried in multiple circumstances to restrict the output of a network to be strictly positing by using softplus and I have always had a headache trying to figure out why it didn't work. I think it sometimes gets stuck in the very close to 0 region where the derivative would be very flat. 

I can't find any information about this by searching. Is this a known problem and how can I fix it?",2020-03-12 14:26:25
Clustering images when you know some images belong in the same cluster. How can I exploit this?,2,fh46pq,https://www.reddit.com/r/MLQuestions/comments/fh46pq/clustering_images_when_you_know_some_images/,18,1583988849.0,"* I have a large dataset of cat-pictures. (I dont know the breed of the cats)
* Of every cat I have multiple photo's (These pictures should fall in the same cluster!)
* I want to cluster the cat pictures and hopefully each cluster is a different cat breed.

I could feed the pictures to a CNN, get the embedding vectors and cluster them with DBSCAN. But then I wouldnt use the fact that some pictures are of the same cat and should be in the same cluster.

How do I use the knowledge that some pictures should be in the same cluster?",2020-03-12 10:24:09
My code says I have NaN despite having no NaNs,4,fgxsdm,https://www.reddit.com/r/MLQuestions/comments/fgxsdm/my_code_says_i_have_nan_despite_having_no_nans/,5,1583964834.0,"I was doing sentdex's KNN on python and here is my code. The data is from  [https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)) . My code is:

    import numpy as np
    from sklearn import preprocessing, neighbors
    import pandas as pd
    from sklearn.model_selection import train_test_split
    df = pd.read_csv(r'C:\Users\prady\Desktop\Data Science\breast-cancer-wisconsin.data')
    df.replace('?',-99999, inplace=True)
    df.drop(['id'], 1, inplace=True)
    X = np.array(df.drop(['class'], 1))
    y = np.array(df['class'])
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    clf = neighbors.KNeighborsClassifier()
    clf.fit(X_train, y_train)

For this the error comes:

    ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

I tried doing pd.asnull  and got nothing. How should I fix this?",2020-03-12 03:43:54
Why do probabilistic models not share the last layer?,8,fgust1,https://www.reddit.com/r/MLQuestions/comments/fgust1/why_do_probabilistic_models_not_share_the_last/,9,1583950024.0,"Most probabilistic models that I see have separate layers for their output distribution parameters [VAE](https://github.com/pytorch/examples/blob/master/vae/main.py), [Concrete Dropout](https://github.com/yaringal/ConcreteDropout/blob/master/concrete-dropout-pytorch.ipynb), and [Neural Processes](https://github.com/EmilienDupont/neural-processes/blob/master/models.py). I am wondering why this is the case when they could just share the last layer and nothing would change. Is there any benefit or reason that I am not seeing for keeping the last layer separate?",2020-03-11 23:37:04
Discrete Actions for PPO,3,fgvxg1,https://www.reddit.com/r/MLQuestions/comments/fgvxg1/discrete_actions_for_ppo/,3,1583956453.0,"I'm trying to implement a PPO RL algorithm for a multi-agent environment: [switch2-v0](https://github.com/koulanurag/ma-gym/wiki/)

Most of the pytorch implementations I've found online have continuous action spaces, with the action in the implementation I'm following being selected along these lines: 

        def select_action(self, state):
            state = torch.from_numpy(state).float().unsqueeze(0)
            with torch.no_grad():
                mu, sigma = self.actor_net(state)
            dist = Normal(mu, sigma)
            action = dist.sample()
            action_log_prob = dist.log_prob(action)
            action = action.clamp(-2, 2)
            return action.item(), action_log_prob.item()

This returns a single, continuous value for the action, whereas I need an integer \[0, 1, 2, 3, 4\]. What's the best way to change this code to output an integer?",2020-03-12 01:24:13
Ouputs of Posenet model,1,fh075f,https://www.reddit.com/r/MLQuestions/comments/fh075f/ouputs_of_posenet_model/,0,1583974129.0,"How do I interpret. the ouput oof a tflite modell for posenet? 

My output is of shape (1,34, 14, 14 ). It says the output shape is supposed to be  ""offset\_2,displacement\_fwd\_2,displacement\_bwd\_2,heatmap "". 

how do I decode this to get the keypoints and positions?",2020-03-12 06:18:49
Download and run style object detection?,1,fgz8fs,https://www.reddit.com/r/MLQuestions/comments/fgz8fs/download_and_run_style_object_detection/,0,1583970599.0,"I will be presenting to some high-school kids and I'd like to rig up a live object detection demonstration.  I've tried [object-detection.com](https://object-detection.com) but I've noticed the detections are less varied as other models I've seen like from YOLO.  Do you know of any download & run style projects?

I'm just looking for something to pique their interest as they walk by etc.",2020-03-12 05:19:59
Filtering content feeds using ML?,3,fgpllr,https://www.reddit.com/r/MLQuestions/comments/fgpllr/filtering_content_feeds_using_ml/,4,1583921007.0,"First timer here. I've studied ML and done some basic puttering with NLP and AI, but I'd like to actually have a go at a first, real ML project, and I'm looking for advice on how to proceed. The main task of the project would be as follows:

>Given an RSS feed filled with news articles, decide the ""positivity"" or ""wholesomeness"" of each article, and set the most positive/wholesome articles aside.

Does this seem like a valid application of ML? (I *think* it is.) And if so, what would be the best approach to designing and implementing it?

I'm assuming I'd want to define criteria to define what ""positive"" and ""wholesome"" mean, and that I'll probably have to involve at least some NLP. Anything else I should consider? And finally, I'm planning on using python (and would favour a homegrown solution rather over using cloud services), so any suggestions for a framework to use and/or resources to consult would be appreciated.",2020-03-11 15:33:27
Asking for help,1,fgujpd,https://www.reddit.com/r/MLQuestions/comments/fgujpd/asking_for_help/,5,1583948365.0,"Hi guys, I'm blocked and I can't decide about my master thesis's subject. So i'm looking for projects or teams or ideas about machine and deep learning that can help me. Thank you!",2020-03-11 23:09:25
help in training a dataset,1,fgui69,https://www.reddit.com/r/MLQuestions/comments/fgui69/help_in_training_a_dataset/,0,1583948069.0,"hello, i have an data set which contains the images of people and have csv file with their emotion classified . Now, i have to build a model according to that data. i even have the feature extraction algorithm ,i have everything just don't know how to perform the computation and train a model",2020-03-11 23:04:29
"Does anyone have data on the Chinese Wildlife trade, or the lawful export of money out of China?",1,fgt2y1,https://www.reddit.com/r/MLQuestions/comments/fgt2y1/does_anyone_have_data_on_the_chinese_wildlife/,2,1583938625.0,"Hi, I'm at home, sick, with something, I don't know what. I read that that's because the Chinese leadership keep eating wildlife. I do not wish to punish them, I wish to figure out how to do something that they wish to happen that isn't eating wildlife. I have an account on Google, and I'm subscribed to Google collab. I think that machine learning is the right tool for this task.",2020-03-11 20:27:05
Ram utilization on Google colab,12,fggeol,https://www.reddit.com/r/MLQuestions/comments/fggeol/ram_utilization_on_google_colab/,2,1583886165.0,"I am training a neural network on approximately 60k data points for donors choose dataset.
I thought if I would use Google colab(Standard free account. I haven't paid for anything) it would take less time to train.
However, while training, each epoch in colab is taking 1.5 hours in comparison to 55 mins on my Gaming Laptop.

I see that I have 12 GB ram available on the top right hand side of the colab notebook. However only 2.2 GB of that is being used while I am training the network.

This is my first time on colab training a neural network. Am I doing something wrong/missing something here??


Edit: I already searched for this over Google but did not find anything substantial.",2020-03-11 05:52:45
Training a RL agent to play baseball using DQN,2,fgokcg,https://www.reddit.com/r/MLQuestions/comments/fgokcg/training_a_rl_agent_to_play_baseball_using_dqn/,0,1583916707.0,"First post here! I’m training an RL agent to play a retro baseball game on GameBoy. I’m using OpenAI Gym and a DQN architecture, but I’m currently having issues.

Focusing on offense (at bat), the RL agent has difficulty learning the precise time to swing and hit the baseball. There are only two actions: the A button (swing) and None (wait). I have tried to implement a small reward for waiting and a small penalty for swinging, but the agent still tries to swing many times (although only 1 or 2 of the swings actually register in the game), and the agent never makes contact with the ball. The penalty for a strike is very large (a strike is also the done condition), but the agent still doesn’t show any improvement.

Any ideas for how I can make this work? I hope I provided enough information, but if not, I can follow up. Thanks!",2020-03-11 14:21:47
Parts of GPUs that are active in machine learning,3,fgij0p,https://www.reddit.com/r/MLQuestions/comments/fgij0p/parts_of_gpus_that_are_active_in_machine_learning/,0,1583893958.0,"Hello guys!

I was wondering weather graphics logic in GPUs is being utilized in any sort of way in machine learning operation? For example are ROPs and TMUs idle the whole time ?",2020-03-11 08:02:38
What is the best api for this task?,4,fgeoct,https://www.reddit.com/r/MLQuestions/comments/fgeoct/what_is_the_best_api_for_this_task/,5,1583879413.0,"
I want to create a python/flask app where the user can upload a picture of an animal and the algorithm based on its training will be able to specify what species of animal it is.

I know there’s a fair few apis out there but I was wondering what is the best (and most simple) to use? Preferably with clear docs as I’m still learning myself and this is for a side project of mine",2020-03-11 04:00:13
[QUESTION] How a complete beginner can learn ML and theory behind it?,5,fgdlqr,https://www.reddit.com/r/MLQuestions/comments/fgdlqr/question_how_a_complete_beginner_can_learn_ml_and/,2,1583874786.0,"Hello everyone! I am a 15 year old student who is interested in ML. Before starting my ML adventure I made several google searches, about the right roadmap to learn ML. After a little bit of searching, I got to know that I needed to know the math behind topics in order to correctly understand and be able to implement them. And most of the answers I've looked so far suggested that I learn math topics such as Calculus, Linear Algebra, Statistics, Probability, Trigonometry. And then move one to learn approaches about ML such as Linear Regression, Logistic Regression… Since I am 15 years old, in my country the education system does not teach those topics at school until I am 17 years old. Because of that, I decided to study topics by myself. After, again, doing some google research I found a few popular courses taught by well known university teachers. But could not understand topics, because most of them assumed that student knows those topics from highschool years and just skimmed through some parts that were important to me. Can any of you guys please suggest me beginner-friendly courses? I do want to learn the whole math required. It does not matter if the course you would suggest to me is paid or not. And do you guys have a road map to suggest? What should I do after learning maths? Thank you all…",2020-03-11 02:43:06
Get Machine Learning Blogs daily,3,fgcmji,https://www.reddit.com/r/MLQuestions/comments/fgcmji/get_machine_learning_blogs_daily/,1,1583870032.0,"If you are one who is looking to learn Machine Learning and python, then there is good news for you. MlTut provide you the platform where you can get daily latest machine Learning blogs. Don't miss to visit this site.
www.mltut.com",2020-03-11 01:23:52
Tensorflow for liquid detection,1,fgg9x0,https://www.reddit.com/r/MLQuestions/comments/fgg9x0/tensorflow_for_liquid_detection/,4,1583885674.0,"Hey guys, I'm fairly new to machine learning and looking to create something that can take a picture of a glass of water and determine how full the glass is. Can anyone point me in the right direction as to how i can go about creating and training a tensorflow model that would be able to do this? Ive done some google searching for tensorflow line detection and the only thing i can find is lane detection which I dont think is what im looking for. Any guidance would be appreciated! Thanks",2020-03-11 05:44:34
log_loss giving a different value than i expect for a categorical cross etnropy baseline,1,fgf7gv,https://www.reddit.com/r/MLQuestions/comments/fgf7gv/log_loss_giving_a_different_value_than_i_expect/,0,1583881562.0,"I am trying to calculate a validation baseline for categorical cross entropy

    from sklearn.metrics import log_loss 
    
    # create empty array with same shape as validation output
    dummy = np.zeros_like(validation_y) 
    
    # get the most popular class in *training* data (i've checked and this index is correct)
    pop_class_ind = np.argmax(np.bincount(np.argmax(train_y, axis=1)))
    
    # set this index's column to 1 (predicting the most popular class every time)
    dummy[:, pop_class_ind] = 1 
    
    baseline = log_loss(validation_y, dummy) 
    print(baseline) 

However the value i get is not what i expect at all. Is log\_loss different than categorical cross entropy?",2020-03-11 04:36:02
What is your preferred method to track results in your porjects?,12,fg50zh,https://www.reddit.com/r/MLQuestions/comments/fg50zh/what_is_your_preferred_method_to_track_results_in/,8,1583828952.0,"Previously I have been writing them out to a text file that I keep appending to and I add relevant information about the run such as hyperparameters, etc. This is getting very annoying because I usually end up having to gather the results by hand into an excel file and do averages, etc. 

I find the pandas API very confusing and I have a hard time making things like different sheets, or opening an existing excel file and appending to it.

I am wondering what the preferred method for tracking results is for everyone, maybe there is a better solution out there somewhere...?

Thanks",2020-03-10 13:59:12
Asking for Help...,1,fgbj29,https://www.reddit.com/r/MLQuestions/comments/fgbj29/asking_for_help/,4,1583863756.0,"Hello community!

Need a help. I'm struggling with a problem. For privacy I can't disclose the actual problem but let's assumed a dummy problem.

Suppose I've a dataset as follow:

&#x200B;

|user\_input|book|
|:-|:-|
|published in 2018, 21 lessons from 21st century|21 lessons for 21st century|
|i'm from india, love to read homo deus by noah harari|homo deus|
|the sunday times top ten best seller, sapiens|sapiens|

&#x200B;

Now from user\_input column I want to infer the name of the book what the user talked about.

&#x200B;

Can anyone suggest any approach? Model, architecture, techniques? Anything.",2020-03-10 23:39:16
"I'm considering graduate school for ML, and I'm looking for some advice in how to approach this.",3,fg66vq,https://www.reddit.com/r/MLQuestions/comments/fg66vq/im_considering_graduate_school_for_ml_and_im/,6,1583833830.0,"I'm currently getting a Bachelor's in CS / Data Science (expected 2021), and I know for certain I want to focus on ML. I have very high grades at a well-known school, and I have been working on the school's ML research team for over a year. However, this team is extremely application-focused, while I'm far more interested in the mathematical and statistical aspects of ML, and want to work in model architecture research. Also, this school has only one ML course and it is very introductory despite being considered a high-level course. I do not want to do graduate school here, so I need to start looking at other schools for solid ML graduate programs, and would like some recommendations. 

In the meantime, I'm looking into completing a Statistics minor to flesh out my mathematical background a little bit more, as well as teaching myself more linear algebra and basic ML math. I'm also considering seeing if I can do research for another department (maybe economics) so I can at least work with data I am more interested in.

I don't believe that the main ML faculty member at my school will be a very useful resource in achieving these goals, though he is likely to provide a good reference. I would very much appreciate some outside guidance  in resources I can use, options I should consider, and any additional steps I should take.",2020-03-10 15:20:30
Statistical Significance from XG Boost Model,9,ffws4m,https://www.reddit.com/r/MLQuestions/comments/ffws4m/statistical_significance_from_xg_boost_model/,14,1583798130.0,"I am working on a dataset with around 16k rows and 80 features.  The target variable has 4 classes.  Around 30-40 variables have missing values and there is high class imbalance, so I decided to use XGB model for prediction.  Although prediction is the main goal, by using the feature importance plot I got decent insights after digging into the important features.  When I presented them to the business user, they were “intrigued” by the patterns.  But they asked me how can you say that these variables are statistically significant among other variables?  I did not know what to say.

Also, more generally, can we prove statistical significance in boosted (or bagged for that matter) trees?  Does it make sense to think in this way?",2020-03-10 05:25:30
Equation of decision boundary in SVM (python),3,fg1b2j,https://www.reddit.com/r/MLQuestions/comments/fg1b2j/equation_of_decision_boundary_in_svm_python/,1,1583814729.0,"Is it possble to view the exact equation of the final decision boundary (surface) produced by SVM?

Thanks!",2020-03-10 10:02:09
[D] Perceptron Learning Algorithm - Implementation in R,2,fg2cij,https://www.reddit.com/r/MLQuestions/comments/fg2cij/d_perceptron_learning_algorithm_implementation_in/,5,1583818525.0,"Hi everyone,

I am currently taking Prof. Yaser Abu-Mostafa's machine learning course from Caltech, and I'm having issues implementing the perceptron learning algorithm (PLA) in R.

My PLA works fine at times, as it converges to a solution within an appropriate number of iterations (it should be \~15 iterations according to the homework solution). There are other times, however, when the PLA seemingly never converges (>100,000 iterations), and I have to stop the program.

Problem statement:  


https://preview.redd.it/573f1v1fupl41.png?width=1025&format=png&auto=webp&s=fcba81083d5ab34d9e6bafae58a4359af26d9810

My implementation steps for PLA have been:

1. Identify all misclassified points with the current weight value *w* (initially all zero)
2. Randomly choose *one* misclassified point and use it as x\_n for the update rule in the box (picture below)
3. Repeat steps 1-2 until there are no misclassified points (i.e., you have converged to a solution for weight w)

https://preview.redd.it/jek3r58gupl41.png?width=1323&format=png&auto=webp&s=21ea77ebc37a5e3c2614c45f908410ec9cacdc45

With this framework, with N = 10 data points, is there a reason why my PLA seemingly doesn't converge to a solution at times? I'm not sure if I'm having an implementation issue in R or simply a conceptual issue with the problem.",2020-03-10 11:05:25
Skip Gram Implementation Questions,1,fg0e84,https://www.reddit.com/r/MLQuestions/comments/fg0e84/skip_gram_implementation_questions/,0,1583811462.0,"Hello all,

I’m implementing the Skip Gram Model from scratch for a project of mine but have a few questions I need cleared up to get the full understanding:

1) What is the size of the output layer? I’m getting mixed information on it. Some says it’s the size of the entire vocabulary list, others say it’s only as big as your window size so that it spans the context words you have for that particular input. 

2) How often do I update my parameters? Is it once per set of data points? Once per full sentence? Once for the entire dataset and then rerun the model?

3) How does the soft max classifier turn the output of the model into a one hot vector since the soft max returns [0, 1] while the one hot is only 0 OR 1? Do I take the highest number and set that as my [0, 0, ... 1 ... 0]?

4) In regards to training the model, after getting this one hot vector in part 3, how do I interpret the loss? Is it if my output doesn’t match my input, then it means it was wrong?",2020-03-10 09:07:42
DDPG agent using the MATLAB reinforcement learning toolbox,2,ffvb2f,https://www.reddit.com/r/MLQuestions/comments/ffvb2f/ddpg_agent_using_the_matlab_reinforcement/,0,1583792240.0,"I have created a neural network and DDPG agent using the MATLAB reinforcement learning toolbox to balance an inverted pendele.

I try to implement the trained agent in a real pendel but i couldn't find a right way.

I will an agent 1 time trainieren and implement it in a pendel. So that it doesn't take time to learn every time.

how to run the code again without taking to much time? How do I save the out puts of the model to the agent. Have anybody an idea?

I am absolutely grateful for any answer.

Thank you!",2020-03-10 03:47:20
Does someone understand the self-Attenion used in this paper.,1,ffy36b,https://www.reddit.com/r/MLQuestions/comments/ffy36b/does_someone_understand_the_selfattenion_used_in/,0,1583803073.0,"Hi so I stumbled across this paper ([https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0414-z](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0414-z)) in which they use self-attention in a graph convolution layer.  


In the paper they simply state that they multiple the matrix containing the embedding (G) is multiplied with itself:

*Attention Weights= softmax ( G\*G**^(T)* *)*

The Attentive Embedding Matrix (E\_G) is then equal to :

*E\_G= att\_weights \* G*

Lastly they state that for the final output of the attention layer they add E\_G+ G. 

I checked the code ([https://github.com/tbwxmu/SAMPN/blob/master/mpn.py](https://github.com/tbwxmu/SAMPN/blob/master/mpn.py)):

    
att_w = torch.matmul(self.W_a(cur_hiddens), cur_hiddens.t())    att_w = F.softmax(att_w, dim=1)    att_hiddens = torch.matmul(att_w, cur_hiddens)    att_hiddens = self.act_func(self.W_b(att_hiddens))    
    att_hiddens = self.dropout_layer(att_hiddens)    
    mol_vec = (cur_hiddens + att_hiddens) 
    return mol_vec

Does anyone know where they could have gotten the idea from: It does not match necessarily with the self-attention I know  
So I don't really understand why they apply the Weights only on the first cur\_targets but not teh second (the transpose) also I do not understand wh they add the att\_hidden to the cur\_hiddens. Should the the att\_hidden not already contain the cur\_hidden but scaled by attention?",2020-03-10 06:47:53
Is Andrew Ng's Machine Learning on Coursera still the best intro to machine learning available online?,44,fff2ur,https://www.reddit.com/r/MLQuestions/comments/fff2ur/is_andrew_ngs_machine_learning_on_coursera_still/,13,1583714555.0,"Or are there better, newer alternatives?

I don't mind paying for a certificate if it's worth it. Thanks",2020-03-09 06:12:35
Is a convolutional layer like a fully connected layer with these following restraints?,2,ffom76,https://www.reddit.com/r/MLQuestions/comments/ffom76/is_a_convolutional_layer_like_a_fully_connected/,3,1583753900.0,"Obviously I apologize if what I'm about to ask makes no sense.

Is a convolutional layer a special case of the fully connected layer where

- almost all connections to a hidden unit h^ij are frozen at 0 weight except for the few inputs near (i,j)

- the same weights are used for each set of connections (per feature)

I've read things online that a fully connected layer is basically a convolutional layer with a single window the size of the input. I believe this assumes that the hidden layer is the same size as the input layer, right? 

But in theory, if I wanted to have 5 features for a NxM image, could I have a hidden layer that has NxMx5 units/neurons? And in theory, it could learn 3x3 or 5x5 features, not just NxM features. It would be near impossibly unlikely, but it could happen theoretically - where NxM units end up with a set of weights that is mostly 0 except the same 9 (or 25) weights have the same values for each of the units? And by same weights, I mean relative to (i,j) 

Somewhat tangentially, I believe you're supposed to select the size of the feature/kernel for a conv layer. But there's no reason you can't have some 3x3 features and some 5x5 features, since they produce the same output size, right? So I think you can have two ""parallel"" layers, one with 3x3 and one with 5x5 and then concatenate them into a single output. Is this ever practical?",2020-03-09 17:08:20
I’m working on a neural network model. Every time I shut down the computer there is a reason for me to run the code again and this taking to much time? How do I save the out puts of the model to the neural network?,1,ffqi9b,https://www.reddit.com/r/MLQuestions/comments/ffqi9b/im_working_on_a_neural_network_model_every_time_i/,2,1583764231.0,,2020-03-09 20:00:31
SPSS Classification table vs SKlearn confusion matrix,5,ffdtqd,https://www.reddit.com/r/MLQuestions/comments/ffdtqd/spss_classification_table_vs_sklearn_confusion/,2,1583709222.0,"Hello,

As far as I understand for (binary) logistics regression, the confusion matrix in Pythons SKlearn is the same as the classification table in SPSS.  I would like to ask, since SPSS uses the whole dataset for the classification table, why is this the case? Shouldn't the train set be exempted?

I thought for ML Models we split into train and test sets, so the accuracy needs to be determined only by the test set, including other metrics like precision or recall. So using the whole data set should be wrong, right?",2020-03-09 04:43:42
Intermediate Layers of AlexNet/VGG,2,ffj1ln,https://www.reddit.com/r/MLQuestions/comments/ffj1ln/intermediate_layers_of_alexnetvgg/,0,1583729966.0,"I am trying to use PyTorch to get the outputs from intermediate layers of AlexNet/VGG:

    alexnet_model = models.alexnet(pretrained=True)
    modules = list((alexnet_model).children())[:-1*int(depth)]
    alexnet_model = nn.Sequential(*modules)

What is odd is that I get the same output values (i.e. the same exact model) when `depth=1` and `depth=2`, and then the same output values for `depth=3` all the way to `depth=10`. I observe this same phenomenon for VGG too. However, I don't observe this for ResNet, which gives me different output values (i.e. different models) for all depths \[1, 10\].

Any ideas about what might be going on?",2020-03-09 10:29:26
Help with creating an AI chat bot,2,ffijrh,https://www.reddit.com/r/MLQuestions/comments/ffijrh/help_with_creating_an_ai_chat_bot/,0,1583728060.0,"Hello everyone, I'm currently trying to build a chatbot simmilr to Woebot that allows users to have someone to talk to about their problems. My general understanding for this is that I would make a large Jason files full of massive amounts of ""intents"" and I would train the tensor flow model to translate what the user says into one of the appropriate ""intents"". Afterwards I would contextualize the chat and provide a sleeker looking UI for the application. I have several questions however. Since I can make literally millions of ""intents"" and still fail to have those intents encompass every response to what every human is going to say, how would I train the model to make it's own intents to better respond to the user? Also, what does contextualizing the chatbot do?",2020-03-09 09:57:40
What data is sent from a client to a server in a federated learning setting?,2,ffhduh,https://www.reddit.com/r/MLQuestions/comments/ffhduh/what_data_is_sent_from_a_client_to_a_server_in_a/,0,1583723680.0,"Hi,

so far, I thought federated learning works like this:

All clients have the same machine learning model (if not personalized). They have their unique data and then train this model (e.g., neural network) with their data. Then, they have a new matrix of neural network weights.

They then either share the new matrix completely with the server, or at least the changed matrix parameters.

&#x200B;

However, in a recent [post](https://www.reddit.com/r/MLQuestions/comments/erskr7/how_computationally_efficient_or_inefficient_is/) of mine, a user said:

>it looks like you might also seem to think that final parameters are the things communicated upstream in federated learning. This isn't the case, it's gradient updates which go upstream.

I don't quite understand what the difference is - a neural network consists of one or several weight matrix/matrices, so this should be shared, not?

Thanks!",2020-03-09 08:44:40
Why does the silhouette_score (in python) require labels as input?,1,ffkf03,https://www.reddit.com/r/MLQuestions/comments/ffkf03/why_does_the_silhouette_score_in_python_require/,0,1583735397.0,"I would think it only needs the data since it: ""outputs a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation).""

However, I also need to input the labels (which the function itself computes); so, why are the labels necessary to input?",2020-03-09 11:59:57
"Pca, kernel pca, ica",2,ffebqe,https://www.reddit.com/r/MLQuestions/comments/ffebqe/pca_kernel_pca_ica/,4,1583711412.0,"Do all these algorithms essentially accomplish the same task (dimension reduction)? Do ica and kernel pca also provide a method of understanding the variance loss per eigen vector? Can you also use the results of ica and kernel pca as inputs for a classification algorithm? E.g. (k means clustering, logistic regression)? 

Thanks!",2020-03-09 05:20:12
Finding MULTIPLICATIVE and ACCUMULATION(MAC) opertations in keras framework. Is there any function to claculate this or should i do it manually? Thanks,5,ff9wuz,https://i.redd.it/8vsh0t5bvel41.png,7,1583685630.0,,2020-03-08 22:10:30
Clustering,1,ffe8vk,https://www.reddit.com/r/MLQuestions/comments/ffe8vk/clustering/,0,1583711068.0,"Can anyone provide a brief explanation how these are different:

Density clustering, hierarchical clustering, graph clustering, spectral clustering?

Thanks!",2020-03-09 05:14:28
How can I structure my time-series data into a recurrent neural network?,1,ff8z2i,https://www.reddit.com/r/MLQuestions/comments/ff8z2i/how_can_i_structure_my_timeseries_data_into_a/,2,1583679299.0,"Say I have multiple time-series data with the same length that I want to pass into my model. For example,



Date | Feature1 | Feature2 | Label | Dataset
----|--------|--------|-----|-----
2010-01-01 | 2 | 1 | 1 | 1
2010-01-02 | 3 | 2 | 2 | 1
2010-01-03 | 1 | 3 | 3 | 1
2010-01-04 | 2 | 4 | 4 | 1
... |  |  | 
2010-01-01 | 1 | 6 | 1 | 2
2010-01-02 | 2 | 7 | 2 | 2
2010-01-03 | 3 | 1 | 3 | 2
2010-01-04 | 1 | 2 | 4 | 2


and so on,

If I have a csv like this, can I separate the entire thing into batches, where the batches are the datasets? So, in this table I only have 2 datasets, which would mean 2 batches. However If I had 1000 datasets, can I feed this thing into my model, with the amount of batches equal to 1000? How can I pass this data into my model?",2020-03-08 20:24:59
Small dataset for speech recognition,1,ff8wd9,https://www.reddit.com/r/MLQuestions/comments/ff8wd9/small_dataset_for_speech_recognition/,0,1583678815.0,"Is there an analog dataset of omniglot for speech recognition ? Indeed, I am interested in the task of one shot learning for speech recognition, and I would like to know if there is a benchmark dataset for that purpose.",2020-03-08 20:16:55
How to evaluate a machine learning model?,9,fey739,https://www.reddit.com/r/MLQuestions/comments/fey739/how_to_evaluate_a_machine_learning_model/,7,1583630548.0,"Hi,

I'm trying to create a credit risk model based on xgboost using sklearn in Python. I'm unsure how to evaluate the model. If I change the random\_state of the test\_train dataset, I get different accuracy, recall, precision etc. values every time. So how am I able to safely evaluate the model if I get a different result with each different chosen random\_state? If I'm not wrong I can try different random\_states out until I finally get a result I'm satisfied with?

I understand so far I can use 5 fold cross validation to pinpoint the accuracy but what about the other classification metrics like the accuracy of the test set? 

Thanks alot!",2020-03-08 06:52:28
How to encode text and pictures in one system to vectors?,2,ff2jc2,https://www.reddit.com/r/MLQuestions/comments/ff2jc2/how_to_encode_text_and_pictures_in_one_system_to/,6,1583648076.0,"Ok, So I have blog posts, with an images, which I want to feed into a NN. The image contains certain features which are important to the model, so I don't want to transcribe it or anything. I was thinking of encoding the text using one hot encoding then using an auto-encoder to reduce the dimensions, however, with the image, I don't know how to do so. Anyone has any suggestions as to what I should do?",2020-03-08 11:44:36
How involved is machine learning in facial recognition technology?,0,ff5e5v,https://www.reddit.com/r/MLQuestions/comments/ff5e5v/how_involved_is_machine_learning_in_facial/,1,1583660676.0,I'm interested to understand how Apple or android phones can read/identify your face for unlocking and whether machine learning has anything to do with it and whether this is something we can program ourselves?,2020-03-08 15:14:36
FB Prophet not capturing specific weekday spikes,2,ff1q2u,https://www.reddit.com/r/MLQuestions/comments/ff1q2u/fb_prophet_not_capturing_specific_weekday_spikes/,4,1583644734.0,"I have about 2 years of data. When running the training on the whole set - 10 days (I use the past 10 days to check if it's accurate) I get pretty decent results for every day but Thursday. Thursdays have a pretty decent spike and Prophet doesn't capture this for some reason and is off by roughly 20%. Thursdays have been this way for at least 6 months, so it should have noticed this pattern. 

Is there any way to tell Prophet to bump up Thursdays or something? Thanks.",2020-03-08 10:48:54
Question on supervised vs unsupervised learning,0,ff4d09,https://www.reddit.com/r/MLQuestions/comments/ff4d09/question_on_supervised_vs_unsupervised_learning/,1,1583655918.0,"1) if you have two identical datasets: one of them has labels, the other doesn't. Are you naturally at an advantage using the dataset with labels? Given the labels, will supervised learning be more likely to correctly classify new observations compared to unsupervised learning (all things being equal)?",2020-03-08 13:55:18
Looking for a Mentor for our Deep Learning Chatbot project(only for Learning purpose Not Commercial),1,ff0eiu,https://www.reddit.com/r/MLQuestions/comments/ff0eiu/looking_for_a_mentor_for_our_deep_learning/,0,1583639363.0,"Hi there!

I am not sure whether I should make this kinda request in the first place!

But we are seeing no other option but to ask for help to the kind hearted people out there..

We are a team of two NLP enthusiasts who are willing to gain experience in advanced text analysis by creating a chatbot project using deep learning.

We know the wheel has already been invented :), but we would like to know how to make a custom wheel for ourselves!

Going by the overwhelming amount of information available online, our novice mind is kinda lost and not yet succeeded in forming a concrete project plan.

Thus we are badly looking for mentorship from an experienced person(who would be like a research guide to a bunch of students engaged in some academic project) but unfortunately there is no one in our known circle, who has prior experience or bandwidth to provide mentorship to a non-commercial project purely meant for learning purpose.

Still, posting this request with a thin hope of being lucky find a mentor for our project who would be able to spend some of his/her valuable time to guide us just for the joy of spreading knowledge!(I know what we are asking is too much to ask for!)

PS: Just thought of mentioning that our two-members team is comprising of two guys who do not know each other and met on this reddit platform and agreed to collaborate going by the sole purpose of learning something new

Thanks in advance!",2020-03-08 09:19:23
Keras inference on big images learning on small,2,fev01p,/r/learnmachinelearning/comments/fdykh2/keras_inference_on_big_images_learning_on_small/,9,1583615849.0,,2020-03-08 02:47:29
HELP!! Seeking your advice on XLM-R for NMT,2,fetf0d,https://www.reddit.com/r/MLQuestions/comments/fetf0d/help_seeking_your_advice_on_xlmr_for_nmt/,0,1583605508.0," I want to use XLM-R for neural machine translation b/n the same low resource language?  
*For example: Input-> He sells food(in Catalan) Output-> Food he sells(in Catalan)*  
Anyone having code example/tutorial please share. Thanks",2020-03-07 23:55:08
problem implementing NN in numpy,6,feol12,https://www.reddit.com/r/MLQuestions/comments/feol12/problem_implementing_nn_in_numpy/,8,1583576500.0,"I'm trying to implement a NN in numpy to recognize digits from the MNIST database as part of a Kaggle competition. The cost does seem to be decreasing with each iteration, but my predictions don't improve. Being a newbie, I haven't been able to figure out where I'm going wrong.

I would really appreciate it if someone could have a look over my code ([github](https://github.com/iso1048/digit_rec_kaggle/blob/master/3%20layer%20NN%20from%20scratch.ipynb)) and point out any mistakes. The dataset can be found [here](https://www.kaggle.com/c/digit-recognizer/data).

Thanks",2020-03-07 15:51:40
Suggesting most likely improvement to performance indicator parameters,1,fetgfp,https://www.reddit.com/r/MLQuestions/comments/fetgfp/suggesting_most_likely_improvement_to_performance/,0,1583605783.0,"I have a machine learning project where we calculate a performance indicator ( A * B * C / D = Performance ). The goal is the following - given a person with the parameters A, B, C and D, suggest the best (most likely/easiest to implement) improvement to one of the parameters to increase Performance.

My idea to do this is the following: implement a machine learning algorithm which predicts one parameter based on the other three (and perhaps some other relevant metadata about the person). Given a person with parameters A, B, C and D, increase parameter A such that Performance increases by 5% (which in this case is A\*1.05). Based on parameters B, C and D, calculate the likelihood of having A\*1.05 as a parameter. Let's say the likelihood is 87%. 

Now do the exact same for parameters B, C and D (and find out how likely it is that the Performance would be increased by 5% by increasing only that specific parameter). 

Let's say the algorithm predicts likelihoods of 82%, 90% and 75% for B, C and D. Given these results, we should suggest to the person that he should increase his parameter C, because based on other people's data, that seems like the most achievable goal (with 90% certainty)

Is this approach feasible? Are there better approaches?

Edit:

It has occurred to me that predicting a number is not the same as predicting the likelihood of a number occurring. If based on A, B and C we predict that D should be, let's say 105, then as far as I know, that tells us nothing about the probability of D being 108. However, a similar approach can still be used. Let's say A = B = C = 2. We will leave out D for now because it's easier to explain that way. And let's say that using the other parameters we will once again try to predict the values of each parameter. Let's say our predictions are A = 1.97, B = 2.02 and C = 2.05. 

In that case we can say ""Oh, the value of C for this person is currently 2, but we predicted that it should be 2.05. Therefore, this person's C parameter worse than we expect, and therefore he should try to raise it."" And since B's prediction is closer to reality than C is, we know that it's more important/more likely for this person to improve his C parameter.",2020-03-07 23:59:43
Question on data leakage/corruption for time series problems,4,fegi6k,https://www.reddit.com/r/MLQuestions/comments/fegi6k/question_on_data_leakagecorruption_for_time/,2,1583543185.0,"I am doing what is essentially some signal prediction using a NN where i will try to predict a characteristic about the future of the signal, using some feature engineering from previous data points of the signal.

All of my features are relative to the current data point so none of them contain any specific values, they are all %'s compared to the current data points. And there is also not any timestamp or date time type of features.

Given this, i think theoretically speaking a NN could possibly gain an artificial edge by validating a sample consecutively to a training sample, and basically say that these patterns are close enough. However, the features are more or less shifted one unit, and because of this the patterns are actually quite different in that sense.

Since i am providing my model nothing but a relative pattern, i am wondering to what sort of degree the model will be able to cheat and find out that samples are close enough? Since i have a large amount of samples, i think that should reduce the effect of any leakage. I also think that the model will have to have a very large capacity to basically create a sub network to match every individual pattern at a very high precision, but also not a high enough precision to cut out of the next pattern with shifted features.",2020-03-07 06:36:25
How to train actor critic agents that sample actions multiple times?,1,feowux,https://www.reddit.com/r/MLQuestions/comments/feowux/how_to_train_actor_critic_agents_that_sample/,2,1583578123.0,"I'm trying to train an agent using IMPALA that has 7 actions. The agent samples each action with different action spaces. In this case how do I calculate policy and entropy loss? Should I iterate over the action, logit pair and calculate the mean?",2020-03-07 16:18:43
Adversarial Facial Recognition,1,fekgtn,https://www.reddit.com/r/MLQuestions/comments/fekgtn/adversarial_facial_recognition/,0,1583558556.0,"Is  the any methods like DeepFool that generalizes well for producing  adversarial examples for multiples types of image recognition models?  Whether it's ResNext, VGG, NoisyStudent, etc.

I was able to get pretty good results with DeepFool against VGGFace. ([Quick write-up on my results](https://medium.com/@mmoya.impulse101/poisoning-the-well-for-privacy-d39b1717176f)).  
But I was just wondering if there was any newer method that can work against any CNN.",2020-03-07 10:52:36
Need some help getting started - determining the important entities in text,1,fehcad,https://www.reddit.com/r/MLQuestions/comments/fehcad/need_some_help_getting_started_determining_the/,0,1583546429.0,"Here's the data I have:  

1. Text from articles from various music blogs & music news sites (title, summary, full content, and sometimes tags).   

2. I used a couple different NLP/NER tools to determine the proper nouns in the text, and gave each proper noun a score based on how many times it appeared, and how many NLP tools recognized it as a proper noun.  

3. For each proper noun I queried [musicbrainz](https://musicbrainz.org/) to find artists with that name. (musicbrainz has a lot of data that may be helpful: aliases, discography, associations with other artists)
  
4. Any links in the article to Spotify, YouTube etc. and the song name & artist for that link  

I have three goals:    

1. Determine which proper nouns are artists  
2. For artists that share the same name, determine which one the text is referring to  
3.  Determine if the artist is important to the article, or if they were just briefly mentioned

I have manually tagged some of the data with the correct output for the above 3 goals.    

How would you go about this? Which algorithms do you think would be best for these goals?   
Is there any semi-supervised learning I can do to reduce the amount of tagging I need to do?",2020-03-07 07:30:29
"If you are a fresher and you’re looking to make a career in data science, is the a requirement as to being able to do a kaggle project perfectly well on your own?",3,fe84e7,https://www.reddit.com/r/MLQuestions/comments/fe84e7/if_you_are_a_fresher_and_youre_looking_to_make_a/,7,1583497520.0,,2020-03-06 17:55:20
Could use some advice about detecting and editing specific part of an image.,2,feaagh,https://www.reddit.com/r/MLQuestions/comments/feaagh/could_use_some_advice_about_detecting_and_editing/,1,1583510109.0,"Hi, I'm still very new to machine learning but I would like to create an application that will take a photo and switch out whatever clothes you are wearing in an image for clothing from a select menu, essentially enabling you to 'try on' those outfits. Any advice on how I might set out to do this?",2020-03-06 21:25:09
Advice for multi-label classification to predict medical codes from reports,1,feb35e,https://www.reddit.com/r/MLQuestions/comments/feb35e/advice_for_multilabel_classification_to_predict/,1,1583515619.0,"Hi everyone,

I have some questions about an ML/DL problem I am facing. I want to predict categories/codes for medical examinations from medical reports. It's a multi-label classification problem (n different codes per report possible). The problem is similar to [""Towards Automated ICD Coding Using Deep Learning""](https://arxiv.org/abs/1711.04075). 

I feel comfortable cleaning, lemmatizing and tokenizing the texts and encoding the medical codes but am not quite sure how to proceed from here because my knowledge of NLP and neural networks is basic at best. I have a statistical background but no fundamental experience in anything deep learning related.

I'd be happy for any ideas and recommendations for resources/literature to give me a push-start here.",2020-03-06 22:56:59
Multivariate Time Series Classification,12,fdybwq,https://www.reddit.com/r/MLQuestions/comments/fdybwq/multivariate_time_series_classification/,7,1583456768.0,"So I am working on a new project which is about time series classification.

I have 8 features and 1 binary variable about if there is activity or not. 

I want to use a conv lstm net and I was wondering if you could maybe help me come up with a way to window the data and especially the features. 

I thought I could use tf.dataset but I could only find information about windowing for time series prediction..",2020-03-06 06:36:08
hi how could i make a simple rnn,6,fdymal,https://www.reddit.com/r/MLQuestions/comments/fdymal/hi_how_could_i_make_a_simple_rnn/,1,1583457865.0,hi i am a begginer in coding and i found this blog from Andrej Karpathy [http://karpathy.github.io/2015/05/21/rnn-effectiveness/](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)  but the code is to advanced for me does anyone have a good tutorial on how to set up a very simple rnn that takes in text as input and outputs text,2020-03-06 06:54:25
Using GA to train multilayer network,1,fe48p3,https://www.reddit.com/r/MLQuestions/comments/fe48p3/using_ga_to_train_multilayer_network/,4,1583479712.0,"Hey guys,

what are my chances of achieving a similar success that the team of OpenAI achieved with Dota-2 robot, if instead of using such a complex system (like they used) I will just use a fixed layer network (say 4 or 5 layers) and train this network using Genetic algorithm altering weights only? (I can't do gradient descent because it would get stuck in local minima)

Now, my problem is not Dota2, I am going to use this network for forex trading, but both problems are very similar. So, instead of using some complex architecture , I could go for a fixed architecture, train it with GA, and implement it on a GPU with custom kernels (to speed up things more than if done with Tensorflow).

Lets say, I will pick a 4-layered architecture of 128 neurons in each layer, and train it for months, eventually this architecture (or any similar architecture) will converge to a working solution, right? Correct me if I am wrong, but if the solution exist, I will reach it anyway with any network architecture, it is just going to take more time. Because, I don't have the knowledge of machine learning to produce so elaborate design like OpenAI did, but a (kind of)""brute-force"" solution like I am describing could work for me even if it be a bit slower, or wouldn' it? What do you think? Will GA be able to train a deep neural network?",2020-03-06 12:58:32
How can I intuitively understand various performance metrics on a Neural Network?,10,fdr4fj,https://www.reddit.com/r/MLQuestions/comments/fdr4fj/how_can_i_intuitively_understand_various/,7,1583418179.0,"Convolutional Neural Network in particular. F1, mAP, AuC, IoU... so many acronyms that don’t make any sense to me. Any good tutorial?",2020-03-05 19:52:59
Sharing a nice site that is friendly for beginners,4,fdtrx3,https://jallobytes.com,0,1583435717.0,,2020-03-06 00:45:17
Any suggestions for thesis?,0,fdyj25,https://www.reddit.com/r/MLQuestions/comments/fdyj25/any_suggestions_for_thesis/,4,1583457521.0,"I am doing masters in computer science and specialisation in Machine Learning and I have to submit thesis topic next week, so you guys have any suggestions?
Thank you for your help.",2020-03-06 06:48:41
Training a Neural Network without Early Stopping,1,fdud1p,https://www.reddit.com/r/MLQuestions/comments/fdud1p/training_a_neural_network_without_early_stopping/,2,1583439191.0,"Hello Guys, I have a question about training a neural network for more epochs even after the network has converged without using early stopping criterion.

&#x200B;

Consider the MNIST dataset and a LeNet 300-100-10 Dense Fully-Connected architecture, where I have 2 hidden layers having 300 and 100 neurons and an output layer having 10 neurons.

&#x200B;

Now, usually this network takes about 9-11 epochs to train and have a validation accuracy of around 98%.

&#x200B;

My question is, what happens if I train this network for 25 or 30 epochs, without using early stopping criterion?

&#x200B;

Thanks!

&#x200B;

&#x200B;

ANSWERED: If a neural network is trained for more epochs without using an early stopping criterion, the model will overfit to the training data and will perform poorly on validation set as it will ""learn"" the data and also the noises in it. Hence, it is a good idea to use an early stopping criterion to prevent this overfitting from happening!",2020-03-06 01:43:11
The Significant Role of AI in Chatbot Development,1,fdrkb9,https://www.iihglobal.com/blog/role-of-ai-in-chatbot-development/,0,1583420790.0,,2020-03-05 20:36:30
How do you balance object detection data?,8,fdflge,https://www.reddit.com/r/MLQuestions/comments/fdflge/how_do_you_balance_object_detection_data/,2,1583368538.0,When balancing data for object detection training do I count the number of images with at least one label for a specific class or do I count total number of labels for that class? If an image has two labels that are the same does that count as one or two towards balancing for that class?,2020-03-05 06:05:38
Mxnet 1D CNN doesn't work,1,fdo1nx,/r/learnmachinelearning/comments/fdo06e/mxnet_1d_cnn_doesnt_work/,0,1583402831.0,,2020-03-05 15:37:11
What determines the speed of an epoch?,1,fdnl41,https://www.reddit.com/r/MLQuestions/comments/fdnl41/what_determines_the_speed_of_an_epoch/,2,1583400755.0,"other than gpus, what determines the speed of an epoch? lets say i have 190000 images to iterate through per epoch and it currently takes 1 hr to complete an epoch. to increase the speed of training would it be a good idea to increase my steps\_per\_epoch to, lets say.. 2? would doing something something like this be beneficial in any way?",2020-03-05 15:02:35
Louvain clustering on non-graph data,1,fdmvrc,https://www.reddit.com/r/MLQuestions/comments/fdmvrc/louvain_clustering_on_nongraph_data/,0,1583397529.0,Does it make mathematical sense to use graph based algorithms on non-graph data?,2020-03-05 14:08:49
Can I commercially use the ML models in the research papers?,3,fdgddo,https://www.reddit.com/r/MLQuestions/comments/fdgddo/can_i_commercially_use_the_ml_models_in_the/,2,1583371582.0,Do I have to give them credit? Do I need to recreate a new model for me to use it in business?,2020-03-05 06:56:22
Hidden Layers in LSTM,1,fdlid0,https://www.reddit.com/r/MLQuestions/comments/fdlid0/hidden_layers_in_lstm/,2,1583391664.0,I don't understand how the hidden state can be hyperparameter in an LSTM. Shouldn't the hidden parameter be fixed to the number of outputs x number of layers?,2020-03-05 12:31:04
Memory error when working with word embedding and 1 hot encoding,5,fddisa,https://www.reddit.com/r/MLQuestions/comments/fddisa/memory_error_when_working_with_word_embedding_and/,8,1583359784.0,"Hey guys,

I am trying to build a neural network model on a fake news detection dataset. The dataset I am using has 233413 rows and 2 columns.

After splitting it, I am trying to feed it into a 1hot encoder after a label encoder but I am getting a memory error, I tried the same thing with tokenizer and got the same error.

My pc has 32 GB of ram and an i7600k. Is there anything, that I can do to alleviate this problem. Is there a different method or approach to convert the texts into vectors that use less memory.

I also would like to know, If I partition my huge dataset into smaller datasets and build dictionaries on them, can I concatenate the small dictionary onto a big one, if it's possible, how?",2020-03-05 03:39:44
Unity3D ML-Agents on Android,2,fdgt14,https://www.reddit.com/r/MLQuestions/comments/fdgt14/unity3d_mlagents_on_android/,0,1583373267.0,"I want to use mlagents plugin with Unity3D to train my model. Is it possible to run the trained model on a Unity application with Android as target? There's something I need to pay attention while trying to do so?
Thanks a lot for your time",2020-03-05 07:24:27
Help with maybe a simple problem,1,fdiyy2,https://www.reddit.com/r/MLQuestions/comments/fdiyy2/help_with_maybe_a_simple_problem/,1,1583381726.0,"I have a 2D array, where each row is a vector that initialized some complex logic and the rightmost entry in that row is a lable for the output of that logic. How can i identify a new array of initialization vectors that will result in the lables i want?",2020-03-05 09:45:26
Identifying the best player to select given the state of the draft board,1,fdioku,https://www.reddit.com/r/MLQuestions/comments/fdioku/identifying_the_best_player_to_select_given_the/,0,1583380614.0,"The agent will need to make 10 actions throughout the course of a draft, in each action selecting one of hundreds of players. At the time of each action, the board will be in a state where there are 9 other teams who have drafted 10 or fewer players, plus the agents own team. At the end of the season, teams place from 1 to 10 based on total points, and points can be gained from placing higher in roto categories than other teams. There are five categories, things like RBI and HR, so if your team hits a lot of homeruns and gets a lot of RBI, you get a lot of points in that roto category. Im going to calculate end of the year standing based on projections, so ill immediately be able to lable any drafted team's individual roto category points earned as well as their place in the standings overall.

I also have the average draft position for the 700 or so players that could possibly be drafted plus the highest and lowest picks theyve been taken, so i can pretty poorly simulate what each draft might look like. A player with an average draft of position of 20 will only be available by the 30th pick in, say, 1 out of 10 drafts. 

What i have, then, is a dataset of fantasy drafts along with the ranking each team has at the end of the season. 

Im working on a cpu. If you have ideas on how i can simulate drafts better, thatd be great. If you have ideas on how i can train an agent so that the projected standings almost always leave my team on top, please chime in. DeepQ learning seems like it would be an obvious choice but would likely take too long to train. Im considering encoding the state of the draft board, all the teams, who they drafted, and whos still available and then using an lstm or something with a long memory to act on those states. But again, im on a cpu so im looking for the perfect algorithm for this scenario that will train quickly and efficiently. Thanks",2020-03-05 09:26:54
Requesting Guidance for Designing a ChatBot Project Architecture,3,fdbp8k,https://www.reddit.com/r/MLQuestions/comments/fdbp8k/requesting_guidance_for_designing_a_chatbot/,2,1583350345.0,"Hi All,

I am willing to learn advanced text analysis thus planning to build a simple interactive chatbot.

The overall idea is: the chatbot will greet the user first and then ask the user about a topic he/she wants to discuss about..be it game, movie, politics and then the bot and the human will start interaction.

My basic plan is to collect data on various topics and then build a attention model which would be trained with the collected data.

I am kinda novice in this field and in learning stage who has never built an end-to-end project.

Now, this is where I require help:

1. Shall I create train three different models for say three different discussion topics: game, movie and politics?
2. And also for the greeting part..shall all the three above mentioned training data sets have some common greeting data points?
3. And finally, if the above stated approach of training three different models for three diff. topics are correct, how to club them all(as the user can choose any topic to discuss)?

My queries might sound very funny and naive but I would really appreciate if you could guide me to clear my perseption and help coming up with a proper project architecture.

Thanks!",2020-03-05 01:02:25
Multi Label Semantic Segmentation,8,fd6kg8,https://www.reddit.com/r/MLQuestions/comments/fd6kg8/multi_label_semantic_segmentation/,29,1583319871.0," I have 1 input image and 4 corresponding masks that represent 4 different classes. However, each pixel in the image can belong to one or more classes. I don't understand how I can combine this into a single mask to feed it to a network. Any help will be appreciated!",2020-03-04 16:34:31
Parameter count in pytorch resnet50 implementation does not coincide with what the original paper suggests?,1,fddifd,https://www.reddit.com/r/MLQuestions/comments/fddifd/parameter_count_in_pytorch_resnet50/,0,1583359741.0,The parameter count in pytorch:s resnet50 is roughly 25 million but in the original [paper](https://arxiv.org/abs/1512.03385)(table 6) they state that it has about 0.85 million. Am I missing something or what is going on here?,2020-03-05 03:39:01
ML program to fight Corona?,0,fdb9ho,https://www.reddit.com/r/MLQuestions/comments/fdb9ho/ml_program_to_fight_corona/,3,1583347500.0,"I was thinking can there be a program based on ML where we can provide it with blood samples of people suffering from any disease and their respective medicine (basically the ingredients used to fight the virus). Based on that load of data won't it may provide some results that can help?


(I m 17 yrs old,  from small apps dev just shifted to AI/ML but have paused learning for a while due to some reason)
So I m a noob in this, and that can surely sound as a dumb question.",2020-03-05 00:15:00
The Lottery Ticket Hypothesis - number of iterations,1,fdaofw,https://www.reddit.com/r/MLQuestions/comments/fdaofw/the_lottery_ticket_hypothesis_number_of_iterations/,6,1583343517.0,"Hey Guys, I am reading [The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635) By: Jonathan Frankle, Michael Carbin and the following table is taken from the paper:

&#x200B;

&#x200B;

[Figure 2](https://preview.redd.it/gmrgi9lqkmk41.png?width=693&format=png&auto=webp&s=328a7c422de752dc5580e26e714f580b75553d29)

&#x200B;

Now, it's mentioned that the Iterations = 50K for LeNet. How is this number reached at?

number of iterations = (number of training examples) / batch size

MNIST has 70000 images in total and using 60000 images for training and 10000 for testing along with the mentioned batch size = 60, gives the number of iterations:

iterations = 60000 / 60 = 1000

How is the number of iterations = 50K for LeNet? What am I not understanding?

&#x200B;

Also, for CIFAR, there are 60000 images in total and using 50000 images for training and 10000 images for testing along with the batch size = 60, gives the number of iterations:

iterations = 50000 / 60 = 833.33

Again, how does the author state the number of iterations as:

20K for Conv2, 25K for Conv4 and 30K for Conv6?

&#x200B;

Thanks!",2020-03-04 23:08:37
Defining 'unsupervised' learning,2,fd56l4,https://www.reddit.com/r/MLQuestions/comments/fd56l4/defining_unsupervised_learning/,2,1583313649.0,"I was under the impression that neural networks are always considered ""unsupervised learning"". If you are using a neural network on labeled data, is this then considered as ""supervised learning""? 

Thanks!",2020-03-04 14:50:49
Implementing Computer vision papers,10,fcuts0,https://www.reddit.com/r/MLQuestions/comments/fcuts0/implementing_computer_vision_papers/,3,1583272205.0,"I'm trying to improve my skills in computer vision and I found this list on Reddit so I decided to implement those papers but I wanted to know what is the time required and dedication to implement all those. Also, it would be great for someone to provide such a list for RNN's. or other recommendations.

Architectures

* AlexNet: [https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)
* ZFNet: [https://arxiv.org/abs/1311.2901](https://arxiv.org/abs/1311.2901)
* VGG16: [https://arxiv.org/abs/1505.06798](https://arxiv.org/abs/1505.06798)
* ResNet: [https://arxiv.org/abs/1704.06904](https://arxiv.org/abs/1704.06904)
* GoogLeNet: [https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842)
* Inception: [https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)
* Xception: [https://arxiv.org/abs/1610.02357](https://arxiv.org/abs/1610.02357)
* MobileNet: [https://arxiv.org/abs/1704.04861](https://arxiv.org/abs/1704.04861)

Semantic Segmentation

* FCN: [https://arxiv.org/abs/1411.4038](https://arxiv.org/abs/1411.4038)
* SegNet: [https://arxiv.org/abs/1511.00561](https://arxiv.org/abs/1511.00561)
* UNet: [https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597)
* PSPNet: [https://arxiv.org/abs/1612.01105](https://arxiv.org/abs/1612.01105)
* DeepLab: [https://arxiv.org/abs/1606.00915](https://arxiv.org/abs/1606.00915)
* ICNet: [https://arxiv.org/abs/1704.08545](https://arxiv.org/abs/1704.08545)
* ENet: [https://arxiv.org/abs/1606.02147](https://arxiv.org/abs/1606.02147)

Generative adversarial networks

* GAN: [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)
* DCGAN: [https://arxiv.org/abs/1511.06434](https://arxiv.org/abs/1511.06434)
* WGAN: [https://arxiv.org/abs/1701.07875](https://arxiv.org/abs/1701.07875)
* Pix2Pix: [https://arxiv.org/abs/1611.07004](https://arxiv.org/abs/1611.07004)
* CycleGAN: [https://arxiv.org/abs/1703.10593](https://arxiv.org/abs/1703.10593)

Object detection

* RCNN: [https://arxiv.org/abs/1311.2524](https://arxiv.org/abs/1311.2524)
* Fast-RCNN: [https://arxiv.org/abs/1504.08083](https://arxiv.org/abs/1504.08083)
* Faster-RCNN: [https://arxiv.org/abs/1506.01497](https://arxiv.org/abs/1506.01497)
* SSD: [https://arxiv.org/abs/1512.02325](https://arxiv.org/abs/1512.02325)
* YOLO: [https://arxiv.org/abs/1506.02640](https://arxiv.org/abs/1506.02640)
* YOLO9000: [https://arxiv.org/abs/1612.08242](https://arxiv.org/abs/1612.08242)",2020-03-04 03:20:05
Ai Chat Bot Help,3,fczzgx,https://www.reddit.com/r/MLQuestions/comments/fczzgx/ai_chat_bot_help/,1,1583292676.0,"Hello all, first post to any AI-related subreddit so, here it goes.

About a year ago I attempted to make an AI chatbot by following [this guide by Sentdex](https://www.youtube.com/watch?v=dvOnYLDg8_Y&list=PLQVvvaa0QuDdc2k5dwtDTyT9aCja0on8j).  It wasn't very beginner-friendly in retrospect but I was really determined. Then I kind of stopped working on it because I got to the part where the Tensorflow configuration and set up was and maybe it just doesn't like my crappy Nvidia GeForce 950. Or maybe it was because the whole guide was outdated, I'm not really sure.

Anyways  I guess I'm just asking for some guidance from the community. Where should I start when it comes to wanting to make a general-purpose,  just-for-kicks chatbot?

I know python really well and I took AP Calculus back in high school. I'm not the best when it comes to math but I'm sure I'd be able to learn what I  need.",2020-03-04 09:01:16
Conditional attributes in a prediction problem,1,fcxinc,https://www.reddit.com/r/MLQuestions/comments/fcxinc/conditional_attributes_in_a_prediction_problem/,3,1583283336.0,"  

I am trying to implement an algorithm to predict fantasy points of a  player regarding past events. However, I am having some doubts about  some attributes. Imagine that a player is going to play away in the next match, I believe  it is useful to have the points/goals he did in the past away matches  to evaluate how well he performs away from his stadium. However, that  same attribute would not be useful if the next match is at home. The  same with the % of occupation of the stadium - it is important when a  player plays at home but not relevant when he plays away. What is the best approach to this kind of scenario? Do I put the away  goals anyway even when the match is at home?

Regards",2020-03-04 06:25:36
Good size for Transfer Learning datasets,2,fcu8va,https://www.reddit.com/r/MLQuestions/comments/fcu8va/good_size_for_transfer_learning_datasets/,1,1583269355.0,"Hi, I'm a student in computer science and we have to make an app (basically a google Lens clone) that use ML in order to retrieve the nearest classes of the picture the user sent.

Our teacher told us about Transfer Learning and I am trying to make this for an app that recognize a car (make and model).  
Problem is that I'd like to demonstrate how the app works on the parking of our school but the only datasets I find are datasets with cars mainly seen in the US market (ie Stanford Cars Dataset) and not EU market (I'm from France). Of course I could simply use existing ""US-market based"" dataset but this could be a good reason to learn about creating datasets from scratch.

So my question is : what is a good size per class for a dataset in my use case ?  
Stanford Cars Dataset uses approx 80 pics per class but is it enough?

I'm using vgg16 for the base model and adding 2 layers as seen below :  
flat1 = Flatten()(model.outputs)  
class1 = Dense(512, activation='relu')(flat1)  
output = Dense(10, activation='softmax')(class1) # only 10 classes for test purposes",2020-03-04 02:32:35
Advantage of Bayesian Neural Network?,17,fcm20p,https://www.reddit.com/r/MLQuestions/comments/fcm20p/advantage_of_bayesian_neural_network/,7,1583224131.0,"From my understanding the benefit of BNN is to quantity confidence of prediction. I understand why this can be very useful but I am more interested in BNN possibly generalizing better than regular NNs with stuff like batch norm, dropout, and regularization. Do BNNs also generalize better than regular NNs?
My other question is whether BNN produces probabilistic output in that predicting on the same sample twice, might produce a different output? Or is the output just a mean and std?",2020-03-03 13:58:51
random forest ，time prediction,1,fcv1en,https://www.reddit.com/r/MLQuestions/comments/fcv1en/random_forest_time_prediction/,4,1583273189.0,"hello, I would like to predict 'diffsecond'(the last column) by data of timestamp and other strings.i don't know why my timestamp can't be the training data.

safe links of my picture👇
data:
https://tlgur.com/d/gvqzMLQG
code:
https://tlgur.com/d/8nojBe1G
error:
https://tlgur.com/d/Gozay208

I'm an English learner and sorry for the grammar error. thanks!",2020-03-04 03:36:29
Differences between GPU programming and multi-threading?,3,fcnpr1,https://www.reddit.com/r/MLQuestions/comments/fcnpr1/differences_between_gpu_programming_and/,9,1583231564.0,"Hope this isn't a stupid question, but I was just wondering when it's better to use multi-threading with OpenMP vs GPU programming with CUDA? In deep learning, CUDA and GPUs are used. I believe it's because programming in Python is alot easier than C++. If that's the case, then why not use multithreading in Python instead of CUDA?

If it's because CUDA/GPUs are alot faster than multithreading, then is it for C++ code, programmers use multithreading or parallel programming instead of GPUs? Is it just because OpenMP is alot easier to code than CUDA?",2020-03-03 16:02:44
ML LAPTOP,1,fcs0yg,https://www.reddit.com/r/MLQuestions/comments/fcs0yg/ml_laptop/,3,1583255572.0,"Which laptop should I choose for machine learning, Acer Predator Helios 300 (i5 9th gen+gtx1660ti) or Acer Predator Trition 300 (i7 9th Gen+GTX1650)?",2020-03-03 22:42:52
Mean Squared Error Question,1,fcrxo3,https://www.reddit.com/r/MLQuestions/comments/fcrxo3/mean_squared_error_question/,2,1583254903.0,"I’m using pandas with sklearn and I’m trying to run KNeighborsRegressor.

For the first part I was supposed to do it for k=1 for the training set and then for part 2, it is asking me to select best k based on mean squared error using the validation set.
I am just double checking that I am understanding this correctly - the best k is the one that results in the smallest mean squared error, correct?",2020-03-03 22:31:43
Adding random noise to latent representation increase the accuracy in the autoencoder,14,fcepfw,https://www.reddit.com/r/MLQuestions/comments/fcepfw/adding_random_noise_to_latent_representation/,2,1583195785.0,"Hello, I am working on an autoencoder project, it consists of dense layers like this :

dense (\[10, 756\] )--> dense ( \[10, 512\] ) --> latent ( \[ 10, 256\] ) --> dense ( \[10, 512\] ) --> dense (\[10, 756\])

This is a very simple setup, and training it with mean square error loss i am getting accuracy \~0.79

I thought to experiment with variational autoencoder but it didn't work out well on this problem, But the strange thing is if I am adding noise in latent representation, it actually increases the accuracy to \~ 0.85

Adding noise in latent then setup is

dense (\[10, 756\] )--> dense ( \[10, 512\] ) --> latent ( \[ 10, 256\] ) + random\_normal(\[ 10, 256\] ) --> dense ( \[10, 512\] ) --> dense (\[10, 756\])

It's giving good accuracy but I want to know the theory behind it, I thought it's denoising auto-encoder but since in denosing auto-encoder we add noise in input samples not in latent space so we can't say it's denosing auto-encoder. How should I explain why it's increasing the accuracy.",2020-03-03 06:06:25
How Machine Learning Algorithms Works? A 7-Step Model,1,fcq4do,http://brainstormingbox.org/how-machine-learning-algorithms-works-a-7-step-model/,0,1583243378.0,,2020-03-03 19:19:38
Louvain clustering,2,fcl6yg,https://www.reddit.com/r/MLQuestions/comments/fcl6yg/louvain_clustering/,1,1583220554.0,Does anyone have any information on this? How does louvain clustering differ from k means? Thanks!,2020-03-03 12:59:14
[D] : Error analysis of Different Machine learning algorithms?,1,fcmh9k,https://www.reddit.com/r/MLQuestions/comments/fcmh9k/d_error_analysis_of_different_machine_learning/,0,1583225999.0,"Hello, I experimented with different deep learning architectures with different word embeddings for text classification.  From the results, how a good error analysis can be done. What does it mean? Can you anyone suggest some papers related to error analysis of the machine learning models or give some idea of how to explain? I am new to machine learning please help me.",2020-03-03 14:29:59
"Does Normalizing a dataset, improve the ML algorithm accuracies?",2,fci4pz,https://www.reddit.com/r/MLQuestions/comments/fci4pz/does_normalizing_a_dataset_improve_the_ml/,4,1583208739.0,"Well, I’ve read: when applying ML, in a dataset with features with different ranges, the best would be to Normalize the data.
is that true?

I used the technique in a Random Forest Algorithm but my accuracy with and without the normalization was the same. 

I’m wondering if normalizing the data ever helps the training!",2020-03-03 09:42:19
Question about DL Architecture for a Biological Image Generation Project,2,fch6es,https://www.reddit.com/r/MLQuestions/comments/fch6es/question_about_dl_architecture_for_a_biological/,1,1583205119.0," 

I'm relatively new to coding but am starting work on a biological research project that aims to utilize a neural network to perform predictive modelling of a molecular structure.

Basically, we have 10,000 images of a given part of the cell. Each of these images can be converted to only show red channel, or green channel images. To clarify, the images themselves are grayscale, but we can selectively choose to only view proteins that would show up with a green dye and show up only with a red dye. These proteins are part of the same biological structure and should be correlated in their position in the image frame.

I'd like to create a network that takes in green channel protein images and generates red channel protein images. I'm unsure what architecture to use for this project. This was my preliminary idea, using a WGAN-GP:

Green Channel Images, and signal noise ----> Generated Red Channel Images ----> Critic

The critic would compare the generated red channel image with the paired, ground truth images, which are known to be correct. The error would then be sent back to refine the generator.",2020-03-03 08:41:59
How to build a YOLOv3 model using Keras?,1,fcinby,https://www.reddit.com/r/MLQuestions/comments/fcinby/how_to_build_a_yolov3_model_using_keras/,2,1583210697.0,"Hi!
First of all, I’d like to mention that I’m new to the Deep Learning world. And I’ve been given a task for building an object detection model(one class). I’ve been reading a lot about YOLO model lately. So I kinda understand it conceptually but I’d have to implement it in a code. I have no clue as to how to go about this. I’ve been researching a lot about it lately but it’s so confusing. 
I have only 35 classified images for training the model. I know it’s too less but I just want to build some object detection model with some accuracy(doesn’t have to be high) as POC for the project proposal and the client will provide more classified images. And then I can work on bettering it. I’d really appreciate if someone can guide me on preparing the dataset and then to train the model or maybe point to some resources. Do I have to manually create bounding boxes for all classified images and annotate them? If yes, then what tool/website should I use?",2020-03-03 10:14:57
Counting with computer vision: How hard is this?,7,fc9vmc,https://www.reddit.com/r/MLQuestions/comments/fc9vmc/counting_with_computer_vision_how_hard_is_this/,19,1583171800.0,"I have a problem that I *think* would be easily solved with computer vision. The problem is, I am not actually a programmer. I can do some *really basic* Python, but nothing more. But this seems pretty easy, and I know there are plenty of Python tools for ML, so I want to get a sense of how hard this problem will be.

I am trying to build a part counting machine, inspired by the machine shown [here.](https://www.youtube.com/watch?v=r7ZmXTTQmEo) These are the basic requirements:

* Count objects moving in a fixed, known direction across a contrasting background.
* In the initial version at least, there is no need to differentiate between different objects, only to count the discrete objects passing through the field. 
* The speed can be controlled so that only a single object *should* normally be in the counting range at any given time, though ideally the software will be forgiving enough to be able to recognize multiple objects in frame at once.
* Objects may be arbitrarily shaped, but will vary from ~5mm (<.25"") across to around 35mm. 
* Only a single type of object will be running at any time, but ideally the machine should not need to be told in advance what type of part it is counting at any given time. That said, if it would substantially increase the accuracy, I can select the specific part being counted in advance. 
* Under counts are acceptable, over counts are not (ie reporting a count of 100 when 102 tiny objects passed through the detector is ok. Reporting 100 when only 98 went through is not. Larger objects should still never over count, but the under count rate should be closer to 1-2 per thousand on larger parts.) (IOW False negatives are fine, though they should be less common with larger objects, regardless of the shape. False positive are never OK.)

I know machine learning is a challenging field, but this seems like it should be-- relatively at least-- a pretty easy problem to solve. Am I off base at all? Is this something that a not terribly bright, entry level Python programmer has any hope of implementing?

I am planning on running this on  Pi 4 if that limits the implementation at all.",2020-03-02 23:26:40
Batch vs layer vs instance normalization,1,fci0jd,https://www.reddit.com/r/MLQuestions/comments/fci0jd/batch_vs_layer_vs_instance_normalization/,0,1583208321.0,"Hi, 

Given a tensor of shape Batch size x Channels x features like this  (4x2x3) :

`x = np.array([ [[1,3,2],`  
                `[1,2,3]],`  
                `[[3,3,2],`  
                `[2,4,4]],`  
                `[[4,2,2],`  
                `[1,2,4]],`  
                `[[3,3,2],`  
                `[3,3,2]] ] )`

I need to compute the batch, layer, and instance mean and std.

For the batch mean I added everything up and divided by 4, but I'm having a hard time understanding how I would do it for the layer and instance. Is it the same for layer, but instead I divide by 3 (the number of features) ?

I don't really understand, thank you for your help!",2020-03-03 09:35:21
Semi supervised Bounding box,1,fchtq6,https://www.reddit.com/r/MLQuestions/comments/fchtq6/semi_supervised_bounding_box/,0,1583207623.0,"I am trying to build a Model that can detect somewhere around 100 separate items in a controlled environment (I am taking the photos and the program will run model will run in the same environment).  Some of the items are incredibly similar.  

My question is.  Can i create a data set of somewhere around 100 with bounding boxes on label then add 4000 more images of just that item with the same solid color background and have it try to make its own boxes that i can double check and create a much more powerful data-set?  So when combined with the other items its not confusing the labels?

Any other suggestions on how to get a good results for object detection of a lot of items again in a controlled space with lighting and solid color background?",2020-03-03 09:23:43
Halp!! how do I make my input/weight matricies,1,fcgdqk,https://www.reddit.com/r/MLQuestions/comments/fcgdqk/halp_how_do_i_make_my_inputweight_matricies/,1,1583202174.0,"I'm trying to make a neural-network directly in and IDE(I'm using Xcode playground lol), and right now I'm on the step of organizing the wights and inputs(an array in my program)  to multiply. I was just wondering how to do this, more specifically, how many rows and columns do I use for my list of weights and inputs or are they just a giant vector?

Thanks in advanced (:",2020-03-03 07:52:54
How can I normalize gamestates in order to use with a machine learning library?,2,fcctog,https://www.reddit.com/r/MLQuestions/comments/fcctog/how_can_i_normalize_gamestates_in_order_to_use/,10,1583188145.0,"I have currently collected 150000 gamestates from playing a Monte Carlo Tree Search AI player against a basic rule based AI at the game of [Castle][1]. The information captured represents the information available to the MCTS player on the start of each of their turn and whether they won the game in the end. They are stored within CVS files.

Example gamestate entry [**HERE**][2].


For example the entry above shows that:

 - **HAND:** MCTS player's hand contains the cards 7,5,4,9,9,9 (suit has been omitted because it has no baring on the game). *(list of cards)*
 - **CASTLE_FU:** MCTS face up cards are 8,2,10 *(list of cards)*
 - **CASTLE_FD_SIZE:** MCTS has 3 cards face down *(int)*
 - **OP_HAND_SIZE:** The opponent has 3 cards in their hand *(int)*
 - **OP_CASTLE_FU:** The opponents face up cards are Jack, Queen, Ace. *(list of cards)*
 - **OP_CASTLE_FD_SIZE:** The opponent has 3 cards face down *(int)*
 - **TOP:** The top of the discard pile is a 4 *(single value)*
 - **DECK_EMPTY:** The deck in which players pick up cards is not empty *(boolean)*
 - **WON:** The MCTS player ended up winning the hand *(boolean)*

I hope to input this data into machine learning algorithms to produce an evaluation function for the MCTS algorithm to use. 

**How can I normalize this data so I can use it in Keras/Scikit-Learn?**

EDIT: 

Would [this](https://i.stack.imgur.com/4OxWa.png) work?
  [1]: https://en.wikipedia.org/wiki/Castle_(card_game)
  [2]: https://i.stack.imgur.com/iym6J.png",2020-03-03 03:59:05
Is it possible to use multiple ways of learning for ONE model ?,1,fcds52,https://www.reddit.com/r/MLQuestions/comments/fcds52/is_it_possible_to_use_multiple_ways_of_learning/,1,1583192165.0,"I'm working on a reinforcement learning project at the moment and the start is always really random. I wondered if there was ways to start the training with some examples and then begin the reinforcement.
Any information about it ?",2020-03-03 05:06:05
Automatic De-identification tool for Echo cardiogram images (CAMUS Data set).,1,fcc65t,https://www.reddit.com/r/MLQuestions/comments/fcc65t/automatic_deidentification_tool_for_echo/,0,1583185034.0,"Is there any tool that can help me with de-identification of echo-cardiogram image.

https://preview.redd.it/cmkwkcns99k41.jpg?width=806&format=pjpg&auto=webp&s=dcb32e614734eb1dc3dffa01c0c519d6f612ee1f",2020-03-03 03:07:14
How relatable is AN unsupervised learning algorithm?,1,fcau0i,https://www.reddit.com/r/MLQuestions/comments/fcau0i/how_relatable_is_an_unsupervised_learning/,3,1583178000.0,"Hi everybody,

today i was working on topic modeling using BERT word embedding. I used a k-means clustering to establish 10 cluster and organize my corpus into this 10 topics.

At the end i asked myself: ""how relatable is this subdivision? How can i express it? "" 
I thought about the cost value but it strongly depends on input data and doesnt really help me out because it is a plain number and it doesnt lead to a real interpretation.

Any hints?",2020-03-03 01:10:00
[D] How to plot classification results versus confidence scores of the classifiers,2,fc7nkf,https://www.reddit.com/r/MLQuestions/comments/fc7nkf/d_how_to_plot_classification_results_versus/,3,1583157637.0," How to plot classification results versus confidence scores of the classifiers. What does it mean? Whether it  could be useful to assess the best available classification performances (likely obtained for high confidence scores), especially for those experimental scenarios that yielded unsatisfactory results?  Can someone explain it?",2020-03-02 19:30:37
Need help improving my code [Help],1,fc7ynp,https://www.reddit.com/r/MLQuestions/comments/fc7ynp/need_help_improving_my_code_help/,0,1583159385.0,"Hi there,

I am trying to create a real time human detection model based on received signal strength indicator.

this is a representation of the data collected, every 4 rows represents 1 complete sampling as there are 4 masters and 8 slave nodes communicating. In every collection, there are 50 samples collected.

[data collected](https://preview.redd.it/0vg87vr6e7k41.png?width=846&format=png&auto=webp&s=868afc09d8233cb8f6dc6638e1a27db5d623d44d)

&#x200B;

[processing of data](https://preview.redd.it/6j80j4fld7k41.png?width=557&format=png&auto=webp&s=4baed407ae37a7657f41c66977ecfbfffb49fe1a)

&#x200B;

[training](https://preview.redd.it/jo9mi5poe7k41.png?width=616&format=png&auto=webp&s=62070e056c0c489de3c8922bfd936a18c796c995)

I am trying to attach a XY coordinate to the data collected from that location within the setup. However, I am not sure if I doing it correctly and hence I am looking for someone who can advise me in improving the existing code. Please do contact me if you are willing to spare some time. Please do tell me if you require any further details.

&#x200B;

Regards.",2020-03-02 19:59:45
Should I Get AMD 2920x (instead of 3900x) and 2080 XC2 11 GB (Not Ti)?,1,fc6w4i,https://www.reddit.com/r/MLQuestions/comments/fc6w4i/should_i_get_amd_2920x_instead_of_3900x_and_2080/,6,1583153496.0,"I am about to order the parts on 3/3/20. I am just hoping to get some suggestions. I appreciate your help!

I am mostly wondering if AMD 2920x and RTX 2080 XC2 11 GB (Not Ti) would be good choices.

Someone suggested I should get 3900x or 3700x instead, but I saw threadripper meantioned most often in DL-desktop-DIY posts...

&#x200B;

(My other parts just as a reference:

Qty ................................................Item Description................................................ ....Unit.... Extension

&#x200B;

1. AMD 2920X 12 CORE 24 THREAD THREADRIPPER CPU, 4.3GHZ BOOST 499.99 499.99 CLOCCK\*Special Order Parts are Non-Returnable\*
2. H115I HYDRO SERIES LIQUID CPU COOLER QUIET 2X140MM FAN F/INTEL AMD 159.00 159.00 CORSAIR
3. 2 x 16GB 3200MHz DDR4 DIMM Memory Module UNBUFFERED 129.00 258.00
4. PRIME X399 MAINBOARD 64GBMAX 6SATARAID 188.00 188.00
5. 1TB BLACK SN750 NVME SSD M.2 3400R/2900W WESTERN DIGITAL S/N: 169.00 169.00
6. CARBIDE 100R ATX CASE 2X5.25EXT WINDOW NO PSU CORSAIR 63.00 63.00
7. 750W ATX12V EPS12V 80PLUS GOLD GF1 LOW NOISE UL FCCB 5YR WARRANTY 119.00 119.00 THERMALTAKE
8. RTX2080 XC2 ULTRA GAMING 11GB DVI-D+2DP+HDMI 2SLOTS EVGA 797.00 797.00
9. (Having a computer store assemble it since I don't know much about hardware) System Assembly and Burn-In 120.00 120.00
10. One Year In-Store Warranty on Parts & Labor (System Only:Does not include external devices such as Printer or Monitor).

&#x200B;

Subtotal 2,372.99

Sales Tax 135.18

Quote Total 2,508.17)",2020-03-02 18:21:36
Basic result-oriented machine learning steps?,6,fby0ja,/r/learnmachinelearning/comments/fbxxrk/basic_resultoriented_machine_learning_steps/,1,1583115264.0,,2020-03-02 07:44:24
Question about RandomizedSearchCV.,4,fbuk3o,https://www.reddit.com/r/MLQuestions/comments/fbuk3o/question_about_randomizedsearchcv/,3,1583100759.0,"Trying to find the best parameters for a model using sklearn randomizedsearch cv, but the value of best score it gives as output is lower than the ones that appears in the terminal while it's running.
Is this normal? Can someone explain why is that?",2020-03-02 03:42:39
Question about output in Neural Net,7,fbs82k,https://www.reddit.com/r/MLQuestions/comments/fbs82k/question_about_output_in_neural_net/,11,1583086968.0,"So I made a simulation in python that runs though a combat system I made that uses the specified stats below and gives the win-rate.

Stats | Attack Mod(/20), Dexterity(/20), AC(/20), Defense Mod(/20), Weapon Mod(/50), Inflict Mod(/50), threshold(100)   


The issue is that in order to simulate the amount I need to to get the data I want is un-doable. (I would have to simulate it an amount of time that requires scientific notation on a calculator) So to fix this issue i'm going to try to make my first Neural network and train it by using the simulations. 

I've been wanting to lean how to program neural networks for a while and understand how they work. I manly need to dive deeper in to the math behind NNs and how to translate that to code. 

The question is because I need a win-rate in a percent forum as the output do I need a lot of output nodes or do I only need one, or am I just thinking about everything wrong? If I were to answer this with my limited knowledge I could just use one but I want to be safe, not sorry.

I came up with the basic neural network blueprint I will be coding please tell me if you see a hole in my understanding with NNs or a foreseen issue with my blueprint. (Obviously the synapses would have weights). Very new to this but also young, I've got time and the willingness to learn so if you would be so kind Reddit, enlighten me. Thanks!!!! 

https://preview.redd.it/qyi7f906f1k41.png?width=1080&format=png&auto=webp&s=4b10a9960096fabd74bf944d04f614e36b604278",2020-03-01 23:52:48
How to improve training accuracy - ECG,1,fbzvcj,/r/learnmachinelearning/comments/fbzssj/how_to_improve_training_accuracy_ecg/,1,1583122499.0,,2020-03-02 09:44:59
Questions on data visualization,1,fbvf9r,https://www.reddit.com/r/MLQuestions/comments/fbvf9r/questions_on_data_visualization/,1,1583104852.0,"1) how is dbscan different from k-means? Apart from the minpts parameter, these seem to be two very similar algorithms.

2) is anyone here familiar with S.O.M. (self organizing maps)? I am trying to understand what is the intended use of this algorithm: data visualization or dimension reduction ? Can this algorithm be used to predict/classify new observations?

Thanks!",2020-03-02 04:50:52
On laptops for ML engineers/researchers,1,fbuh3h,https://www.reddit.com/r/MLQuestions/comments/fbuh3h/on_laptops_for_ml_engineersresearchers/,8,1583100356.0,"Simple question here, are MacBooks popular among ML engineers/specialists/researchers or do other brands such as MSI / ASUS have the upper hand in the normality within the sector??

Thanks",2020-03-02 03:35:56
Play store reviews model at work,2,fbr9pl,https://www.reddit.com/r/MLQuestions/comments/fbr9pl/play_store_reviews_model_at_work/,4,1583080438.0,"# Hello everyone!

I work at a startup in India as an intern. I am new to Reddit and I think a question like this in StackOverflow would be frowned upon. At the same time, I could not find a course that covers these problems in detail. I am a beginner in machine learning. Although I have taken a few courses in ML, I think I need help with real-world data. My boss told me to create a model for sentiment analysis of reviews.

## Background: 

I have knowledge of NumPy, Pandas, Sklearn, and SpaCy. I am also familiar with NLP techniques such as Bag of words, TF-IDF and Word2Vec. I also have an idea regarding stemming, lemmatization and POS tagging. I have some time to look into or learn other techniques.

## Problem Statement:

My task is to classify a sentiment as positive or negative, with a certain confidence k. If k >= 0.6, it is positive or if k <= -0.6, it is negative. However, the document containing confidence -0.6 < k < 0.6 (intermediate confidence level) should be sent to a human, who would then label it as positive, negative or neutral. The model should be updated with the new document. I should also deploy this model using the Flask framework in Python.

The data contains 800 reviews, out of which, only 500 are text-based reviews. The dataset is also pretty imbalanced.

## Questions: 

1. Is this a valid machine learning problem?
2. I don't think the training data is sufficient. Should I add more data? If so, from where?
3. There are a lot of reviews that are duplicates. Should I perform data deduplication? (This may bring down the size of the data even further)
4. What should be my approach towards EDA in text data?
5. Should I store the data in a database?
6. Which model should I use? (Logistic Regression, Random Forest, XGBoost, Neural nets or any other model)
7. How do I update the model with the human-labeled document?

I am open to feedback, suggestions, criticism or advice.

Thanks in advance!",2020-03-01 22:03:58
Mask rcnn mobile android,1,fbskbg,https://www.reddit.com/r/MLQuestions/comments/fbskbg/mask_rcnn_mobile_android/,5,1583089186.0,Do you can implement mask rcnn on Android. Please help me,2020-03-02 00:29:46
[Help] Tensorflow implementation of Google Brain's GAN Cryptography paper,1,fbplp8,https://www.reddit.com/r/MLQuestions/comments/fbplp8/help_tensorflow_implementation_of_google_brains/,0,1583069601.0,"So, I came across this paper called ""Learning to protect communications using adversarial neural cryptography"" a while ago and found a few implementations in Tensorflow and Theano.

But every single one of them implements only the first two sections and skips the 3rd.

Can anyone help me with the Tensorflow code? I wanna try running it.

I've linked the paper and an article and github link of an implementation.

[https://arxiv.org/abs/1610.06918](https://arxiv.org/abs/1610.06918)

[https://github.com/VamshikShetty/adversarial-neural-cryptography-tensorflow](https://github.com/VamshikShetty/adversarial-neural-cryptography-tensorflow)

[https://towardsdatascience.com/life-of-alice-bob-and-eve-with-neural-net-6df0ad1d6077](https://towardsdatascience.com/life-of-alice-bob-and-eve-with-neural-net-6df0ad1d6077)

(More info: In the paper, 1 net (Alice) sends encrypted text and key to a 2nd net (Bob). A 3rd net (Eve) gets only the encrypted text and no key and has to decrypt it. The paper quite clearly mentions how to implement the models and necessary parameters. All this has been implemented many times by different people but the part of the paper in which we alter the models to learn selective encryption (section 3 of the paper) has in my research not been implemented. I also wasn't able to properly understand how exactly the changes were to be made. I would really appreciate it if someone with a better understanding of the subject could provide me with the implementation in code as I am trying to understand the implementation at the moment.)",2020-03-01 19:03:21
Training image caption model,1,fboopu,https://www.reddit.com/r/MLQuestions/comments/fboopu/training_image_caption_model/,0,1583064643.0,Can we train image caption without pre trained model like keras model vgg16 or resnet. Because i read many blogs in that they have used pre trained model. So is it  necessary to use that model because it takes lot of time to load this model when it is deployed.,2020-03-01 17:40:43
Quick Question,1,fbn2nf,https://www.reddit.com/r/MLQuestions/comments/fbn2nf/quick_question/,4,1583056729.0,"I am relatively new to machine learning and I was wondering, for entry level is it more worth to use free cloud options such as Google's COLAB or build my own rig.",2020-03-01 15:28:49
Learn Machine Learning in 6 Hours | Machine Learning | Machine Learning Tutorial,0,fbs1az,https://www.youtube.com/watch?v=O5F8JZMHGd4,0,1583085754.0,,2020-03-01 23:32:34
Struggling with the KITTI 3D object dataset,8,fbcrsn,https://www.reddit.com/r/MLQuestions/comments/fbcrsn/struggling_with_the_kitti_3d_object_dataset/,0,1583013087.0,"Probably a post that most will find silly, but here it goes.

I am using the KITTI 3D Object dataset ([link](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d)) and trying to separately compute 3D bounding boxes of each object in the left image and the right image. I have found various implementations that can predict this using the 2D coordinates and the orientation of the object([example](https://github.com/lzccccc/3d-bounding-box-estimation-for-autonomous-driving)).

Doing this is quite straight forward for the left image because the left image labels are present in the dataset, these contain the 2D coordinates, orientation and other properties. However, I can't figure what would be the best way to go about making the 3D bounding box predictions for the right image since no label information is present. I was thinking of first running a 2D object detection algorithm like YOLOv3 on the right images to get the 2D coordinates for the objects, but that still doesn't allow me to make the 3D predictions because I don't have the orientation.

Any help would be much appreciated.",2020-03-01 03:21:27
Do neural networks forget things like brains do?,4,fbdpeg,https://www.reddit.com/r/MLQuestions/comments/fbdpeg/do_neural_networks_forget_things_like_brains_do/,6,1583017417.0,"The way people learn and forget things means that [the spaced repetition system](https://i.imgur.com/hZzNAVu.png) : [https://en.wikipedia.org/wiki/Spaced\_repetition](https://en.wikipedia.org/wiki/Spaced_repetition) is one of the most effective methods of retaining knowledge.

Is there anything equivalent in Machine Learning or is there any theoretical grounds saying whether this is something a more advanced AI would experience?",2020-03-01 04:33:37
"Project idea suggestion - Game theory, Attention-based deep learning.",3,fbcpbu,https://www.reddit.com/r/MLQuestions/comments/fbcpbu/project_idea_suggestion_game_theory/,2,1583012727.0,"Hi, subreddit

I have been reading quite a lot about the research progress in the domain of attention-based neural networks that were introduced by Google Inc. in their paper titled ""Attention is all you need"".

The concept of introducing attention into neural networks in order to free ourself from a strict context vector being really amazing on one hand, I have been trying to figure out so has to how this concept of attention would aid deep networks which model multi-agent systems in which game-theoretic factors come into play for the network to learn.

I was looking for some direction or a toy example/explanation or even possible previous research done to try to test these concepts together.",2020-03-01 03:15:27
How can I improve the test accuracy of my CNN in PyTorch?,1,fbgm31,https://www.reddit.com/r/MLQuestions/comments/fbgm31/how_can_i_improve_the_test_accuracy_of_my_cnn_in/,0,1583029180.0,"I'm a beginner with PyTorch and ML and I would like to know the techniques and strategies used to improve the network performance on the test dataset.

Currently, I have two network architecture:

1 - ConvNet1

    # experiment 1
    # 3 convolutional layers and 2 linear layers
    class ConvNet1(nn.Module):
        
        def __init__(self, num_classes=10):
            super(ConvNet1, self).__init__()
    
            self.layer1 = nn.Sequential(
                nn.Conv2d(3, 16, kernel_size=3),
                nn.ReLU(),
                nn.MaxPool2d(kernel_size=2),
                nn.Dropout2d(p=0.3))
            
            self.layer2 = nn.Sequential(
                nn.Conv2d(16, 24, kernel_size=4),
                nn.ReLU(),
                nn.MaxPool2d(kernel_size=2),
                nn.Dropout2d(p=0.3))
    
            self.layer3 = nn.Sequential(
                nn.Conv2d(24, 32, kernel_size=4),
                nn.ReLU(),
                nn.MaxPool2d(kernel_size=2),
                nn.Dropout2d(p=0.3))
    
            self.dropout = nn.Dropout2d(p=0.3)
            
            self.fc1 = nn.Linear(32*29*29, 120)
    
            self.relu = nn.ReLU()
    
            self.fc2 = nn.Linear(120, 10)
    
            
        def forward(self, x):
    
            x = self.layer1(x)
    
            x = self.layer2(x)
    
            x = self.layer3(x)
    
            # print(out.shape)
            
            x = x.view(-1, 32*29*29)
    
            x = self.fc1(x)
    
            x = self.relu(x)
    
            x = self.fc2(x)
    
            return x
    
 and

2 - ConvNet2

    # experiment 2
    # 1 convolutional layer and 1 linear layer
    class ConvNet2(nn.Module):
    
        def __init__(self, num_classes=10):
            super(ConvNet2, self).__init__()
    
            self.layer1 = nn.Sequential(
                nn.Conv2d(3, 16, kernel_size=3),
                nn.ReLU(),
                nn.MaxPool2d(kernel_size=2),
                nn.Dropout2d(p=0.3))
    
            self.fc1 = nn.Linear(258064, 120)
    
        def forward(self, x):
            x = self.layer1(x)
    
            x = x.view(-1, 16 * 127 * 127)
    
            x = self.fc1(x)
    
            return x

Surprisingly, the ConvNet2 network performs much better than ConvNet1 even if its architecture is simpler. When I train for 10 epochs, ConvNet1 has 41% accuracy and ConvNet2 has 78%. Not really sure why, though.

What would you do to ConvNet2 (or ConvNet1?) to improve its accuracy?",2020-03-01 07:49:40
Complex event processing using Java or Python,1,fbfqah,https://www.reddit.com/r/MLQuestions/comments/fbfqah/complex_event_processing_using_java_or_python/,1,1583025707.0,I have to perform complex event processing for stock market prediction as part of my project. Which of the above languages would u prefer for it and how would u think should I approach it. Which libraries would u recommend for it?,2020-03-01 06:51:47
"Encoder, Decoder Translation using Cross Entropy loss function in pytorch",1,fben5v,https://www.reddit.com/r/MLQuestions/comments/fben5v/encoder_decoder_translation_using_cross_entropy/,0,1583021367.0,"I have Encoder-Decoder translation model which I am trying to train using a Cross Entropy Loss function.

The source dictionary has 40106 words

The target dictionary has 41274 words

Each individual sentence(i.e example that needs to be translated) has at most 300 words. 

In order to train with cross entropy loss, can I simply build model that learns to 'translate' from a 300 dimensional vector to another 300 dimensional vector, where each component is an index into the source and target dictionaries respectively? 

The cross entropy loss function in PyTorch  requires a categorical distribution (encoded in-one hot style) over all the possible words, hence would it be valid to then map these the output of the model (a 300 dimensional vector)  into a 41274 dimensional one-hot encoding vector and compute the loss?",2020-03-01 05:39:27
Recognizing family trees.,1,fbdl95,/r/learnmachinelearning/comments/fbap7p/recognizing_family_trees/,0,1583016912.0,,2020-03-01 04:25:12
How does convolution work on data with multiple channels?,1,fbdeqk,https://www.reddit.com/r/MLQuestions/comments/fbdeqk/how_does_convolution_work_on_data_with_multiple/,3,1583016061.0,"Let's say I have a 50x50x1 image. I apply a 32 filter convolution layer to it and I end up with data in the shape 50x50x32. But if I use a 50x50x3 image, and apply the same filter, the output is 50x50x32, not 50x50x96 like I would expect.

Are the channels compressed somehow, or does each filter in the convolution layer choose a single channel from the input data to operate on?",2020-03-01 04:11:01
HELP!! Finetuning XLM-R for neural machine translation b/n the same low resource language?,2,fb9zce,https://www.reddit.com/r/MLQuestions/comments/fb9zce/help_finetuning_xlmr_for_neural_machine/,4,1582995832.0," HELP!! I wonder if it is possible to finetune XLM-R for neural machine translation b/n the same low resource language? 

Catalan to Catalan with different grammar 

For example: Input: He sells food(in Catalan)  

Output: Food he sells(in Catalan)",2020-02-29 22:33:52
Love Python,14,fawxj5,https://i.redd.it/9icqjnipuoj41.jpg,13,1582934801.0,,2020-02-29 05:36:41
Why use t-sne?,9,faujm7,https://www.reddit.com/r/MLQuestions/comments/faujm7/why_use_tsne/,5,1582924556.0,"Why is the t-SNE algorithm (https://en.m.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) useful? From what I've read :

- running this algorithm on your data each time can produce a different visual output (i.e. graphical tsne plot).

-furthermore, tuning the preplexity parameter can significantly change the visual output.

- tsne should not be confused with nearest neighbor: distances between points on the visual output should not be confused with similarity or association.

- tsne visual outputs can not be used for outlier detection on existing data, nor can it be used to classify new data. 

- tsne also does not offer any interpretable explanations during visualization.

With all this being said, why is tsne so useful? I could be entirely wrong, but it just seems to provide ""cool"" visual representations of the data - but these representations seem to be unstable and have little use (as listed above). I understand that tsne can take into consideration complex non-linear relationships that PCA fails to do, as well as solve the ""overcrowding"" problem : but these to me do not seem to be a convincing motivation for me to use t-sne for data visualization over PCA.

In short: why should i use tsne for analyzing my data?

I would be interested in hearing your thoughts!",2020-02-29 02:45:56
Tool for generating synthetic data?,1,fb4p8v,https://www.reddit.com/r/MLQuestions/comments/fb4p8v/tool_for_generating_synthetic_data/,2,1582966545.0,Is there any way/trick/tool to generate synthetic data based on an input template?,2020-02-29 14:25:45
Conditionality and GANs,3,fayvjn,https://www.reddit.com/r/MLQuestions/comments/fayvjn/conditionality_and_gans/,1,1582942080.0,"Hi guys,

I've been looking for a better approach for implementing cGANs than concatenating labels to a dataset. It seems that this approach does not promote diversity in generated images, or at the least it could be done better. Are there any approaches you have taken that was helpful in this regard?

All the best,

yo\_dawg97",2020-02-29 07:38:00
Sorting video game levels by difficulty based on the performance of players,2,fb0vc5,https://www.reddit.com/r/MLQuestions/comments/fb0vc5/sorting_video_game_levels_by_difficulty_based_on/,1,1582949844.0,"Hi All!

I'm undertaking a personal statistical/ML project involving a music video game I enjoy, but I'm struggling to find the right method to use or whether it is even possible to do! I'll try to break down the problem as concisely as possible.

**Background of the Game**

The objective of the game is to press a predefined sequence of keys (A.K.A *notes*) in time with the music. The player is scored based on the accuracy of their key presses and are penalised if they miss a key press. If the player misses too many key presses in succession, they run the risk of 'failing' the song. They are given a grade from F to A based on their score despite their pass/fail outcome. (It's similar to the likes of Guitar Hero and Dance Dance Revolution)

**Aim**

I have a dataset that contains the best scores (and whether they passed or failed) of 4,000+ players (of varying ability level) and I intend to use that to sort all the songs in the game from easiest to pass, to hardest to pass.

The game already has a difficulty scale from 1 to 10 but these are allocated subjectively and are often unrepresentative of other songs in the same difficulty level. For example, an 'easy 10' can be easier than a 'hard 8'. 

Ordering all the songs also allows these difficulty levels to be subdivided further (E.g. Lv 8.1, 8.2 etc) which makes things more convenient for those who are wanting to progress more steadily in the game.

Ultimately, I would like to create a predictive model that can give a player a probability of passing a song given their prior scores, but this is very much Phase 2 of this project!

**The Dataset**

I have one table that contains all the player's best scores for all the songs they have played. The key columns of interest are: player\_id | song\_id | has\_passed | score (as a % of the maximum score).

The other table has information regarding the song: song\_id | difficulty\_level (1-10 scale) | num\_notes (the total number of key presses in the song.)

The data in the best\_score's table is somewhat sparse as not every player has played every song. If every player had played every song, we would expect to see \~11.3mill rows. Instead, we have \~1.6mill rows of usable data. Furthermore if I had a complete table, I would have just sorted all the songs by the total number of player who have passed it!

**Caveats**

One thing to bare in mind with the dataset is that weaker players are less likely to attempt harder songs. Similarly, stronger players are less likely to play easier songs, so averaging the pass rate will result in a bias due to the missing data.

It's also important to note that the score a player gets in a song isn't always correlated with the pass rate. For example, a song might be easy but then have a short and very hard final section resulting in a 'fail' but a decent score. (The converse can happen too)

Lastly, the total number of notes in a song is correlated with difficulty but not strictly.

&#x200B;

So that's the problem and I was wondering if anyone has encountered a similar problem or knows where I could start. (Or, indeed, if I'm trying to achieve the impossible!)

Thanks for reading!",2020-02-29 09:47:24
Can you do target encoding for multilabel classification,1,fb2fhq,https://www.reddit.com/r/MLQuestions/comments/fb2fhq/can_you_do_target_encoding_for_multilabel/,0,1582955986.0,"Is there a way to perform target encoding on multi label (closed set) problems, obviously target encoding is used on multi-class problems all the time, but i'm wondering if it works for multi label as well? and if there are any specialized methods for it.

A naive approach would be to create a dataset with duplicate rows but different target variable values, for each label they contain, and then then target encoding on that, but i'm not sure how effective this would be.

Any alternative approach to target encoding is also appreciated, i just want to lessen the mess of having a massive amount of cardinality on my categorical variables.",2020-02-29 11:29:46
Advice needed on object detection project,1,fb27ph,/r/computervision/comments/fb26u5/advice_needed_on_object_detection_project/,0,1582955087.0,,2020-02-29 11:14:47
Kernel Theory / svm,1,fb0s0m,https://www.reddit.com/r/MLQuestions/comments/fb0s0m/kernel_theory_svm/,1,1582949480.0,"Hello! 

I have spent the day researching kernels (in the context of machine learning) and had some questions:

1) frequently, the motivations for kernel projections have been said that it might be possible to find a high dimensional sepperation-boundary within the data at a higher dimensions than the feature space of your data. Why not at a lower space?

2) is there strict mathematical intuition for projecting data into higher dimensions (for ML)? Or is it something trial-and-error (i.e. lets see if this works). I would have imagined you would want data brought ti a lower dimension, not higher.

3) in kernel theory, is it straightforward to take the augmented feature space (in higher dimension) and project it back into lower dimension? Does the kernel  easily allow this? (inverse kernel)

4) in the case of the 2nd degree polynomial kernel:
K(x,y)  =   (1 + x-transpose y) ^d : where d=2
I imagine that in 3 dimensions, d = 3 ?

I have seen the 2 dimensional example expanded:

Assume: x =(x1,y1) and y = (x2,y2)

K(x,y) = 1+2(x1y1) + 2(x2y2) + 2(x2y2x1y1) + (x1y1)^2 +(x2y2)^2

In this case: x,y are variables and[( x1,x2 ), (y1,y2)] are the observation values?

Similarly, one could evaluate k(x,y,z) with x1,x2,...z1, z2?
How would the the form change of 
K(x,y)  =   (1 + x-transpose y) ^d  for k(x, y,z)?

5) how does the rbf kernel k(x,y) change for k(x,y,z)?
Rbf: K(x,y) = e ^ (-gamma || x - y || ^2)
im confused how to adapt this equation for 3 dimensions?

6) is it important to analytically know the form(equation) of the form of the decision surface (both in the original and augmented feature space)? Does python store these equations?

7) in the example of the two dimensional polynomial kernel 

K(x,y) = 1+2(x1y1) + 2(x2y2) + 2(x2y2x1y1) + (x1y1)^2 +(x2y2)^2

The original feature space of 2 dimensions gets projected into 6. So original data (x1, y1,x2,y2) = (1,2, 0,0) would take values on each new axis:

2(x1y1) = 4
2(x2,y2) =0 
2(x2y2) = 0 
Etc?

Thanks!",2020-02-29 09:41:20
Template for bayesian optimisation in Pytorch,2,favbzv,https://www.reddit.com/r/MLQuestions/comments/favbzv/template_for_bayesian_optimisation_in_pytorch/,1,1582928212.0,"Hi,

Does any one have a template on how you chose the best parameters using BO in Pytorch for a model ?

So far I have used ax([https://github.com/facebook/Ax/blob/master/tutorials/tune\_cnn.ipynb](https://github.com/facebook/Ax/blob/master/tutorials/tune_cnn.ipynb)) from facebook but I still have some hard time for eg. when I need to put the type of the parameters. 

What are you guys using ?",2020-02-29 03:46:52
Forming a path of neurons that have contributed to the final output,1,fawi6p,https://www.reddit.com/r/MLQuestions/comments/fawi6p/forming_a_path_of_neurons_that_have_contributed/,2,1582933150.0,"Hello,


I have a pretrained fully connected neural network with 6 layers. The output of the last layer is an one-hot vector of 10 elements, pointing out the predicted class for a mnist sample. So in this layer, only one neuron is active. Let's name this neuron n.



How can I find which set of neurons of the previous layer has contributed for neuron n to fire in the last layer? And how can I find these sets of neurons for all the layers of the network so that I can form a path of the ""important neurons""?


Thank you!",2020-02-29 05:09:10
How do time series problems predict for a future date when the only features are the date and the target variable??,1,fatb5t,https://www.reddit.com/r/MLQuestions/comments/fatb5t/how_do_time_series_problems_predict_for_a_future/,2,1582917920.0,Is any kinda learning being achieved in this process? Where is ML part coming?,2020-02-29 00:55:20
"Is it possible to jump into ""using"" ML without learning ML?",4,fapr9w,https://www.reddit.com/r/MLQuestions/comments/fapr9w/is_it_possible_to_jump_into_using_ml_without/,36,1582896221.0,"Hello,

I've been trying to learn ML for a while (Andrew Ng's course ""Machine Learning"" on Coursera and Siraj Raval's videos and some podcasts), but because of various reasons, I can't devote enough time and energy to sustain my learning (I'm talking gaps of days-weeks between learning). I know others have done it but it's not working out for me.  

What did work for me was watching a ""Two Minutes Papers"" video on AI which learned to play hide-and-seek and then broke the game. I still remember it after a few months of watching it. 

So I was wondering if I could learn ML by playing around with it - just run open-source code which has already been explained and play around with it. That way I'll remember more of what I learned because I've been actively using it and can think about what the outcome will be if I change some input, even if I can't sit down and use my computer. 

Is this possible and is there a resource for it?

Edit: I've decided to pursue more CS and ML theory before I jump in. However, I found this and maybe it'll help someone else:  https://machinelearningmastery.com/machine-learning-in-python-step-by-step/",2020-02-28 18:53:41
Loss and accuracy start random and stay random?,3,faoi30,https://www.reddit.com/r/MLQuestions/comments/faoi30/loss_and_accuracy_start_random_and_stay_random/,4,1582889993.0,"I'm sure it's a simple fix but what are some of the reason why if I have two classes and 10 features, when I run a simple FNN network in keras It starts out acc = 0.5 and basically stays that way.

I believe the data is correct and I have normalized and standardized on top of reducing my learning rate. Any ideas?",2020-02-28 17:09:53
tf.contrib with tensorflow 2.0,1,fasa8x,https://www.reddit.com/r/MLQuestions/comments/fasa8x/tfcontrib_with_tensorflow_20/,0,1582911367.0," 

Hello there, i try to predict stock trading and I found a tuto who use LSTM to predict stock trading.

\-> 

Unfortunately, that was with tensorflow1.14. So tf.contrib is no more with tf 2.0

Apparently we can use a script to upgrade our TF 1.x code to TF 2.x but some people say that doesn't work for tf.contrib.

Also we can use :

    import tensorflow.compat.v1 as tf tf.disable_v2_behavior() 

But in the doc, they say ""work for everythings EXCEPT contrib"".

So I can't figure out how to fix this problem.

I try to uninstall tf and reinstall 1.14 but that doesn't work either.

Any advices ?",2020-02-28 23:06:07
Can basic ML algorithms spot relative differences/asymmetries?,1,faruvj,https://www.reddit.com/r/MLQuestions/comments/faruvj/can_basic_ml_algorithms_spot_relative/,1,1582908651.0,"Hi all,

I'm doing an ML project on medical imaging data, specifically of the brain of Parkinson's Disease patients. The task is to spot relative differences between the two hemispheres of the brain. Namely, given the input data we want the algorithm to output which hemisphere shows more signs of degeneration - the left or the right.

I thought of defining two classes: 1. Right side more damaged, 2. Left side more damaged, and using logistic regression with the labeled dataset to train the classifier (we can process the labels to reflect the 2 classes I suggested). However, I'm not sure whether the algorithm can learn to spot relative differences within the same training example, and how one training example will affect the next regarding finding the optimal weights

Does anyone have any experience with problems like this one?
Thanks",2020-02-28 22:20:51
introductory textbooks,8,fag96q,https://www.reddit.com/r/MLQuestions/comments/fag96q/introductory_textbooks/,9,1582856121.0,"Hi!

I'm looking for any good introductory textbooks (or just books) on the topic of machine learning and AI. Math shouldn't be a problem (I am a math student - but some overly specific ML jargon may...) Something that'll blow my mind. :)

Also, it'll be great if it's purchasable online. 

Thanks y'all :)",2020-02-28 07:45:21
Any industry oriented ML summer schools in Europe?,3,fajmw8,https://www.reddit.com/r/MLQuestions/comments/fajmw8/any_industry_oriented_ml_summer_schools_in_europe/,3,1582868996.0,"Hey!

As a machine learning engineer, I have a yearly budget to spend on sharpening my ML skills. Usually, we go to conferences. 

This year, I was thinking of splitting my budget, and use the other half to actually advance my practical ML knowledge, in the context of hands-on sessions e.g. some summer school, a (conference) workshop, etc. 

I have already checked that there's quite a variety of summer schools to choose from. Most of them seem to be research focused though. I was wondering, are there any European (preferably, could be U.S. as well) ML summer schools that would be industry oriented? I am interested in the full cycle of ML - data and feature engineering, modelling, productionizing models.

Thanks!",2020-02-28 11:19:56
Difference between Multi-Hop Paragraph Retrieval and Single Paragraph Retrieval Question Answering,3,fah5td,https://www.reddit.com/r/MLQuestions/comments/fah5td/difference_between_multihop_paragraph_retrieval/,0,1582859589.0,"Hello,

Recently I have been different papers on **Multi-Hop Paragraph Retrieval for Open Domain Question Answering** ([this](https://www.aclweb.org/anthology/P19-1222.pdf) one for example).  
My point is, why cannot we just simple combine the different paragraphs into a single one and run the **Single Paragraph Retrieval Open Domain Question Answering.**  
My first intuition is the accuracy will be very low but isn't it actually the fault of the Neural Architecture rather than the approach?  
Some insights or pointers to useful links will be great and appreciated.",2020-02-28 08:43:09
Locating coordinates of object in image,1,fakj1b,https://www.reddit.com/r/MLQuestions/comments/fakj1b/locating_coordinates_of_object_in_image/,0,1582872532.0,"My project partners and I are working on a project. We want to stream video of a user, where they hold their hand up, and track where their finger is. Using the location of the finger, as it moves, we want to move the mouse around the screen in relation to it. I'm trying to figure out if finding the location comes from the mask/kernel during convolution, or sometime else?",2020-02-28 12:18:52
Pothole detection using CNN,3,fagps2,https://www.reddit.com/r/MLQuestions/comments/fagps2/pothole_detection_using_cnn/,0,1582857857.0,I am interested in getting paper recommendations on recent detailed research conducted on detection of potholes using machine learning techniques,2020-02-28 08:14:17
Time series symbolization,4,faancs,https://www.reddit.com/r/MLQuestions/comments/faancs/time_series_symbolization/,1,1582831263.0,"Hi, someone can suggest some time series symbolization techinques implemented in python? I already found PAA, SAX, ESAX, 1d-SAX.",2020-02-28 00:51:03
Traffic Accident Prediction,2,fac9kt,https://www.reddit.com/r/MLQuestions/comments/fac9kt/traffic_accident_prediction/,4,1582839812.0,"I was given a dataset to predict a road accident. The problem is data only have positive examples. There's is no information about no accident which means I have a one-class problem.

What are the possible ways to model this problem?",2020-02-28 03:13:32
Lack of accuracy for my open market price forecasting,2,fabu4w,https://www.reddit.com/r/MLQuestions/comments/fabu4w/lack_of_accuracy_for_my_open_market_price/,6,1582837706.0," I'm trying to solve a problem to train my skill. I've daily data (each day during 10 years,2010 to 2020, except saturday and sunday). I would like to predict like ten day after my data end.

Problem is my model are atrocious. I tried xgboost, svm and Prophet for now.

I think the problem is : I always worked on monthly data, and with monthly it's far easier to detect seasonality and so on. With daily data I'm kind of lost.

I thought : ""Why not transform into monthly instead of daily ?"" But how to predict only few days with monthly ? I don't think it's possible.

So if you have some tips to improve my work with daily data, I'll be very grateful. I'm quite new so any hel would be appreciated.

Thanks. :)",2020-02-28 02:38:26
"Stumped by scaling variables in multivariate, multistep time series prediction with LSTMs",6,fa7sxk,https://www.reddit.com/r/MLQuestions/comments/fa7sxk/stumped_by_scaling_variables_in_multivariate/,7,1582813114.0,"I have a working implementation of a multivariate, multistep time series prediction using LSTMs in Keras. I want to extend it by adding more variables but need to scale the data as the new features are of a different magnitude. Therefore, I tried to take my working implementation, scale all the variables (although it's not necessary) and then train and make predictions. That all works but now I'm pulling my hair out trying to understand how I get the prediction (yhat), input (X\_test) and target (y\_test) back into the right shape to use the `inverse_transform` function. All the details are [here.](https://github.com/mintgreenstrat/SO_LSTM/tree/master) 

The shape of the array when I performed the `MinMaxScaler()` was (2456, 154). That's built from 4 features, 30 timesteps back and 30 timesteps forward for one of the features. Ie. (4 x 30) + (1 x 30) + 4 = 154. The shape of the output prediction (yhat\[0\] = (30,)). The shape of X\_test\[0\] = (30,4).

If I'm not mistaken the `inverse_transform` class is looking for an array of the same shape to when it was scaled. It's obviously not getting that in my code but I don't understand how I'd get back to that....

Any help to point me back in the right direction is highly appreciated.",2020-02-27 19:48:34
My NEAT system is not learning the comparison I want it to learn,2,fab9az,https://www.reddit.com/r/MLQuestions/comments/fab9az/my_neat_system_is_not_learning_the_comparison_i/,12,1582834730.0,"Hi all,

as a first foray in ML, I developed a simple flappy bird NEAT system, but I cant get it to learn something a bit smarter than just following the next pipe height.

[Imgur](https://i.imgur.com/aDEY6NX.png ""the game"")

The bird is not completely on the left, but the pipes exit on the left of the screen. I give the 2 leftmost pipes to as inputs to the bird, and I would like it to learn to look at the pipe that's ahead of it, not behind. I think it can be done with a couple hidden nodes and a few links to the bias, but my bird never discovered the structure.

To try to help the slow learner I decided to change a bit the pipe generation algorithm, the pipes are initially far appart (so the bird learns to look at the first pipe), and they get closer and closer over time, to a point where they need to look at the other pipe before the previous has disappeared. But it stills doesn't look at the second pipe.

I suspect that the issue is the transition to needing to look at the second pipe is not ""smooth"" enough, but I don't know clue the bird in about the second pipe more smoothly.

Any help is welcome.

the game is here: [https://nraynaud.github.io/nraygame/](https://nraynaud.github.io/nraygame/) the code is here: [https://github.com/nraynaud/nraygame](https://github.com/nraynaud/nraygame)

thanks you for your help.",2020-02-28 01:48:50
How do I approach this problem?,0,fae6fx,/r/learnmachinelearning/comments/fae63l/i_have_a_dataset_that_quantify_data_from_2013/,5,1582848008.0,,2020-02-28 05:30:08
Comparing ML model performance,2,faaky6,https://www.reddit.com/r/MLQuestions/comments/faaky6/comparing_ml_model_performance/,3,1582830872.0,"Hello all, 

&#x200B;

I have a question on comparing performance of ML models. I am using same dataset to train/test various ML algorithms (regression, Boosted Trees, SVM, neural network). The aim is to compare their individual performance. I am aware that \_the model selection depends on the question being asked\_ and that various models will perform differently based on dataset, however, in this instance, it is an academic exercise. 

&#x200B;

Any help in how can I compare model performance would be very much appreciated. What kind of metrics I can use? So far I have 

&#x200B;

1. ROC/AUC - with both is advantages/disadvantages 

2. hmeasure ([http://web.cs.iastate.edu/\~cs573x/Notes/hand-article.pdf](http://web.cs.iastate.edu/~cs573x/Notes/hand-article.pdf))

3. Brier Score ([https://en.wikipedia.org/wiki/Brier\_score](https://en.wikipedia.org/wiki/Brier_score))

4. KS stats ([https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov\_test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test))

&#x200B;

Thanks

S",2020-02-28 00:44:32
Confused on comparing policies.. How ? (Reinforcement Learning),8,fa3yvo,https://www.reddit.com/r/MLQuestions/comments/fa3yvo/confused_on_comparing_policies_how_reinforcement/,5,1582794673.0,"When we talk about comparing different policies(plans) what we do is basically compare the expected reward of a state. Now I'm confused as to how it works. Consider this problem:

Let 'a' be the start state, 'g' be the goal state and 'x' be an intermediate step between 'a' and 'g' such that a -> x -> g

the expected return for each of state be A, X, G( G doesn't matter)

Case 1: suppose according to one policy, reward X at state 'x' is suboptimal. but by the same policy, the maximum of the reward propogates to 'a' (Bad path x-> g, Good path a->x)

Case 2: in another policy, reward X at state 'x' is optimal, but by the same policy, the rewards degrades a lot as it reaches 'a' (Good Path x->g, Bad Path a->x)

In this case, how can we compare which policy is better simply on the basis of expected return/reward.

I don't understand. Please Help.",2020-02-27 14:41:13
AI Chatbots – Business Applications and Frameworks for AI/ML Engineers,1,fa8ac0,https://www.artiba.org/blog/ai-chatbots-business-applications-for-ai-engineers,0,1582815965.0,,2020-02-27 20:36:05
GPU Support For AMD Cards?,2,fa4xpu,https://www.reddit.com/r/MLQuestions/comments/fa4xpu/gpu_support_for_amd_cards/,1,1582798966.0,"My only machines at the moment are:

1. A well-used MacBook Pro (2015)
2. A tower PC with a AMD Radeon HD 7470 1GB GPU  


At the moment I'm trying to study how todo Horses to Zebras with CycleGAN.  


I've got a simpler script that uses GAN to generate output MNIST data look-alikes but my MacBook doesn't seem to like large batch\_sizes so I can't get a very good output after training the module.  


I'm wondering if GPU would fix this problem?  


If so, will the AMD Radeon HD 7470 1GB GPU work with any libraries? Ideally, it'd work with the Google jax / autograd package. But I'm open to other packages.

And how complex is it to use a GPU vs CPU for most common libraries?",2020-02-27 15:52:46
Campaign Analysis,12,f9vayx,https://www.reddit.com/r/MLQuestions/comments/f9vayx/campaign_analysis/,0,1582761433.0,"How to find ROI given the marketing spend, no of impressions and no of clicks on different platforms such as FB, Google etc. I have overall sales data but not sales by platform.

Do I need to build market mix model for this? If yes, how should I go about it?",2020-02-27 05:27:13
how to model slot filling like dialogflow,1,fa4srp,https://www.reddit.com/r/MLQuestions/comments/fa4srp/how_to_model_slot_filling_like_dialogflow/,0,1582798347.0,"I've been banging my head past couple days trying to come up with a model to work my way up to do something like dialogflow, I'm getting stuck. This problem is richer than NER and more structured than automatic QA, because I think there most be some amount of semantic analysis. I have agreed with myself the first step should be intent recognition, which is just classification. But, afterwards, I can't see how to train on detecting slots. Any advice?",2020-02-27 15:42:27
Can I train StyleGan using rectangular images? How about black and white ones?,1,fa29i3,https://www.reddit.com/r/MLQuestions/comments/fa29i3/can_i_train_stylegan_using_rectangular_images_how/,0,1582787506.0,"For instance, can I train StyleGan using a 300x1500 image?  How do I reduce the number of channels to just 1?",2020-02-27 12:41:46
How to modify K-means algorithm to pick a centroid that exists within the original dataset,1,fa1gyq,https://www.reddit.com/r/MLQuestions/comments/fa1gyq/how_to_modify_kmeans_algorithm_to_pick_a_centroid/,4,1582784453.0,"I am looking to modify a typical k-means algorithm to find centroids within my dataset. The naive solution that immediately comes to mind is take the original algorithm which outputs k centroids and find the closest point in the dataset to each centroid and make those the new centroid. I think this won't necessarily achieve my goal. My goal being to find k clusters (defined by k centroids which exist in my dataset) that minimize the overall squared euclidian distance between points in a cluster and their respective centroid. 

I was thinking maybe using k-medians would work but I have heard this is typically used for manhattan distance rather than euclidian.

I am wondering what are some better approaches to this problem?",2020-02-27 11:50:53
Student: ASR (automatic speech recognition) of a certain language (here: Polish) - where to start?,1,f9zk9b,https://www.reddit.com/r/MLQuestions/comments/f9zk9b/student_asr_automatic_speech_recognition_of_a/,1,1582777407.0,"Hello, I am a student and I had to choose a half a year project and I've decided that out of all listed, I'd like to try a task that is ""Voice Recognition of Polish language"" as it seems interesting.

Assumptions:

* possibility to use ready-made open source libraries, e.g. Julius or Kaldi
* teaching acoustic model and language model based on available learning collections
* the possibility of implementing an end-to-end system

Where do I begin? What should I learn beforehand? Of course, it's a student prototype project, so a failure is possible, though unwanted; I will have to document my attempts and research, which is the part of the grade, but seeing as I am really green in the subject and pushed right into the deepwaters, I have to ask: Where to start? What knowledge do I need to have to  even begin to be able to google stuff necassary for it? 

Thank you.",2020-02-27 09:53:27
How are Deepfakes created using GANs ?,5,f9rrru,https://www.reddit.com/r/MLQuestions/comments/f9rrru/how_are_deepfakes_created_using_gans/,8,1582744905.0,"Hello ML Community,

Can someone please help me understand how Deepfakes are created using GANs ?

I understood how GANs work but I can't understand how they are used to create Deepfakes.

Edit : 
A GAN is supposed to generate fake data from random input. A deepfake is generated from a source video and a target video (or images). I want to know where in the GAN are these source and Target data put.

Thanks a lot !",2020-02-27 00:51:45
Looking for advice for a music based project looking at machine learning,1,f9xpro,https://www.reddit.com/r/MLQuestions/comments/f9xpro/looking_for_advice_for_a_music_based_project/,0,1582770555.0,"Hi, I am currently looking to start a music production project for my final degree submission at a music university. I am looking to create an album of music in which both real musicians improvise as well as generating improvisation via machine learning, and intertwining the two. While I have some very basic programming knowledge (understand the core concepts and studied some at school) this is a big step up for me. I am currently looking at using deepjazz (link below) to generate the music, I was wondering if anyone knows of any other already available tools that would allow a machine to read in a midi file and produce similar compositions from it. Any other suggestions of starting points / tools that may help me would be greatly appreciated.

Thanks!

deepjazz: [https://deepjazz.io/](https://deepjazz.io/)",2020-02-27 07:59:15
Advice on Image Processing ML Algorithm for detecting Inliers/Outliers,1,f9wckb,https://www.reddit.com/r/MLQuestions/comments/f9wckb/advice_on_image_processing_ml_algorithm_for/,1,1582765400.0,"Hi guys, I'm a beginner with Data Science, and for my college project wanted to work on implementing machine learning algorithms on Images to see whether certain images are inliers or outliers (based on theme similarities like trees, cars etc). How should I go about implementing this? And what algorithm can I use? I don't have a lot of experience with ML so would realllyyy appreciate some help. Thankssss. 😁",2020-02-27 06:33:20
[Q] Representation dimension with number of classes/labels,2,f9ufb6,https://www.reddit.com/r/MLQuestions/comments/f9ufb6/q_representation_dimension_with_number_of/,0,1582757849.0,"Hi,

I am trying to understand the impact of number of classes on the representation dimension (d) (or model complexity). For instance, if an optimal binary classifier (linear) can be learnt in d dimensions, then how should d change, when we add a second or a third class? Here, the d can be seen as the hidden dimension of a neural network etc. 

Assumptions:  
\[1\] The new classes are independent of first class.  
\[2\] Infinite training data is available.

Thanks!",2020-02-27 04:27:29
"Can someone explain the joke here, please.",26,f9gfhj,https://i.redd.it/d8yfyebxo4j41.jpg,6,1582690716.0,,2020-02-26 09:48:36
"Perturbation in ""How to Escape Saddle Points Efficiently"" (weights) and ""Domain-Adversarial Training of Neural Networks"" (inputs) is well researched. Are there more perturbation theory related to neural-network training?",2,f9o7uz,https://www.reddit.com/r/MLQuestions/comments/f9o7uz/perturbation_in_how_to_escape_saddle_points/,0,1582722885.0,"It seems that perturbation is really a great tool. 

For **adversarial training of a neural-network** (helps avoiding pixel attack, makes network robust etc.) a/c paper [Domain-Adversarial Training of Neural Networks](https://arxiv.org/abs/1505.07818) where the input data is augmented using a perturbation in **input** ***x****,* with [x + ϵ sign(∇x(J))](http://www.freepatentsonline.com/10521718.html); where **∇x(J) is the gradient** of the specified objective function with respect to the training **input x**, **ϵ is a value that is small enough** to be discarded by a sensor or data storage apparatus due to a limited precision of the sensor or data storage apparatus.

And a paper on **escaping Saddle points** efficiently a/c to the paper [How to Escape Saddle Points Efficiently](https://arxiv.org/abs/1703.00887) ([blog version](http://www.offconvex.org/2017/07/19/saddle-efficiency/)) is a perturbation in weights when a certain condition is met over the gradients of the weights for examples, L2 norm less than some constant value *c*. The perturbation is given by **wt←wt+ξt**, where perturbation **ξt** is sampled uniformly from a ball centered at zero with a suitably small radius, and is added to the iterate when the gradient is suitably small. 

&#x200B;

I want to know if there are more perturbation theories in neural-network training. And more broadly how do you think of such ideas which seems very intuitive but not straightforward?",2020-02-26 18:44:45
Applying Transformer on Multiple Inputs in Keras,1,f9mrx5,https://www.reddit.com/r/MLQuestions/comments/f9mrx5/applying_transformer_on_multiple_inputs_in_keras/,0,1582716137.0,"I'm trying to use the transformer in keras, using the keras-transformer library (https://github.com/CyberZHG/keras-transformer).  However, I am having trouble building a keras model that does exactly what I want.  I would like to have an input of multiple sentences, and use the transformer on each sentence individually and get a sentence representation for each (which will later be combined in the model).  I have been using Lambda functions for this so far (for example, each entry is a list of a list of  words, which are then put into an Embedding layer to get a list of a list of embeddings).  However, I am having trouble using the keras-transformer task for this, as the get_encoder() from keras-transformer method requires an input layer.  Are there any tips on how to accomplish this correctly?",2020-02-26 16:52:17
Shrinking a vector of 3d images into a single vector?,1,f9jjcq,https://www.reddit.com/r/MLQuestions/comments/f9jjcq/shrinking_a_vector_of_3d_images_into_a_single/,2,1582702364.0,"Does anyone know how this is done? (Through Keras specifically)

For instance, if I have an input of (10000, 27, 25, 25) = (batch, channel, width, height), how do I iterate through each sample and shrink the (27, 25, 25) into a single value so that after applying the layer, the output is (10000, 1). What convolution techniques allow me to do this properly?",2020-02-26 13:02:44
Best qualifications for Data Science master studies,0,f9jg2t,https://www.reddit.com/r/MLQuestions/comments/f9jg2t/best_qualifications_for_data_science_master/,1,1582701990.0,"i am looking to apply for some masters programe in Data Science, however i have degree in economics and have 0 experience in data science type of jobs. Can you maybe suggest me what types of job experience could improve my chances of getting accepted on programe? :D to know what to lie in my cv :D",2020-02-26 12:56:30
Epochs and machine learning algorithms,10,f981pa,https://www.reddit.com/r/MLQuestions/comments/f981pa/epochs_and_machine_learning_algorithms/,6,1582653569.0,"I'm trying to understand how epochs that are used in Deep Learning algorithms suchs as CNN/RNN are compared to machine learning methods.

As I understand epoch means that you pass the data through the whole algorithm (neural network) once. So many epochs means that data goes over the network many times so that it can be optimized better. 

But I never heard this thing mentioned in models like linear/logitsitc regression, decision trees, svm and other typical ML algorithims. But then those algorithms also use optimization techniques like gradient descent so why there is no such thing as using epochs in those? 

Are those algorithms optimized already after one run? Or are the epochs hardcoded in them already?",2020-02-25 23:29:29
Generative capability and distribution modelling,2,f9cn8k,https://www.reddit.com/r/MLQuestions/comments/f9cn8k/generative_capability_and_distribution_modelling/,1,1582676265.0,"I've been reading up quite a lot on autoencoders and variational inference. VAEs are used to generate data in accordance with the distribution of the training data. I am unable to understand how assuming a uniform distribution of the latent space grants this generative/interpolation capability to the autoencoder.

I guess this question could be generalised to the whole idea of using generative models by learning the probability distribution of the training data. How are they intuitively related?",2020-02-26 05:47:45
Introduction to Machine Learning and Neural Networks,0,f9fhky,https://youtu.be/1W7z1uFv8qQ,0,1582687197.0,,2020-02-26 08:49:57
I want to benchmark NN hyper parameter tuners against each other. Does the data set used really matter?,1,f9eglh,https://www.reddit.com/r/MLQuestions/comments/f9eglh/i_want_to_benchmark_nn_hyper_parameter_tuners/,8,1582683255.0,"I know why specific data sets or architectures are used for bench marking various NN enhancements but does it really matter which function we are modeling when it comes to a hyper parameter tuner? The hyper parameter tuner is more about finding the best set of parameters for the network, than it is about performance of the NN on a particular problem.

A lot of these standard data sets take a while to train, i think it would be far more efficient to just generate samples with some random non linear function.

Ie. 

`def my_func(x, y)`

`return output`

`inputs = []`

`outputs = []`

`for x in range(100):`

`for y in range(100):`

`inputs.append([x, y])`

`outputs.append(my_func(x, y))`

Is there some reason why i can't just bench on some simpler function to gauge the performance of hyper parameter optimization? Or is there something more intrinsic in using an a bigger real-life data set.",2020-02-26 07:44:15
Asymmetry and General Additive Models without Quantile Regression?,1,f9db2y,https://www.reddit.com/r/MLQuestions/comments/f9db2y/asymmetry_and_general_additive_models_without/,0,1582678855.0,"Hi, my professor wants us to incorporate an asymmetry within our loss function for a General Additive Model (GAM). I proposed using a quantile regression GAM (via the qgam package), but he said to look for other ways to do so because we will cover quantile regressions later in class. I am unsure how else to incorporate such asymmetry using GAM in R. Accordingly, I would appreciate it if anyone has any advice or willing to share their experience doing so.

To be clear, this is a for a machine learning class. So, our models tend to weigh false positives and false negatives equally. Yet, when working for clients, one of those may be more costly than the other. For example, if clients are interested in reducing crime, falsely predicting that no crime will happen in a given neighborhood would be more consequential than false predicting that crime will happen. The former could have potentially been preventable while the latter needed no attention.",2020-02-26 06:30:55
How to use ML to help the elderly?,3,f98f1j,https://www.reddit.com/r/MLQuestions/comments/f98f1j/how_to_use_ml_to_help_the_elderly/,10,1582655954.0,"I was thinking maybe there could be a neutral net that predicts their time of death so they can prepare.

Or maybe a deep learning model to help them remember things. Like there could be a bot like Siri which would set reminders for them by inputting the data about their lifestyle and outputting the best optimized schedule.

I really want to help the elderly.",2020-02-26 00:09:14
Why not use constant instead of permutation for variable predictor importance?,1,f9ct85,https://www.reddit.com/r/MLQuestions/comments/f9ct85/why_not_use_constant_instead_of_permutation_for/,0,1582676930.0,"I want to determine predictor importance. Ideal is to re-train same  model on same dataset missing each variable in turn. This is too time  consuming. The recommendation I have seen everywhere is to ""remove"" the  column by converting it into noise by replacing it with its permutation.  Why is it not better to replace the variable with a constant, thus  ""muting"" the signal? 

I ran an experiment on my own natural dataset with highly  cross-correlated variables removed. Variable importance was computed  using the constants 0, mean median and values common in variable. I used  all of caret's regression models. Loss function is Pearson's  correlation. Data with no error was removed. All center constants  produce less of a drop in correlation than permutation about 900/1400 of  the time. 531/1421 constants did not make same error therefore  interaction and conditionality. At least all decision trees would do  this.

Take all available values in a variable and use them as the muting  constant. Weigh by constant's occurrence. The mean of that is what  permuting converges to as more iterations are run. Right?

I can not think of what to try next to understand this problem.",2020-02-26 05:58:50
Finding out which prediction results correlate,1,f9bsw1,https://www.reddit.com/r/MLQuestions/comments/f9bsw1/finding_out_which_prediction_results_correlate/,1,1582672937.0,"Hi all,

&#x200B;

I'm very new to Machine Learning but have still done a project on predicting premier league results (using pycharm). 

Using sklearn I have done my training and testing and produced my results:

Training a XGBClassifier using a training set size of 6600

Trained model in 1.1063 seconds

Made predictions in 0.0202 seconds

0.8967491999326258 0.9071212121212121 

 F1 score and accuracy score for training set: 0.8967 , 0.9071

Made predictions in 0.0058 seconds

F1 score and accuracy score for test set: 0.7083 , 0.7200.

&#x200B;

I was wondering if it was possible to find out which games this applies to that it got right/wrong?

&#x200B;

Happy to provide more info where needed.",2020-02-26 04:52:17
Actors and their actions extraction from text,1,f9bj9r,https://www.reddit.com/r/MLQuestions/comments/f9bj9r/actors_and_their_actions_extraction_from_text/,1,1582671843.0,"Hi everyone,i have to extract characters and their actions (actions have to be kept sequentially in time) from a simple child-story-like text, was told that BERT has already pre-trained layers, so it would be helpful to me in some way. 

How should i start exactly with that? Don't really have much experience with NLP now.  

Simple part-of-speech classification doesnt really seems to help, so it shoud be some kind of role labeling and i can't seem to find those methods, would be really thankful for a piece of advice.",2020-02-26 04:34:03
Is there any significant difference between Data Science platforms?,7,f947dy,https://www.reddit.com/r/MLQuestions/comments/f947dy/is_there_any_significant_difference_between_data/,4,1582631857.0," Hello everyone - New poster here.

I work at a large enterprise of 2k+ employees, and we have previously implemented internal DIY ML algorithms (built internally, from scratch). We are now ramping up the use cases where we will implement machine learning and have a lot more budget $ to invest - we are looking at a bunch of options from Alteryx, SAS, Databricks, Dataiku, H2O and Data Robot.

Considering that money isn't that much of an issue, which one would you prefer? and is there really any differentiation between all these?",2020-02-25 17:27:37
Help with defining constraints using MPC k-means in R,1,f99cr4,https://www.reddit.com/r/MLQuestions/comments/f99cr4/help_with_defining_constraints_using_mpc_kmeans/,0,1582661566.0,"Is anyone familiar with  MPC k-means and already used  the conclust package in R ?

I'm using the conclust package in R to perform semi-supervised clustering using MPC k-means algorithm to cluster fuel stations based on their activities. 

Stations with type X don't have to be in the same cluster with stations of type Y.

How to define such constraints using the mpckm function ?",2020-02-26 01:42:46
Machine Learning for an error prediction of a best first search maze solving algorithm,1,f99b15,/r/learnmachinelearning/comments/f999ph/machine_learning_for_an_error_prediction_of_a/,0,1582661305.0,,2020-02-26 01:38:25
Piecewise linear nature of deep relu networks,1,f98sl0,https://www.reddit.com/r/MLQuestions/comments/f98sl0/piecewise_linear_nature_of_deep_relu_networks/,1,1582658297.0,I have read that deep relu networks learn functions that are piecewise linear in nature but I am having a tough time understanding as to how this is true. Is there any proof of this point or any intuitive explanation that can make this more clear?,2020-02-26 00:48:17
Not sure where to post this - is there a free piece of software that uses machine learning and a piece of audio to create text to speech from that audio?,2,f96iky,https://www.reddit.com/r/MLQuestions/comments/f96iky/not_sure_where_to_post_this_is_there_a_free_piece/,2,1582643755.0,"Somewhat similar to the concept of Adobe Voco, I'm looking for some software that might be able to do this. I found CorentinJ's Real Time Voice Cloning on GitHub, but my computer can't run it (Intel 620 integrated GPU, it requires NVIDIA CUDA). Any suggestions, and how to install/use?",2020-02-25 20:45:55
Can I use the last n examples from a shuffled dataloader as k-fold cross validation?,1,f96ror,https://www.reddit.com/r/MLQuestions/comments/f96ror/can_i_use_the_last_n_examples_from_a_shuffled/,3,1582645260.0,If a dataloader shuffles examples every epoch can I just use the last 10% of the examples as the validation set instead of doing some more elaborate construction of the k-folds?,2020-02-25 21:11:00
Depth and width of network required to predict next frame in a video?,1,f96fij,https://www.reddit.com/r/MLQuestions/comments/f96fij/depth_and_width_of_network_required_to_predict/,0,1582643270.0,"I read [here](http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w19/Byeon_ContextVP_Fully_Context-Aware_CVPR_2018_paper.pdf) that a very simple, but very deep network (20 ConvLSTMs stacked above each other, each using a 3x3 filter) can beat state of the art models, but they did not indicate how many filters each ConvLSTM has, and what is a reasonable training time to reach convergence. I know the point of the paper isn't to use deep ConvLSTM networks, but I am just using it as reference.

&#x200B;

 I'm currently training with images of about 100x200 in size, using a window size of 10 past frames to predict the next frame. Not too sure why but my network keeps predicting the next frame as a nearly unchanged version of my previous frame. It's also taking quite long (4 min per epoch on a Tesla T4), and hovering about a mse of 10.

&#x200B;

This is the model I am using. Not too sure if it needs to be significantly deeper/wider.

    lstm = tf.keras.models.Sequential([
        tf.keras.layers.Lambda(lambda x: tf.expand_dims(x,axis=-1),input_shape=X.shape[1:]),
        tf.keras.layers.GaussianNoise(0.1),
        tf.keras.layers.ConvLSTM2D(25,
                                   padding='same',
                                   kernel_size=(3,3),
                                   dropout=0.1,
                                   return_sequences=True),
        tf.keras.layers.ConvLSTM2D(25,
                                   padding='same',
                                   kernel_size=(3,3),
                                   dropout=0.1,
                                   return_sequences=True),
        tf.keras.layers.ConvLSTM2D(25,
                                   padding='same',
                                   kernel_size=(3,3),
                                   dropout=0.1,
                                   return_sequences=False),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(1,padding='same',kernel_size=(1,1),trainable=False,activation='relu'),
        tf.keras.layers.Lambda(lambda x: tf.clip_by_value(x,0.,1.)),
        tf.keras.layers.Lambda(lambda x: 255. * tf.keras.backend.squeeze(x,axis=-1))
    ])

My Xs are all normalized to the range \[0.0,1.0\], while my Ys are in the range \[0,255\], hence I multiplied by 255 in the last line.",2020-02-25 20:37:50
Dataset size and batch size in model training performance,3,f8zddk,https://www.reddit.com/r/MLQuestions/comments/f8zddk/dataset_size_and_batch_size_in_model_training/,1,1582611667.0,"I'm new to machine learning and wanted to check if I am understanding some basic principles.

1.) A dataset with less samples is more likely to overfit or will overfit more quickly than a dataset with a larger amount of samples.

2.) When training a model, a larger batch size will train a model faster and has a better opportunity to reach a global minima but can quickly overfit, while smaller batch sizes will take longer to train but will introduce some ""noise"" during each batch which can help reduce the speed of overfitting.

Is my understanding correct?",2020-02-25 11:51:07
Lottery Ticket Hypothesis clarification,1,f93ev5,https://www.reddit.com/r/MLQuestions/comments/f93ev5/lottery_ticket_hypothesis_clarification/,1,1582628375.0,"A recent podcast [episode of Linear Digressions](https://soundcloud.com/linear-digressions/the-lottery-ticket-hypothesis?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+udacity-linear-digressions+%28Linear+Digressions%29) covers the Lottery Ticket Hypotheses, i.e. pruning a neural net to find the most useful subnetworks within, then resetting the weights in the pruned model to pre-training pseudo-random values.

They seem to imply that that pruned, reset, *un-trained* model can function nearly as well as the full, trained model. If true, that’s obviously huge, potentially indicating that training is bringing little added value.

But it was my understanding the Lottery Ticket work retrained the pruned model (albeit after having weights reset to original random values).

Can anyone explain which it is?

I believe this is the original paper on the Hypothesis: [https://arxiv.org/abs/1803.03635](https://arxiv.org/abs/1803.03635)",2020-02-25 16:29:35
"Masters in Machine Learning, looking for something to pair it with",4,f8uqh9,https://www.reddit.com/r/MLQuestions/comments/f8uqh9/masters_in_machine_learning_looking_for_something/,3,1582594390.0,"I’m going to be getting a CS masters in machine learning and as the title says I’m looking to add some other field to pair it with through electives. My general thoughts are to either take software or cyber security courses however I’m open to other suggestions as well. Based on everyone’s experiences, would either set of courses generally be a well suited application for machine learning?",2020-02-25 07:03:10
Transforming ordered list,2,f8y6fz,https://www.reddit.com/r/MLQuestions/comments/f8y6fz/transforming_ordered_list/,0,1582607228.0,"Hi I'm working on the preprocessing part of a project,
I have a column containing textual instruction about recipes, and the values are very heterogeneous.
I'm able to convert a string to a list of ordered steps.
Like this for example [('add','flour'),('add','water')]
The list is different for every row, can have an unlimited size and can contain duplicates (repeating the same step later for example, that's intended).
Also the verbs used can be anything, there isn't a set list of values(also intended) 
I'd like to make this column more usable
So here are a few questions :

Should I even try to do that ? 
Is it reasonable to create lots of columns containing the ordered steps? (knowing that it will create lots of empty values)
If you've dealt with this kind of problem before, what solution have you found?",2020-02-25 10:37:08
Got a hold of an old double card Nvidia 1080 Windows 10 gaming computer and I am looking to turn it into a Machine learning monster.,3,f8scm2,https://www.reddit.com/r/MLQuestions/comments/f8scm2/got_a_hold_of_an_old_double_card_nvidia_1080/,14,1582584965.0,"Is it possible to just download and run apps like Pytorch etc natively on windows 10 or install virtual machines with linux.
The hard drive is built in, so I can't just remove windows 10 , I uninstalled the  mining software but am ready to use it for ML
Any suggestions",2020-02-25 04:26:05
Aiming for high precision,1,f8wx3n,https://www.reddit.com/r/MLQuestions/comments/f8wx3n/aiming_for_high_precision/,1,1582602552.0,"Are there techniques to encourage your model to perform well at a particular threshold. (say, a random forest, but any model would still be interesting). We will deploy our model at very high precision, >99%, but when we add a certain set of features we improve the AOC and the recall at lower precision thresholds, but reduce recall at high precision.",2020-02-25 09:19:12
Simple Question about Time Series,1,f8wcek,https://www.reddit.com/r/MLQuestions/comments/f8wcek/simple_question_about_time_series/,1,1582600388.0,"
Let's say we are using the [NYC Taxi Cab dataset](https://www.kaggle.com/c/nyc-taxi-trip-duration/) and wanted to create a forecasting model of the length of trips that the average car has.

Would the best way to do is this to be to control for outliers, and then just do an average by day, and then do ARIMA?",2020-02-25 08:43:08
Annotating audio datasets using active learning,2,f8qowf,https://www.reddit.com/r/MLQuestions/comments/f8qowf/annotating_audio_datasets_using_active_learning/,0,1582577060.0,"I'm trying to find ways to annotate large audio datasets by using active learning techniques. Does anyone know of any open-source audio annotation web applications?

I'm trying to develop one.",2020-02-25 02:14:20
"Can I fine-tune BERT, ELMO or XLnet for Seq2Seq neural machine translation?",3,f8odka,https://www.reddit.com/r/MLQuestions/comments/f8odka/can_i_finetune_bert_elmo_or_xlnet_for_seq2seq/,3,1582562186.0,"I'm working on neural machine translator that translates English sentence to American sign language sentences. I'm wondering if it is possible to fine-tune BERT, ELMO or XLnet for Seq2seq encoder/decoder. 

 **English:** He sells food. 

 **American sign language:** Food he sells",2020-02-24 22:06:26
[P] Making a model for Nauto hand sign detection,10,f8dvgu,https://www.reddit.com/r/MLQuestions/comments/f8dvgu/p_making_a_model_for_nauto_hand_sign_detection/,1,1582512945.0," 

Hello community,

I am new to Dl, so plz excuse me if the questions are very nub. I went through several articles and tutorials, and before deciding I understood deep learning, I wanted to make my own project and this is what I came up with.

I tried implementing it in fastai using resnet50 after getting crowdsourcing the data( mostly me). I got a model predicting one category for everything.

This is the kaggle link:

[https://www.kaggle.com/vikranthkanumuru/naruto-hand-sign-detection-usin-fastai-diff-method](https://www.kaggle.com/vikranthkanumuru/naruto-hand-sign-detection-usin-fastai-diff-method)

Not sure if this is a problem, but earlier I had around 28 images per group so I made a video of myself doing the various signs and used opencv to save frame by frame. I later removed the ones that did not confine to any group and this increased the size of the dataset from 220mb to 2GB. Was this proper or is it the reason the model is bad?

This is the link to the dataset

[https://www.kaggle.com/vikranthkanumuru/naruto-hand-sign-dataset](https://www.kaggle.com/vikranthkanumuru/naruto-hand-sign-dataset)

I am not sure how to proceed further and would appreciate any help. Thank you very much.",2020-02-24 08:25:45
"Question about Generalized Additive Models, backfitting algorithm, and covariance adjustments?",2,f8kywj,https://www.reddit.com/r/MLQuestions/comments/f8kywj/question_about_generalized_additive_models/,0,1582543272.0,"Hi, I am taking a class on machine learning, but the professor is not the most helpful and often makes students feel bad about asking certain questions. Thus, I am asking here. In the assigned textbook, we are being asked about how the how the backfitting algorithm employed by GAM corresponds to the covariance adjustments in a linear regression?

I imagine he expects us to use the assigned textbook to answer this question. Unfortunately, the writing in the textbook isn't super clear, but if it helps provide context, I've copied some of the relevant paragraphs below:

"" One can use for GAM the same conception of “holding constant” that applies to conventional linear regression. Suppose that for a conventional regression analysis each of the predictors is transformed in a known manner. With least squares, each transformed predictor is covariance adjusted; the relationship between a given transformed predictor and the response is determined with the linear dependence between that transformed predictor and all other transformed predictors removed. One would like to do the same thing when each transformation is not known. But there can be no covariance adjustments until the transformations are determined, and there can be no transformations until each predictor is covariance adjusted. We have a chicken-egg problem. The backfitting algorithm provides a solution.""

Here's a link to the [text via Google Books](https://books.google.com/books?id=D6ZlDQAAQBAJ&pg=PA98&lpg=PA98&dq=With+least+squares,+each+transformed+predictor+is+covariance+adjusted;+the+relationship+between+a+given+transformed+predictor+and+the+response+is+determined+with+the+linear+dependence+between+that+transformed+predictor+and+all+other+transformed+predictors+removed.+One+would+like+to+do+the+same+thing+when+each+transformation+is+not+known.+But+there+can+be+no+covariance+adjustments+until+the+transformations+are+determined,+and+there+can+be+no+transformations+until+each+predictor+is+covariance+adjusted.&source=bl&ots=amaOhkf4TX&sig=ACfU3U3lkMcYo5wZZOEn6KTJVLGlHxoG2A&hl=en&sa=X&ved=2ahUKEwjxw_eRvejnAhULhXIEHTaSABUQ6AEwAHoECAoQAQ#v=onepage&q=With%20least%20squares%2C%20each%20transformed%20predictor%20is%20covariance%20adjusted%3B%20the%20relationship%20between%20a%20given%20transformed%20predictor%20and%20the%20response%20is%20determined%20with%20the%20linear%20dependence%20between%20that%20transformed%20predictor%20and%20all%20other%20transformed%20predictors%20removed.%20One%20would%20like%20to%20do%20the%20same%20thing%20when%20each%20transformation%20is%20not%20known.%20But%20there%20can%20be%20no%20covariance%20adjustments%20until%20the%20transformations%20are%20determined%2C%20and%20there%20can%20be%20no%20transformations%20until%20each%20predictor%20is%20covariance%20adjusted.&f=false).

Any help would be super appreciated!",2020-02-24 16:51:12
Agent based modeling question,1,f8j4dl,https://www.reddit.com/r/MLQuestions/comments/f8j4dl/agent_based_modeling_question/,0,1582534702.0,"
I come from architecture background and don’t have a lot of experience in programming.
Currently I’m exploring agent based modeling for my research.
What prerequisite knowledge do I need to have? And how hard to learn? Any advice on how and where to start? My research is on occupant behavior in buildings to enhance energy usage.",2020-02-24 14:28:22
Can anyone please help me build a machine learning model for vegetable and fruits detection .,1,f8i7vk,https://www.reddit.com/r/MLQuestions/comments/f8i7vk/can_anyone_please_help_me_build_a_machine/,4,1582530586.0,,2020-02-24 13:19:46
Image- background removal feature,1,f8hirt,https://www.reddit.com/r/MLQuestions/comments/f8hirt/image_background_removal_feature/,1,1582527527.0,"I was looking at an interesting app (?) that is hosted on GitHub : [https://github.com/theapache64/remove-bg](https://github.com/theapache64/remove-bg) .

Is there a way to use this service, or the code, without needing to use the API from the company?

Are there similar tools that could be implemented into a web app that you could recommend?",2020-02-24 12:28:47
"Video Call Processing (Whatsapp, Skype)",1,f8ejey,https://www.reddit.com/r/MLQuestions/comments/f8ejey/video_call_processing_whatsapp_skype/,4,1582515539.0,Is it possible to process an image in a video call on Whatsapp?,2020-02-24 09:08:59
Audio ML methods & methodologies 🔈🔈🔈,3,f8981l,https://www.reddit.com/r/MLQuestions/comments/f8981l/audio_ml_methods_methodologies/,3,1582492058.0,"Say you come across aliens or animals that use clicks to communicate and you want to better understand their communication. What would you do in order to explore and understand their sounds?

**Dataset**: 200 hours of continuous audio of the aliens/animals sounds of great quality

Language, as I see it, is a system with multiple levels of discrete units that can be combined with certain rules in order to form meaning. In a simplified form:

* Syllables are discrete units of sound that are combined in order to form words
* Words are discrete units of meaning, that are combined to form sentences
* Sentences are units in a conversation.

Thus, my exploration of the data will start from the smallest possible meaningful syllable-like signal into higher and higher levels:

**Understand the clicks (click embedding)**

1. Create a simple classifier that detects clicks.
2. Based on separate clicks, create a classifier / clustering of different clicks. Create a latent representation for each click using:
   1. Autoencoder variations on spectrograms -[ https://www.biorxiv.org/content/10.1101/870311v1](https://www.biorxiv.org/content/10.1101/870311v1)
   2. Autoencoder on raw wav[ https://www.researchgate.net/publication/317820073\_A\_Wavenet\_for\_Speech\_Denoising](https://www.researchgate.net/publication/317820073_A_Wavenet_for_Speech_Denoising)
3. Plot umap on click embeddings.

**Explore click sequences**

An initial approach could be to train an RNN predictor for the silence length after a sequence of clicks that also predicts the next click embedding or type (=cluster ID in such an embedding), and also gets as input the click representation.

# I’d highly appreciate more insights and advice here on methods, methodologies and any other interesting thought",2020-02-24 02:37:38
"Since machine learning can map out meanings of words, can it find gaps where words should be but humans haven’t invented yet?",41,f7uavp,https://www.reddit.com/r/MLQuestions/comments/f7uavp/since_machine_learning_can_map_out_meanings_of/,15,1582415691.0,,2020-02-23 05:24:51
Good ML papers to implement for beginners,12,f7wvcv,https://www.reddit.com/r/MLQuestions/comments/f7wvcv/good_ml_papers_to_implement_for_beginners/,2,1582426349.0,"Hello,  we have have been tasked with a project at our uni to select a good ml paper and implement it. I am complete newb at this and dont know where to find good papers. So  please suggest some papers to implement Also i am currently taking a course on machine learning and still a beginner. So if the papers a beginner friendly it is highly appreciated. 

Thank you",2020-02-23 08:22:29
RBM assigns arbitrary energies to unseen states in supervised learning,1,f85lge,https://www.reddit.com/r/MLQuestions/comments/f85lge/rbm_assigns_arbitrary_energies_to_unseen_states/,0,1582466843.0,"Hi there!

I got a question about restricted Boltzmann machines, I feel best to explain with an example:

I have a Boltzmann machine with 2 visible and one hidden unit. Now, I want to train that RBM in such a way that when I take samples from it afterwards using Monte Carlo Markov chain methods those should be either 00 or 11. This would mean that those states should have a high energy value assigned while the states 01 and 10 should have low energy values after the training. 

Now, in order to reach that goal my training set for a supervised learning algorithm (which will optimize the log likelihood using gradient descent) would look like that:

state -> target_energy
00 -> 1
11 -> 1

i.e. it only contains the states which I want to see afterwards but not those I don’t want to see (on scaling up to more visible units this would mean an exponential explosion of the size of the training set).  Now when I train my RBM it will assign energy values like the following to the possible states afterwards

00 -> 1
01 -> 2.7
10 -> 0.5
11 -> 1

So, the RBM would have learned the correct target for 00 and 11 but instead of having very low energies for the other states, they just seem to be random. Sampling from the RBM would not give me the desired distribution.

I feel there should a very simple solution to this but I don’t see how? Any help is highly appreciated! :-)",2020-02-23 19:37:23
Seeking responses for a survey on the Data Scientist and ML Engineer hiring process,2,f82izq,https://www.reddit.com/r/MLQuestions/comments/f82izq/seeking_responses_for_a_survey_on_the_data/,0,1582450647.0,"If you are an ML Engineer, Data Scientist, or have experience applying to these kinds of roles please fill out our short survey (less than 5 min).

[Take the Survey Here](https://forms.gle/Etuh89oXSTc6wNqh8)

My team and I are university undergraduates working on our Senior project. We are developing a solution to make searching for jobs and completing job applications easier for those searching for employment as a Machine Learning Engineer.",2020-02-23 15:07:27
Unsupervised Deep Learning,1,f7yvcx,https://www.reddit.com/r/MLQuestions/comments/f7yvcx/unsupervised_deep_learning/,1,1582434498.0,"Here is a problem. I have a dataset of many images of a metal sheets with a lot of defects on it but they are not labeled or classified. There are different kinds of defects(scratch, scribble, etc). Now, I’d like to identify all the ones that are more common without having to manually classify them. I’d really appreciate if someone can help me out on how to approach this problem.

A follow-up question:
Assuming I have identified some of these defects and if I have an image of all these identified defects with their labels, would I be able build a model that detects them as well as gives the exact location in the dataset of images of sheets that may or may not contain defects.

Thanks!",2020-02-23 10:38:18
Possible to remove the whistling sounds in voice recordings?,5,f7qj4w,https://www.reddit.com/r/MLQuestions/comments/f7qj4w/possible_to_remove_the_whistling_sounds_in_voice/,7,1582393431.0,"In voice recordings, there can be high-piteched whistle-like noises. I think it is especially so in French. I wonder if we could use the all-mighty machine learning to remove them automatically. I mean, not just deleting the noise parts, which I can do manually, but filling the vacancy with the voice, to make the voice recording continous natural.",2020-02-22 23:13:51
When should I use YOLO/MaskRCNN instead of a Vanilla CNN?,1,f7w91f,https://www.reddit.com/r/MLQuestions/comments/f7w91f/when_should_i_use_yolomaskrcnn_instead_of_a/,0,1582423763.0,I understand how YOLO and other object detection networks work but also see some people using a simple CNN to predict a point / bounding box. When should I use something more complex? If I’m just detecting one box per image would I use a standard CNN?,2020-02-23 07:39:23
ML and output,4,f7i7ox,https://www.reddit.com/r/MLQuestions/comments/f7i7ox/ml_and_output/,7,1582350087.0,"sorry I am a newbe at ML and I think I have a good idea how it works, but struggling with this.

I am trying to retrieve a bunch of computers names that are going to fail, but I have no idea how to ask the question, as ML seems to just return a few values, accuracy, precision and prediction. I'm not sure how to get it to return the computer names.

Am I looking at this wrong and should be asking the question will ""this"" computer fail, based on stats from a single computer, instead of a group of computers? the weighted values being what we consider to be failing, for example less then x% free disk space, or CPU utilization over x%, or network speed less then x%, etc...…...",2020-02-22 11:11:27
"The best strategy to build a binary classifier for a dataset with a 10,000 - 50,000 features",8,f7efsq,https://www.reddit.com/r/MLQuestions/comments/f7efsq/the_best_strategy_to_build_a_binary_classifier/,12,1582334918.0," 

If you have a data-set with >10,000 feature labels for a binary classification, what would be your strategy to build the classifier ?

And what would be your go-to algorithms and models ?",2020-02-22 06:58:38
Semi-automatic labeling of datasets using active learning,11,f7b080,https://www.reddit.com/r/MLQuestions/comments/f7b080/semiautomatic_labeling_of_datasets_using_active/,6,1582320110.0,How would you approach the given problem of labeling of datasets with the minimal human intervention? Do you guys know of any papers/articles where I can read more about it?,2020-02-22 02:51:50
Beginner ML projects and workflow,19,f740n4,https://www.reddit.com/r/MLQuestions/comments/f740n4/beginner_ml_projects_and_workflow/,7,1582279550.0," Hello everyone, I am a recent grad hoping to land a ML gig sometime in the not too distant future. As a beginner, I have so far been pouring all of my energy into ML tutorials (I am using python). I realize that without professional experience, my best chance to land a job is to work on personal projects but all I feel I am doing is copy pasting code from online tutorials, without really understanding what I am doing or why. After months of reading and learning I am beginning to feel like I am spinning my wheels not getting anywhere. I guess my question is what can I focus my work on that will translate to applicable knowledge/valuable projects to throw on my github that employers will actually care about",2020-02-21 15:35:50
Custom YOLO output,1,f7cnzq,https://www.reddit.com/r/MLQuestions/comments/f7cnzq/custom_yolo_output/,0,1582327698.0,"Hi guys, I'm working on a personal project that is about founding the key positions of an object (let's say a sword) in an image. What I want want to do is to use a pre-trained network to solve my problem, in this case YOLO v3. 
I've already worked on a transfer learning project but in this case the output will be different since I want to get the 3 key positions (the position of the handle of the sword, the middle position of the blade and the tip of it). Can I just use the YOLO network, chop out the last layer and customize it for my project? Would it be better to retrain everything since the original model was used to find bounding boxes?",2020-02-22 04:58:18
Is There Voice Cloning Model In Tf.Keras?,1,f7bw4j,https://www.reddit.com/r/MLQuestions/comments/f7bw4j/is_there_voice_cloning_model_in_tfkeras/,0,1582324348.0,What the title says. I'm looking for voice cloning in tf.keras. Thanks!,2020-02-22 04:02:28
"Which ML algorithm, architecture and packages could be used for 3D sequence data with 4D-5D output?",1,f7bvot,https://www.reddit.com/r/MLQuestions/comments/f7bvot/which_ml_algorithm_architecture_and_packages/,0,1582324295.0,"I want to train a model on FEM simulations and predict the deformations and the stresses.

So, the **input** is the geometry (\~100k nodes with x, y, z dimensions) and the ""master node"", where the strain is applied (boundary conditions). What changes through the different cases is the geometry (number and location of the nodes) and the master node. The strain applied is the same.

The **output** is the dx, dy, dz deformations of each node and the stress that it takes, namely the output is a \~100k x 4 matrix. An idea would be to train 2 different models, one for the deformations and the other for the stresses...

Any suggestions on which algorithm and architecture could be suitable? The data seems to be sequential, because the deformation is passed from node to node, but everything that I found was on NLP, where the information travels 1D. Is there any way to apply Recurrent NN in 3D data and is it relative to this problem?

Thank you!",2020-02-22 04:01:35
Why is computing 2nd derivative so much more expensive than the 1st when using autodiff?,6,f74gek,https://www.reddit.com/r/MLQuestions/comments/f74gek/why_is_computing_2nd_derivative_so_much_more/,2,1582281567.0,"Much of the content is said in the header: I'm curious as to the theory behind why the second derivative is so much more expensive than the first when using automatic differentiation for DL applications. 

Is it because it requires computing all of the first derivatives before computing the second? Couldn't that happen in a dynamic approach? 

If anyone prefers to send resources for me to find the answer instead of just answering it outright, that's fine too.

Any help is appreciated",2020-02-21 16:09:27
Pose estimation from video of a known 3D object.,1,f791tv,https://www.reddit.com/r/MLQuestions/comments/f791tv/pose_estimation_from_video_of_a_known_3d_object/,0,1582308416.0,Let's say I have a 3D model of the object that is very precise. Are there some simple methods to get the pose from video (object can be partially visible)? I'm quite aware of general pose estimation or bounding box pose estimation that gives position and rotation of the video (6D). But given that the models are that general it seems like an overkill for my case.,2020-02-21 23:36:56
Catchy company names generator,1,f77x98,https://www.reddit.com/r/MLQuestions/comments/f77x98/catchy_company_names_generator/,0,1582300457.0,"Hello,

I want to create a project where users can generate catchy and unique company names. Users will enter some keywords (e.g. vehicle, public transport) and my service would generate some catchy names. Something similar to [https://namelix.com](https://namelix.com). 

I have a dataset with company names. What approach should I start with? 

All ideas are welcome!",2020-02-21 21:24:17
Types of Machine Learning: A Beginner's Guide,1,f76c1u,http://brainstormingbox.org/types-of-machine-learning-a-beginners-guide/,0,1582290797.0,,2020-02-21 18:43:17
Could Someone Please explain entropy models in terms of Decision Trees?,5,f6xzd7,https://www.reddit.com/r/MLQuestions/comments/f6xzd7/could_someone_please_explain_entropy_models_in/,7,1582254701.0,,2020-02-21 08:41:41
Bayesian Prediction/ naives bayes algorithms?,5,f6ukqw,https://www.reddit.com/r/MLQuestions/comments/f6ukqw/bayesian_prediction_naives_bayes_algorithms/,2,1582240991.0,"Lecturer asked us to do a report of algorithms, one of the requirements was to talk about 

""Probability-based (Bayesian Prediction/ naives bayes algorithms) ""        

from my research Bayesian prediction is a group of algorithms that the  naives bayes is a part of,

is that correct?",2020-02-21 04:53:11
Time-Series data transformation/normalization with no prior knowledge.,5,f6robt,https://www.reddit.com/r/MLQuestions/comments/f6robt/timeseries_data_transformationnormalization_with/,6,1582226430.0,"Hey! We are two guys working on a predictive maintenance system, where the key goal is to detect anomalies in an information stream. We'll be working with a multitude of sensor data collecting data from temperature, humidity, structural changes and lot's of others.

We have a key challenge wrt. to normalizing the data. Often when I work with machine learning we would use for example, the minimum and maximum, or the standard deviation of the data to transform it. However, we have no such prior knowledge about the data. We're trying to find a robust transformation that uses no such information, that still differentiates between difference in the values.  

I thought about for example using a sigmoid transformation, but the distinguishability of the data seems to be greatly reduced. For example, the sigmoid transformation of 15 and 22, returns 0.999999694097773 and 0.9999999997210531, respectively.

So my question is, does anyone know some transformations that will work on a majority of different features with different characteristics, without loss of granularity?

Please let me know if my issue is not clear :)",2020-02-21 00:50:30
Unit Neurons: Neural Networks as Complex Systems,3,f6u63h,/r/DecisionTheory/comments/f6u55t/unit_neurons_neural_networks_as_complex_systems/,0,1582239222.0,,2020-02-21 04:23:42
source for generating sentences with certain grammatical structures?,2,f6vyyh,https://www.reddit.com/r/MLQuestions/comments/f6vyyh/source_for_generating_sentences_with_certain/,0,1582246728.0,"Is there a resource that can produce sentences with certain grammatical structures?  Like a sentence starting with a dependent clause, or one with a semicolon?",2020-02-21 06:28:48
Is this really where machine learning is headed?,1,f6yxgy,https://www.reddit.com/r/MLQuestions/comments/f6yxgy/is_this_really_where_machine_learning_is_headed/,3,1582258403.0,"This sounds about as dystopian and terrifying as a world could ever become. The possibility for abuse of such software is unlimited and could lead to unprecedented forms of totalitarianism, forced drugging or even torture.

I've been thinking about data science or machine learning as a career goal, so I would be curious to know what people who work in machine learning jobs think about this kind of stuff.

[https://www.marketwatch.com/story/how-ai-therapists-could-shrink-the-cost-of-mental-health-2020-02-18](https://www.marketwatch.com/story/how-ai-therapists-could-shrink-the-cost-of-mental-health-2020-02-18?mod=best-new-ideas-in-health-care&mod=home-page)",2020-02-21 09:43:23
"If hybrid-HMMs are trained by having the neural net predict the same as the GMM-HMM, why do they perform better?",2,f6uubz,https://www.reddit.com/r/MLQuestions/comments/f6uubz/if_hybridhmms_are_trained_by_having_the_neural/,2,1582242089.0,"Been reading a bit about hybrid-HMMs for speech recognition, but don't get this fundamental thing. My understanding is that they work by doing the following:

1. GMM-HMM is trained with MFCCs and force aligns phones/triphones/senones/etc for each frame.

2. Neural net attempts to predict the same outputs as the GMM-HMM for each frame.

3. After training, HMM using neural net instead of GMM for emission probabilities gives better results.

I don't understand how that can be. To me it seems that a perfectly trained neural net would then be predicting the exact same outputs as the GMM. Would be really appreciative if someone could tell me what I'm missing!",2020-02-21 05:11:29
Who,0,f6yb4n,https://www.reddit.com/r/MLQuestions/comments/f6yb4n/who/,2,1582255972.0,Who is Naive Bayes? Sounds as though he/she is based on a person.,2020-02-21 09:02:52
How to make recommendation with KNN,1,f6qyu0,https://www.reddit.com/r/MLQuestions/comments/f6qyu0/how_to_make_recommendation_with_knn/,1,1582221933.0,"I am building a simple book recommender where I only have certain book information (price, title, author, genre, publishing date) and **no user information** at all (no ratings, no demographics) just their **purchase history**.

So I want to make recommendations based only this purchase history, as an example: user A bought book1, book2 and book3, and user B bought book1, book3 and book4, if I want to get recommendations for user A I can assume book4 would be a good one given that they share similar interests based on their purchase history.

I'm trying to implement KNN with cosine similarity but I don't really know how to give recommendations based on the user, I mean, I've built the matrix and I've chosen the parameters but I don't know how to use the results to give a list of recommended books given a user.

Here's how my matrix looks (simplified):

&#x200B;

https://preview.redd.it/1mh5wfg5z1i41.png?width=645&format=png&auto=webp&s=63e99d72955d61668aa9df499220a744765883ef

Where 1 represents if the user bought the book and 0 if he/she didn't.

And here is what I've done so far:

    # Matrix with users as rows, products as columns and count as content 
    df_matrix = pd.pivot_table(order_df, values='count', index='username', columns='product') 
    # Replace all NaN contents with 0 
    df_matrix_dummy = df_matrix.fillna(0) 
    # Convert dataframe of books features to scipy sparse matrix 
    product_matrix = csr_matrix(df_matrix_dummy.values)  
    model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)

Can someone give me a hand or point me into a good tutorial?",2020-02-20 23:35:33
ConvLSTM2D prediction is the same as the image at t-1,1,f6qv2o,https://www.reddit.com/r/MLQuestions/comments/f6qv2o/convlstm2d_prediction_is_the_same_as_the_image_at/,0,1582221247.0," I am trying to predict the next image in a sequence of images, and I'm not too sure why LSTMs aren't cutting it for me. My predicted image seems to always be a copy of the image at the previous timestep.  I also had similar results when using Conv3D on my images, but I'm not too sure why this is so. My input has been normalized to be in range \[0,1\], and I multiplied my output by 255 because my Ys weren't normalized. 

&#x200B;

 This is my LSTM model 

    lstm = tf.keras.models.Sequential([
        tf.keras.layers.Lambda(lambda x: tf.expand_dims(x,axis=-1),input_shape=X.shape[1:]),
        tf.keras.layers.GaussianNoise(0.05),
        tf.keras.layers.ConvLSTM2D(25,padding='same',kernel_size=(3,3),return_sequences=True,stateful=False),
        tf.keras.layers.ConvLSTM2D(25,padding='same',kernel_size=(3,3),return_sequences=True),
        tf.keras.layers.ConvLSTM2D(25,padding='same',kernel_size=(3,3),return_sequences=False),
        tf.keras.layers.Conv2D(1,padding='same',kernel_size=(1,1),trainable=False),
        tf.keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(x,axis=-1)),
        tf.keras.layers.Lambda(lambda x: 255. * tf.clip_by_value(x,0.,1.))
    ])

And this is my Conv3D model

    conv = tf.keras.models.Sequential([
        tf.keras.layers.Lambda(lambda x: tf.expand_dims(x,axis=-1),input_shape=X.shape[1:]),
        tf.keras.layers.GaussianNoise(0.05),
        tf.keras.layers.Conv3D(25,padding='same',data_format='channels_last',kernel_size=(5,3,3)),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.Conv3D(25,padding='same',data_format='channels_last',kernel_size=(5,3,3)),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.Conv3D(1,padding='same',data_format='channels_last',kernel_size=(1,1,1), trainable=True),
        tf.keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(x,axis=-1)),
        tf.keras.layers.Conv2D(1,kernel_size=(1,1),data_format='channels_first',trainable=True),
        tf.keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(x,axis=-3)),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.Lambda(lambda x: 255. * tf.clip_by_value(x,0.,1.))
    ])

 

I tried making a SSIM loss function but it makes my model predict that the next image will be **super bright**, and performs much worse than simply using mse.

This is the loss function I made. I know it looks extreme but all my images are very similar in structure to each other, so I believe this harshness is warranted. There were no NaN errors during training.

    def custom_err(y_true,y_pred):
        #ssim has range [-1,1], with -1 being the worst and 1 being the best
        def SSIM(y_true,y_pred):
            ssim= tf.image.ssim(tf.expand_dims(y_true,-1),tf.expand_dims(y_pred,-1),255)
            return ssim
        ssim=SSIM(y_true,y_pred)
        return 10**(abs(ssim - 1) * 20) - 1

&#x200B;

I also posted this on stackoverflow [here](https://stackoverflow.com/questions/60316167/convlstm2d-prediction-is-the-same-as-the-image-at-t-1).",2020-02-20 23:24:07
Quantum Computing: Feedstock For Artificial Intelligence,1,f6q9lg,https://www.artiba.org/blog/quantum-computing-feedstock-for-artificial-intelligence,1,1582217120.0,,2020-02-20 22:15:20
[D]Has there been research in finding out the intrinsic dimensionality of the natural image manifold?,19,f6cu8d,https://www.reddit.com/r/MLQuestions/comments/f6cu8d/dhas_there_been_research_in_finding_out_the/,10,1582157355.0,"The Manifold Hypothesis says that images lie on a low dimensional manifold embedded in a high dimensional euclidian space(Observed Pixel Space).If we want to ""roam"" around the manifold,we have limited degrees of freedom.

I'm curious if there has been any research that aims to find the dimension of this low dimensional manifold. Also, if there are aliens on some planet a million light-years away, would an image of those aliens lie on the natural image manifold?",2020-02-20 05:39:15
Best Video Classification methods and their tutorials?,2,f6mbny,https://www.reddit.com/r/MLQuestions/comments/f6mbny/best_video_classification_methods_and_their/,0,1582195942.0," 

I have done image classification with CNN and some NLP with RNN, LSTM and GRU..so I do have an idea what to expect in a video classification task, basically a combination of CNN and RNN I believe due to images being the time series data here. I want to get straight to the point and not loiter around looking for methods and tutorials that are not upto the mark, so please guide me to the ones that are, lol

Any resources, may it be blogs, books, courses..they will be appreciated!",2020-02-20 16:22:22
Can a neural net automatically tell neuron distances?,1,f6kcyg,https://www.reddit.com/r/MLQuestions/comments/f6kcyg/can_a_neural_net_automatically_tell_neuron/,4,1582187256.0,"Hi,

I was wondering,

If we have say 100 inputs based on position and time.
As in neuron 1 is at 0m, neuron 2 is at 0.1m... neuron 100 is at 10m, and the input value is how long people stood in that position in time (0- 1 million seconds).(random example)
So we have 100 neurons entering in with values of 0 to 1 million seconds, but as the user we knew these are in order of position in distance, but the neural net isn't given that as a value.

Will a neural net automatically be able to figure out the difference in positions between the highests features?
As in, say the top 3 times are neuron 50,65, and 68.
Will it be able to tell the difference between them is 13 and 3?
Or can it not differentiate between the abstract that is 'locations' of it's features without being given them? And that is feature engineering one must do?

Thanks",2020-02-20 13:57:36
Subscaling tensors with WaveRNN,1,f6k4h7,https://www.reddit.com/r/MLQuestions/comments/f6k4h7/subscaling_tensors_with_wavernn/,0,1582186232.0,"So I am currently taking a look at applying subscale WaveRNN (in particular the fused subscale WaveRNN found [here](https://arxiv.org/pdf/1802.08435v2.pdf).

Note that my codebase is based on fatchord's WaveRNN: https://github.com/fatchord/WaveRNN.

Currently, I'm trying to generate an audio using a subtensor however the output audio sounds pretty bad. Has anyone can point me to references about audio subscaling information for WaveRNN. Please let me know.",2020-02-20 13:40:32
[D] Classification and Mapping of products based on the title and description,2,f6gcmy,https://www.reddit.com/r/MLQuestions/comments/f6gcmy/d_classification_and_mapping_of_products_based_on/,0,1582171019.0,"I m trying to solve the problem which involves mapping of two e commerce products from two different sources. (let's say A and B, and there will be one to one mapping between the set.) 
I am taking two step approaches to solve. First, will classify products into to 30-50 categories. Classification happens on the both set  A, B independently. Second step to map correct product from set A to B. Simple string match or fuzzy search will not work, as data is not consistent.

Please suggest me which algorithm that I can use to solve this.

Tl:dr
Best ML algorithm to map products from A to B using title and description.",2020-02-20 09:26:59
Does there exist a neural network that can play any game?,0,f6jq10,https://www.reddit.com/r/MLQuestions/comments/f6jq10/does_there_exist_a_neural_network_that_can_play/,3,1582184510.0,"I've tried Serpent.AI, but it requires you to set up sprites and code. A way I could think of a neural network working without setting up sprites and code is for human feedback on its actions (like a good action/bad action button or hotkey).

In my research, I have found [this DeepMind article](https://deepmind.com/blog/article/learning-through-human-feedback) that uses a similar approach to my idea. However, I am still not a pro at programming (I have a basic knowledge of Python) and machine learning.

Does anyone have any pointers? Is this idea too ambitious and naive?

Thanks!",2020-02-20 13:11:50
"What is ""xi"" used for (and what are good values) in the Expected Improvement acquisition function",2,f6d80d,https://www.reddit.com/r/MLQuestions/comments/f6d80d/what_is_xi_used_for_and_what_are_good_values_in/,2,1582158919.0,"        def _ei(x, gpr, y_max, xi):
            mean, std = gpr.predict(x, return_std=True)
            z = (mean - y_max - xi) / std
            return (mean - y_max - xi) * norm.cdf(z) + std * norm.pdf(z)

y\_max is just worst guess more or less. gpr is our gaussian process. x is our guess. There is an adjustable component of the function xi. What is this used for and what kind of range should this value be in?",2020-02-20 06:05:19
In search of AI edge use cases needing extremely low inference latencies,5,f65ry1,https://www.reddit.com/r/MLQuestions/comments/f65ry1/in_search_of_ai_edge_use_cases_needing_extremely/,4,1582117728.0,I am tabulating all AI Edge applications that require custom ASICs able to support super low-latency (in microseconds) or/and extremely high throughput.  Does anything come to mind?,2020-02-19 18:38:48
"Hi, I am a newbie. I wanna get started with ML, AI. Could you guys please suggest me how to start and where to start?",0,f6bsy0,https://www.reddit.com/r/MLQuestions/comments/f6bsy0/hi_i_am_a_newbie_i_wanna_get_started_with_ml_ai/,3,1582153124.0,,2020-02-20 04:28:44
Has anyone used XLM-R on undeciphered writing systems?,1,f68odb,https://www.reddit.com/r/MLQuestions/comments/f68odb/has_anyone_used_xlmr_on_undeciphered_writing/,0,1582134764.0,"Like [Linear A](https://en.wikipedia.org/wiki/Linear_A). Is there any work on language archeology that uses these methods?

If not, is it because of data availability?",2020-02-19 23:22:44
"why is smooth interpolation between data points, a good inductive bias for neural networks?",11,f5y7no,https://www.reddit.com/r/MLQuestions/comments/f5y7no/why_is_smooth_interpolation_between_data_points_a/,10,1582086683.0,,2020-02-19 10:01:23
How can you bin data in pandas? By range,1,f67kqs,https://www.reddit.com/r/MLQuestions/comments/f67kqs/how_can_you_bin_data_in_pandas_by_range/,5,1582127887.0,"I have a dataset.

Its one column long for ranges from 1-28.


I want to simply do a value count and percentage of this data at a range of 1-21 and 22-28.



What I want is something that will look like this....



    range     category  count    percentage 
    [1-21]       A         xxx       xxx%
    [22-28]     B         xxx       xxx%




I have been googling pandas cut and group by and I am losing my mind. I can't figure out what words to even google to do what it is that I want to do.

Please, if you know who to do this in pandas. I would really appreciate your help.",2020-02-19 21:28:07
Need help assigning XY coordinates with dataset,2,f64o0t,https://www.reddit.com/r/MLQuestions/comments/f64o0t/need_help_assigning_xy_coordinates_with_dataset/,3,1582112496.0,"Hi there,

I am currently building a human predictive model using received signal strength indicator(rssi). I was wondering if its possible to assign the dataset to the XY coordinates and train the model with k nearest neighbour to predict human location thus returning a XY coordinate within the setup? I have been trying to use numpy to create an array of the specific data collected XY coordinates. However as I have collected 10 samples of rssi data of each location, I am in a dilemma on how to proceed with the assigning of the dataset. 


If this isn't a feasible method, could anyone point me the right direction to achieve my desired result?


Appreciate any help, please feel free to ask if you require additional information.",2020-02-19 17:11:36
Best Video Classification methods and their tutorials?,1,f64rvl,https://www.reddit.com/r/MLQuestions/comments/f64rvl/best_video_classification_methods_and_their/,0,1582112988.0," 

I have done image classification with CNN and some NLP with RNN, LSTM and GRU..so I do have an idea what to expect in a video classification task, basically a combination of CNN and RNN I believe due to images being the time series data here. I want to get straight to the point and not loiter around looking for methods and tutorials that are not upto the mark, so please guide me to the ones that are, lol

Any resources, may it be blogs, books, courses..they will be appreciated!",2020-02-19 17:19:48
Can someone link me some papers on intrinsic rewards? :),1,f647da,https://www.reddit.com/r/MLQuestions/comments/f647da/can_someone_link_me_some_papers_on_intrinsic/,0,1582110460.0,Fascinating stuff,2020-02-19 16:37:40
Need Help Fixing Volatile Validation Loss,1,f63n1p,https://www.reddit.com/r/MLQuestions/comments/f63n1p/need_help_fixing_volatile_validation_loss/,2,1582108015.0,"&#x200B;

https://preview.redd.it/mnk2n5s6ksh41.png?width=1280&format=png&auto=webp&s=11b9d725e8ed9b5f7dbbafbdf427ca0b2461a501

This is my loss function after running the validation set. Is this an example of either over/underfitting? And what are some possible ways to reduce the volatility of the validation loss?",2020-02-19 15:56:55
First ML algorithm suggestion? (Predicting patient outcomes with gene expression),1,f62sbe,https://www.reddit.com/r/MLQuestions/comments/f62sbe/first_ml_algorithm_suggestion_predicting_patient/,1,1582104409.0," Hello! I'm trying to construct my 'first' ML algorithm. I have data provided to me by the FDA that I want to use to predict patient outcomes in brain cancer patients using their gene expression.

The sample comprises of n = 377 cancer patients.

There are 6 main brain cancer type categories: Astrocytoma, glioblastoma, oligodendroglioma, mixed, unknown and unclassified.

For each cancer type, there are 5 classifications of cancer severity: I, II, III, IV, and 'missing value' (WHO grading).

There are 19336 genes with log2 normalized gene expression values for each patient (continuous values).

What algorithm would you suggest I use? Although I've done some linear regressions, I am pretty new to machine learning and I'm just looking for ANYTHING to get started (the simpler the better for now). As I become more knowledgeable I will go back and implement different techniques or adjustments, but for now, I'm just looking for something to show my work in my portfolio for upcoming internship/research applications.

Any (even small) suggestions of where to start are incredibly appreciated!

And also I'm programming in R at the moment.

Link to more info on the data (Cancer types & Grading):

[https://docs.google.com/document/d/1znQnvJgYNG8jaSN4o8Hj0paX-dWr4vhX6NpMfxxQUF0/edit?usp=sharing](https://docs.google.com/document/d/1znQnvJgYNG8jaSN4o8Hj0paX-dWr4vhX6NpMfxxQUF0/edit?usp=sharing)",2020-02-19 14:56:49
"Just learned about automatic differentiation, a really interesting way to go about differentiation. I was wondering if there is something similar w.r.t integration like automatic integration?",13,f5qngm,https://www.reddit.com/r/MLQuestions/comments/f5qngm/just_learned_about_automatic_differentiation_a/,5,1582055601.0,,2020-02-19 01:23:21
Bounding box regression with keras,1,f60o6x,https://www.reddit.com/r/MLQuestions/comments/f60o6x/bounding_box_regression_with_keras/,0,1582095858.0,"
Hi everyone, I wanted to make a cnn that would output the x min, x max, y min, y max of a bounding box tracking balls on the ground. I found online tutorials to do this but all of them only had examples of training the cnn with 1 object/ box per image and they had 4 output neurons + number of classes. Would this be okay if there were multiple classes? Would the cnn output multiple boxes with this configuration? Thanks for the help.",2020-02-19 12:34:18
How to calculate the inital loss for heatmap detection problems? ie MSE loss,2,f5v3d7,https://www.reddit.com/r/MLQuestions/comments/f5v3d7/how_to_calculate_the_inital_loss_for_heatmap/,0,1582074872.0,"Andrej Karpathy say that you should always verify your loss 

>**verify loss @ init**. Verify that your loss starts at the correct loss value. E.g. if you initialize your final layer correctly you should measure   
>  
>-log(1/n\_classes)  
>  
>on a softmax at initialization. The same default values can be derived for L2 regression, Huber losses, etc.

I have been doing this with my image classification tasks. I have created a model that predicts a heatmap using MSE Loss. How would you calculate the initial loss in this case?",2020-02-19 06:44:32
Understanding deep learning frameworks,1,f5vvtz,https://www.reddit.com/r/MLQuestions/comments/f5vvtz/understanding_deep_learning_frameworks/,3,1582077829.0,"Is there any resource that walks me through the implementations of popular frameworks like TF and torch? I realize that they are both open source, but my question is whether just staring at their GitHub source code is the best way to understand them on a low level. Thanks!",2020-02-19 07:33:49
"Keras, pretrained networks and preprocess_input function",2,f5rxxi,https://www.reddit.com/r/MLQuestions/comments/f5rxxi/keras_pretrained_networks_and_preprocess_input/,5,1582062008.0,"So I've been following the book Deep Learning with python by Francois Chollet, as a guide for fine-tuning pretrained networks on imagenet.

In his book he uses rescale = 1./255
I've been using this myself and getting good results with VGG16. However this does not work at all for ResNet50, the model does not converge. In this case I have to use preprocess_input.

It seems the preprocess input function for both uses ""caffe"" style preprocessing which zero centres the mean which seems very different from 1./255


I guess my question is, was it incorrect to use 1./255 as the pre processing function with VGG16? I'm fine tuning for a completely different dataset. I don't want to have to redo my experiments with different preprocessing functions.

Again thanks for any help.",2020-02-19 03:10:08
Statistics Departments with heavy Machine Learning Research in US,1,f5usyn,https://www.reddit.com/r/MLQuestions/comments/f5usyn/statistics_departments_with_heavy_machine/,1,1582073846.0,"Hello everyone,

I am a Physics and Mathematics undergraduate student. I want to go to graduate school for machine learning. Being a Math major, I thought going to the statistics department would be better rather than the CS department for Machine Learning. Can you guys suggest to me some Statistics Departments which do heavy research in Machine learning?",2020-02-19 06:27:26
Do regression problems have different manifolds like classification problems?,3,f5m5gu,https://www.reddit.com/r/MLQuestions/comments/f5m5gu/do_regression_problems_have_different_manifolds/,7,1582029458.0,"A lot of classification literature refers to class manifolds which makes sense. I am wondering how the idea of manifolds applies to regression problems. Do regression problems have one continuous manifold or are there infinitely many manifolds for every training instance?

I cant seem to find many things mentioning manifolds in regression problems. Thanks",2020-02-18 18:07:38
Bounding Boxes in CNNs,1,f5p7q1,https://www.reddit.com/r/MLQuestions/comments/f5p7q1/bounding_boxes_in_cnns/,0,1582046767.0,"Recently, in one of my ML projects on neuroscience, I have noticed there is a scarcity of brain image datasets with bounding boxes in them (ie. to indicate lesions, tumours, etc.), and a lot of datasets that merely indicate the presence or absence of such lesions/tumours. 

Thus, given a small dataset (about 1000 images) that contain bounding boxes, would it be possible to train the rest of the data to draw bounding boxes in the final outputs? Or failing that, would this small size of images be enough to train another model to draw bounding boxes on the rest of the training data before using that for training?",2020-02-18 22:56:07
Extremely slow LSTM training?,1,f5p6ns,https://www.reddit.com/r/MLQuestions/comments/f5p6ns/extremely_slow_lstm_training/,2,1582046581.0," I was trying to make a network to predict the next image in a sequence of images, and I noticed that any network with a LSTM in it trains exceedingly slowly, so I tried to make a toy network with relatively easy data to train on. It still takes forever to train with Colab (\~ about 9s/epoch). Is this inherent to how LSTMs are computed or is there something wrong with what I'm doing?

&#x200B;

[https://pastebin.com/7UwAbfvZ](https://pastebin.com/7UwAbfvZ)",2020-02-18 22:53:01
Is id an irregular cardinality?,0,f5p2vb,https://www.reddit.com/r/MLQuestions/comments/f5p2vb/is_id_an_irregular_cardinality/,0,1582045908.0,,2020-02-18 22:41:48
The Lottery Ticket Hypothesis - TensorFlow 2.0 implementation,4,f5gyw0,https://www.reddit.com/r/MLQuestions/comments/f5gyw0/the_lottery_ticket_hypothesis_tensorflow_20/,0,1582007251.0,"Hey guys, I wrote a Python 3.X TensorFlow 2.0 implementation for [The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635) in my [GitHub repo](https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2)

Let me know your comments and thoughts!",2020-02-18 11:57:31
Question about math,1,f5mzed,https://www.reddit.com/r/MLQuestions/comments/f5mzed/question_about_math/,17,1582033551.0,"I took up to cal 1 about ten years ago and im planning on getting g a college algebra text and mastering that , then same for trig, precal, cal 1,2,3, diff equ, lin algebra, my question is this will take years is all of this necessary for ml?",2020-02-18 19:15:51
How can i fit a Gaussian process to a data set where some samples contain missing features,1,f5j72x,https://www.reddit.com/r/MLQuestions/comments/f5j72x/how_can_i_fit_a_gaussian_process_to_a_data_set/,0,1582016406.0,"Since i am doing bayesian hyper parameter optimization that has nested features, i need to find a way to more or less ""ignore"" some features for some samples when fitting a Guassian process.

The reason for this is because sometimes a feature/parameter is not active for a particular sample/configuration and has no effect on the target output.

The most basic example would be something like this.

  sample    output

1 [0, 1]  ->  4

2 [?, 3]  ->  5

Here my second sample has a feature that does not affect the output at all. Yet in the first sample that feature is active and does affect the output. They are both the same parameter space despite that sometimes samples will have different dimensions/amount of active features.

If i put in a random number i think this complicate the search process as the BO is now optimizing on features that do not affect the target.

When i use sklearn's GPR and i try to fit to samples like the one's shown above, i get an error that the sample cannot contain nulls if i try just place a null in the missing feature.

Is there a good way to deal with missing features when fitting to gpr?",2020-02-18 14:30:06
difference between irregular cardinality and outliers,1,f5j5v8,https://www.reddit.com/r/MLQuestions/comments/f5j5v8/difference_between_irregular_cardinality_and/,0,1582016252.0,,2020-02-18 14:27:32
Long Document (2000 tokens) classification,1,f5hakl,https://www.reddit.com/r/MLQuestions/comments/f5hakl/long_document_2000_tokens_classification/,4,1582008521.0,"Hello everyone!

Young datascientist, first post here!d

So I was looking for techniques for text classification, I've read tons of articles, including the one related to BERT.

The problem is that BERT and all the declined models obtained from it (fine tuned, or obtained by compression techniques such as Distillation) are designed for 512 token-sized documents.

I found that BiLSTM do great work and use less computational resources but I still think they can't capture long dependancies in documents and there are a lot of types of BiLSTM, (max pooled output, attention.. etc..) 

Overall I can't find any paper that confronts different architecture except the DocBert (2019) paper but it looks like they only keep the 512 first tokens of the docs



Do you guys have ideas or have first experience dealing with this ?

Thank you very much!",2020-02-18 12:18:41
is ID feature irregular cardinality since it adds nothing to the information?,0,f5jcyj,https://www.reddit.com/r/MLQuestions/comments/f5jcyj/is_id_feature_irregular_cardinality_since_it_adds/,0,1582017101.0,,2020-02-18 14:41:41
Production setup for 15GB model,6,f560fm,https://www.reddit.com/r/MLQuestions/comments/f560fm/production_setup_for_15gb_model/,15,1581958591.0,"Hey,

I have a 15GB SKlearn model that I'm tasked to expose through a REST api. Normally, I'd look into using Azure/Google AI platform, but they are both limited with regards to the model size.

Why such a huge model? It's partly using a natural text field in its prediction, and I've understood that this requires the model to use a decision tree which will essentially copy large parts of the training data into the model (I'm not the one who created the model). We're still working on reducing the model though, but for now this is what I've got.

My current setup is an ubuntu VM (2 cores, 30GB ram), and a small python FastAPI webserver which I've reverse proxied behind Nginx. To minimize response time, the webservice loads the model into memory and keeps it there through its lifetime. This works fine for now, but it is sort of fragile. More than 2 concurrent predictions naturally maxes both cores, and if the memory is maxed out, it crashes and restarts the service.

My current idea is to create a prebuilt docker image containing the model, and to use this as a base for building the web application in a container. Then, this can be deployed through Kubernetes, possibly with auto-scaling. My concerns however, are that the container size means that spinning up new instances will be too slow to respond to a waiting HTTP request (just starting the webservice and loading the model takes a minute or two).

Is it feasible to expose this model through an auto scaled docker setup? Or do you have any better ideas for deploying this monstrosity?",2020-02-17 22:26:31
Optimal training process,5,f576ym,https://www.reddit.com/r/MLQuestions/comments/f576ym/optimal_training_process/,1,1581966177.0,"Hey,

A couple of hours ago I posted a question concerning the [production deployment of a 15 GB model](https://www.reddit.com/r/MLQuestions/comments/f560fm/production_setup_for_15gb_model/). As I suspected, it seems the massive size of this model is the main problem, and something I should seek to tackle. The current mode is not one I created, and as such, I don't know the specifics of what preprocessing and learning algorithms are involved in its creation. However, I would love for some input from you guys on how it *should* be done.

The training set consists of three strings predicting one number of four integers. The produced numbers should be considered as classification brackets. Some numbers will be quite common, while others are rarer. Example:

    Freetext                      |Word 1      |Word 2      | Classification
    ------------------------------------------------------------------------
    This is some describing text  |1235412TXT  |534532231   |5520
    Some other describing text    |42523113    |93789TEXT   |9920

What would be your strategy for creating a model around this?",2020-02-18 00:32:57
Conv-2 CNN architecture - CIFAR-10,1,f59a9k,https://www.reddit.com/r/MLQuestions/comments/f59a9k/conv2_cnn_architecture_cifar10/,11,1581977617.0,"I have a CNN architecture for CIFAR-10 dataset which is as follows:

&#x200B;

Convolutions:           64 (filter size), 64 (filter size), pool (Max Pooling)

Fully Connected Layers: 256, 256, 10 (number of dense neurons)

Batch size:             60

Optimizer:              Adam(2e-4)

Loss:                   Categorical Cross-Entropy

&#x200B;

When I train this model, training and testing accuracy along with loss has a very jittery behavior and does not converge properly.

Is the defined architecture correct? Should I have a maxpooling layer after every convolution layer?

&#x200B;

The Conv-2 architecture is an attempted implementation of the following paper.

The following table is taken from [The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635) By: Jonathan Frankle, Michael Carbin

&#x200B;

https://preview.redd.it/n0wgh5bd3kh41.png?width=693&format=png&auto=webp&s=4b8b61acb554655178a12e778000752b6961d58f

Thanks!",2020-02-18 03:43:37
What are the differences between Tensorflow and Tensorflow Lite?,3,f55bd3,https://www.reddit.com/r/MLQuestions/comments/f55bd3/what_are_the_differences_between_tensorflow_and/,5,1581954186.0,What would be the things that I'd be sacrificing if I were to use Tensorflow Lite (on Raspberry Pi 4) instead of Tensorflow?,2020-02-17 21:13:06
Question on cross validation/parameter calculations,2,f53ikw,https://www.reddit.com/r/MLQuestions/comments/f53ikw/question_on_cross_validationparameter_calculations/,1,1581944366.0,"The concept of cross validation confuses me - once a model has been selected, trained, developed and validated - do you then use 100% of the data to calculate the final parameters (the model you present to the client)? I can't seem to find a straight answer on this. Thanks!",2020-02-17 18:29:26
Would footage from a multiple angle camera be immune to accusations being generated?,5,f4we78,https://www.reddit.com/r/MLQuestions/comments/f4we78/would_footage_from_a_multiple_angle_camera_be/,2,1581912749.0,"My question is essentially this: is it trival or non-trivial to extend realistic ""deepfake"" generation of video to a setting in which the subject is recorded from multiple angles at once and both have to be generated?

To be perfectly clear: the issue at hand is **not** if you can generate multiple angles of the same subject, but **if you can create** **video of multiple angles that correspond perfectly** (i.e. realistically when examined closely for the same subject at the same time).

My sense is that this would be non-trivially harder than generating only one angle, even if provided with a dataset of such video. But I could be wrong. Bonus points for those who can show me the math either way!",2020-02-17 09:42:29
is there any website that says which machine learning algorithms use which inductive bias?,3,f4xxfm,https://www.reddit.com/r/MLQuestions/comments/f4xxfm/is_there_any_website_that_says_which_machine/,0,1581918657.0,,2020-02-17 11:20:57
Where to find solid theoretical and practical resources BERT like transformer architectures?,7,f4tkwu,https://www.reddit.com/r/MLQuestions/comments/f4tkwu/where_to_find_solid_theoretical_and_practical/,4,1581901928.0,"I've been an NLP enthusiast for years and lately I've been trying to find some resources that help me in both understanding transformer architectures like BERT and actively teaching me how to build models from them. 

I've found myself stopping and starting quite a few times when trying to learn how to fine tune LM for downstream tasks. I've read the core papers on attention, BERT etc but I find it really hard to directly translate that theory into practice in a way I that I didn't have with computer vision for example. 

It might be the case that much of the material out there is still targeted towards full-time researchers but I'd love if anyone could point me in the right direction in terms of getting started. Thanks!",2020-02-17 06:42:08
what inductive bias does neural networks use?,0,f4zcrq,https://www.reddit.com/r/MLQuestions/comments/f4zcrq/what_inductive_bias_does_neural_networks_use/,0,1581924871.0,,2020-02-17 13:04:31
[MS Excel] Could I utilize ML to predict multiple (3+) different values based off other inputed values?,1,f4xgzs,https://www.reddit.com/r/MLQuestions/comments/f4xgzs/ms_excel_could_i_utilize_ml_to_predict_multiple_3/,7,1581916839.0,"For further clarification, I have a worksheet that contains fields about various marketing-related KPIs. I'd like to create an ideal set that drive our performance (increase number of good prospects). In the first portion of the set, I have to filter between some different column values i.e. Age_group (20-25, 25-35, etc), Region (Midwest, South, North, etc), Device_Targeting (Mobile, Computer, Tablets), etc.

All of the data is located on another sheet (""Raw Data"") on the same workbook which contains several filters/values for various columns like the three columns I mentioned above.

Let's say I've created a specific set: i.e. 20-25 (Age_group), Midwest (Region) and Mobile (Device_Targeting). In the adjacent cells, there are blanks for expected spending, number of prospects, expected views, etc. Those three columns are also found on the ""Raw Data"" sheet.

I'm stumped as to how to predict what the values for expected spending, number of prospects, and expected views would be based off what I enter originally for Age_group, Region, and Device_Targeting.

I'm not really familiar with ML so any help is appreciated, thank you!",2020-02-17 10:50:39
How to convert Pytorch (fastai) Roberta model (from transformers library) to tlite?,1,f4xdbj,https://www.reddit.com/r/MLQuestions/comments/f4xdbj/how_to_convert_pytorch_fastai_roberta_model_from/,1,1581916446.0,"Is it even possible? I have a roberta text classification model that was trained with fastai, and is in the .pkl format. How can I convert this to a tensorflow lite model? I am aware of ONNX, but based on my knowledge, that is for image networks only.",2020-02-17 10:44:06
Does Least Square Fitting Line in Linear Regression always passes through the mean of X1 and X2?,4,f4pqwk,https://www.reddit.com/r/MLQuestions/comments/f4pqwk/does_least_square_fitting_line_in_linear/,5,1581882962.0,"Suppose we are trying to fit a line of least cost function in linear regression and it has two variables X1 and X2. How strong is my assumption that the line of best fit would always pass through their mean. i.e. the line of best fit would intersect the point  (mean(X1),mean(X2))?",2020-02-17 01:26:02
Why does training my Naive Bayes Classifier take so much memory?,0,f4w5a6,https://www.reddit.com/r/MLQuestions/comments/f4w5a6/why_does_training_my_naive_bayes_classifier_take/,1,1581911850.0,"Just posted this to Stack Overflow at this link:  [https://stackoverflow.com/questions/60250397/why-does-training-my-naive-bayes-classifier-take-so-much-memory?answertab=oldest#tab-top](https://stackoverflow.com/questions/60250397/why-does-training-my-naive-bayes-classifier-take-so-much-memory?answertab=oldest#tab-top)

And just wanted to see if anyone here could help me out! This is in Python by the way, didn't see a flair to specify that.

Recently, I have been working on a project which requires Sentiment analysis of twitter data. I am using a Naive Bayes Classifier from the Textblob library, and am trying to train it with 1.6 million tweets (which can be found here if anyone is wondering: [https://www.kaggle.com/kazanova/sentiment140](https://www.kaggle.com/kazanova/sentiment140)). Just outright passing in the 1.6 million tweets causes a Memory Error, so I decided to chunk it so only 1000 tweets get trained at a time. This has minor success as I can only get to about 10,000 tweets on my local machine until my computer freezes up, because I am using too much ram. I then tried it on Google colab, so I could run my code in the cloud. With both the TPU, and the GPU, the max I have gotten too is 28,000 tweets, before the session crashed and I had to restart the runtime. Here is my code:

    with open(""shuffledlist.pickle"", 'rb') as f: #Loading in my list of 1.6 million tweets
        full_data = pickle.load(f)
    
    training_data = (tweet for tweet in full_data[:1500000]) 
    
    try:
        with open(""sentimentclassifier.pickle"", ""rb"") as file: #makes a new classifier if one doesnt exist
            classifier = pickle.load(file)
            print(""Got existing classifier"")
    except EOFError:
        classifier = NaiveBayesClassifier(full_data[:1000])
        print(""Made new classifier"")
    del full_data
    
    feeding_size = 1000
    left_splice = 0
    right_splice = feeding_size + left_splice
    
    count = 0
    new_start_time = time.time()
    past_times = 0
    
    while right_splice < 1500000:
        loop_time = time.time()
        data = itertools.islice(training_data,left_splice,right_splice)
        try:
            classifier.update(data)
        except Exception:
            print(""Houston we got a problem"")
            with open(""sentimentclassifier.pickle"", ""wb"") as sentiment:
                 pickle.dump(classifier, sentiment, protocol = -1)
            sys.exit(""Yo it ended at {} and {}"".format(left_splice, right_splice))
        past_times += time.time() - loop_time
        count += 1
        string = ""Left: {} Right: {}. Took {} seconds. Total Time Elapsed: {}. Average Time for each: {}. Count: {}.""\
            .format(left_splice, right_splice, time.time()-loop_time, time.time() - new_start_time, past_times/count, count)
        sys.stdout.write('\r' + string)
        left_splice += feeding_size
        right_splice += feeding_size
        with open(""sentimentclassifier.pickle"", ""wb"") as sentiment:
            pickle.dump(classifier, sentiment, protocol = -1)
            print(""Done dumping cycle {}!"".format(count))
    
    print(""Done! Right: {}, Left: {}!"".format(left_splice, right_splice))
    
    with open(""sentimentclassifier.pickle"", ""wb"") as sentiment:
        pickle.dump(classifier, sentiment, protocol = -1)
    
    
    print(""Training took {} seconds!"".format(time.time()-new_start_time))

Some notes:

* Since my primary problem is how big my sentimentclassifier.pickle file gets, I have tried using gzip, but it just takes way too long to open and close the file, and this is especially bad because I need to open the file every loop since I do not want to lose any progress if the program crashes.
* I switched from using lists to using generators, which did improve the speed quite significantly.
* In google colab I tried passing in 10,000 at a time, which was sort of a last ditch effort, and unsurprisingly, it did not work out for the best.
* I am not sure if nltk's Naive Bayes Classifier is more efficient, but I really want that to be a last resort, as reformatting my list of tweets may take a few hours. But if it really is more efficient I will happily redo my code if it means I can get this working.

Thank you and any advice will be greatly appreciated!",2020-02-17 09:27:30
Why is LSTM better than a dense NN with a flatten version of the sequence in input?,5,f4omzq,https://www.reddit.com/r/MLQuestions/comments/f4omzq/why_is_lstm_better_than_a_dense_nn_with_a_flatten/,6,1581875572.0,"I'm not understanding clearly why a LSTM is supposed to be so much better than a classic NN receiving a flatten version of the same input sequence.  

Can you explain what makes it conceptually superior?",2020-02-16 23:22:52
How do you encode categorical variable into DummyVariables using OneHotEncoder in sklearn 0.22,1,f4q8z3,https://www.reddit.com/r/MLQuestions/comments/f4q8z3/how_do_you_encode_categorical_variable_into/,0,1581886212.0," Hi, I am new to ML and was working on a dataset which has a column of Categorical Variables, and it had three different types and I used LabelEncoder to encode the data to 0,1,2 ; now what I wanted to do was to create dummy variables using OneHotEncoder:

'''from sklearn.preprocessing import LabelEncoder,OneHotEncoder  
labelencoder\_X = LabelEncoder()  
X\[:,3\] = labelencoder\_X.fit\_transform(X\[:,3\])  
onehotencoder = OneHotEncoder(categorical\_features=\[3\])  
X = onehotencoder.fit\_transform(X).toarray() '''

I used pyCharm as IDE and I got the error: TypeError: **init**() got an unexpected keyword argument 'categorical\_features'

While searching through the internet I only got to know that the 'categorical\_feature' thing is changed in sklearn 0.22 , but was unable to find what to do in newer version.

Any help will be appreciated.",2020-02-17 02:20:12
DQN network running but agent is not improving,0,f4p6vp,https://www.reddit.com/r/MLQuestions/comments/f4p6vp/dqn_network_running_but_agent_is_not_improving/,0,1581879294.0,"Edit: I'm using Pytorch

Hi, I’m new to machine learning and Programming in general. I’m trying to get a DQN to beat the OpenAI gym Mountain car-v0 game. the code runs without any errors but does not seem to improve at the game at all. I ran 50,000 episodes and the average score over past 100 episodes remained unchanged at -200. This is the code. If anyone is willing to go through it and let me know what I’ve done wrong I would greatly appreciate it.

import numpy as npimport randomimport osimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimimport gymsample\_size = 25# Creating the architecture of the Neural Networkclass Network(nn.Module):

def \_\_init\_\_(self, input\_size, nb\_action):super(Network, self).\_\_init\_\_()self.input\_size = input\_sizeself.nb\_action = nb\_actionself.fc1 = nn.Linear(input\_size, 30)self.fc2 = nn.Linear(30, nb\_action)

def forward(self, state):        x = F.relu(self.fc1(state))        q\_values = self.fc2(x)return q\_values# Implementing Experience Replayclass ReplayMemory(object):

def \_\_init\_\_(self, capacity):self.capacity = capacityself.memory = \[\]

def push(self, event):self.memory.append(event)if len(self.memory) > self.capacity:del self.memory\[0\]

def sample(self, batch\_size):        samples = zip(\*random.sample(self.memory, batch\_size))with torch.no\_grad():return map(lambda x: torch.cat(x, 0), samples)# Implementing Deep Q Learningclass Dqn():

def \_\_init\_\_(self, input\_size, nb\_action, gamma):self.gamma = gammaself.model = Network(input\_size, nb\_action)self.memory = ReplayMemory(100000)self.optimizer = optim.Adam(self.model.parameters(), lr = 0.001)self.last\_state = torch.Tensor(input\_size).unsqueeze(0)self.last\_action = 0self.last\_reward = 0

def select\_action(self, state):        state\_transformed = torch.Tensor(state).float().unsqueeze(0)        probs = F.softmax(self.model(state\_transformed)\*100, dim= 1) # T=100        action = probs.multinomial(1)self.last\_action = action.data\[0,0\]self.last\_state = state\_transformedreturn action.data\[0,0\]

def learn(self, batch\_state, batch\_next\_state, batch\_reward, batch\_action):        outputs = self.model(batch\_state).gather(1, batch\_action.unsqueeze(1)).squeeze(1)        next\_outputs = self.model(batch\_next\_state).detach().max(1)\[0\]          target = self.gamma\*next\_outputs + batch\_reward        td\_loss = F.smooth\_l1\_loss(outputs, target)self.optimizer.zero\_grad()        td\_loss.backward(retain\_graph = True)self.optimizer.step()

def update(self, reward, new\_signal):        new\_state = torch.Tensor(new\_signal).float().unsqueeze(0)self.memory.push((self.last\_state, new\_state, torch.LongTensor(\[int(self.last\_action)\]), torch.Tensor(\[reward\]))) if len(self.memory.memory) > sample\_size:            batch\_state, batch\_next\_state, batch\_action, batch\_reward = self.memory.sample(sample\_size)self.learn(batch\_state, batch\_next\_state, batch\_reward, batch\_action)

self.reward\_window.append(reward)if len(self.reward\_window) > 1000:del self.reward\_window\[0\]return action

def score(self):return sum(self.reward\_window)/(len(self.reward\_window)+1.)

def save(self):        torch.save({'state\_dict': self.model.state\_dict(),'optimizer' : self.optimizer.state\_dict(),                   }, 'Brain\_save\_1.pth')

def load(self):'''        loads brain        '''if os.path.isfile('Brain\_save\_1.pth'):print(""=> loading checkpoint... "")            checkpoint = torch.load('Brain\_save\_1.pth')self.model.load\_state\_dict(checkpoint\['state\_dict'\])self.optimizer.load\_state\_dict(checkpoint\['optimizer'\])print(""done !"")else:print(""no checkpoint found..."")

if \_\_name\_\_ == '\_\_main\_\_':    env = gym.make('MountainCar-v0')    EPISODES = 25000    show\_every = 500    save\_check = 24998    scores =\[\]    env.reset()

brain = Dqn(2, env.action\_space.n, 0.95)    brain.load()for episode in range(EPISODES):        score = 0        done = False        obs = env.reset()        reward = 0if (episode == save\_check):          brain.save()print('File saved')while not done:            action = brain.select\_action(obs).item()            obs\_,reward,done,info = env.step(action)            brain.update(reward,obs\_)            obs = obs\_            score += reward         scores.append(score)if episode % show\_every == 0:            avg\_score = np.mean(scores\[-100:\])print('episode ', episode, 'score %.1f avg score %.1f' %(score, avg\_score))",2020-02-17 00:24:54
What kinds of problems are neural networks used for?,12,f4dxes,https://www.reddit.com/r/MLQuestions/comments/f4dxes/what_kinds_of_problems_are_neural_networks_used/,14,1581822186.0,,2020-02-16 08:33:06
Two questions about Lambda layers in Keras,3,f4hsa9,https://www.reddit.com/r/MLQuestions/comments/f4hsa9/two_questions_about_lambda_layers_in_keras/,0,1581838405.0,"So, I have as input two (n,n,1)-shaped greyscale images, and one single number. I want a layer that takes these three inputs, and outputs something that's shaped (n,n,2), achieved by simply taking one image to be one channel and the other image to be the other, with the choice of which is which determined by whether the third input is less than or greater than zero.

So, two questions:

1. Practically, how do I code this? I'm not great at understanding the whole tensors thing.
2. How does it handle training with such a layer inbetween? In my setting this shouldn't be a problem, since there will only ever be trainable weights either above or below this layer but never both above and below, but in general, it seems difficult to train with Lambda layers that might do all sorts of stuff?",2020-02-16 13:03:25
Reporting results of k-fold validation,1,f4kcb7,https://www.reddit.com/r/MLQuestions/comments/f4kcb7/reporting_results_of_kfold_validation/,0,1581850229.0,"I'm working with a small dataset and using k-fold validation so I can give each subject a predicted value. Is it reasonable to report summary statistics re sensitivity/specificity (precision/recall/etc) on the whole dataset rather than as an average between all the folds? I suppose you loose some of the information about how the model's performance varies as the training sample varies, but I feel like overall performance would still be reflected in the results if you combine the predictions?",2020-02-16 16:20:29
Car Damage Detection using Computer Vision,2,f4fgfk,https://www.reddit.com/r/MLQuestions/comments/f4fgfk/car_damage_detection_using_computer_vision/,5,1581828462.0,"I am working on project where I have to detect what are the different damaged parts of the car for the Insurance Claim. I will also have to classify those identified damaged part based on severity of damage.


How should I approach this problem?",2020-02-16 10:17:42
machine learning and system penetration / vulnerability scanning,0,f4gkcr,https://www.reddit.com/r/MLQuestions/comments/f4gkcr/machine_learning_and_system_penetration/,1,1581833039.0,"why has nobody used machine learning to break into systems ? i mean the one thing that ML n needs is a big data set of indexed example data to train from .. which there is tons of for security vulnerabilities... and one of the things ML often does is find completely new ways of arriving at the same result ... imo it kinda seems like machine learning and finding vulnerabilities in systems were meant for each other

that being said, I assume this has been considered before and im not inadvertently triggering the apocalypse here.   Preventing bugs and vulnerabilities in my applications is crucial as a sysadmin and programmer so if I can use ML to find things ive missed bug or security wise I want to try.",2020-02-16 11:33:59
Why is the decision tree algorithm used in data mining?,3,f4901f,https://www.reddit.com/r/MLQuestions/comments/f4901f/why_is_the_decision_tree_algorithm_used_in_data/,5,1581799821.0,what are the advantages of the decision tree algorithm that make it suitable for data mining?,2020-02-16 02:20:21
"Given the coefficients of a SVM Classifier, how can we make predictions using pen and paper?",3,f48yju,https://www.reddit.com/r/MLQuestions/comments/f48yju/given_the_coefficients_of_a_svm_classifier_how/,8,1581799573.0,"When I say pen and paper it doesn’t mean pen and paper, but general maths. 

So if I have trained a SVM classifier using a framework, and extracted the coefficients. Is it possible to predict?",2020-02-16 02:16:13
example of induction bias,1,f4dg5v,https://www.reddit.com/r/MLQuestions/comments/f4dg5v/example_of_induction_bias/,1,1581820264.0,"im still trying to understand induction bias. im trying to use examples to help me wrap my head around it. what would be an example of induction bias for predicting the amount of rainfall in a day?

if you have any other examples that would be very helpful",2020-02-16 08:01:04
Why doesn't SMOTE hurt performance?,1,f4d5fv,https://www.reddit.com/r/MLQuestions/comments/f4d5fv/why_doesnt_smote_hurt_performance/,1,1581819053.0,"I am working with a highly imbalanced dataset (4%, 23%, 73%) and I get \~73% accuracy due to the majority class always being predicted. When using SMOTE to balance the dataset, I converge to 33.33% accuracy, which intuitively makes sense since it can no longer guess the majority class.

It seems daunting to raise accuracy from 33.33% to 73% through feature/model engineering for some datasets. Why doesn't this significant drop in accuracy happen for other imbalanced datasets such as credit card fraud detection. If it does, is the workaround simply to improve the model until it beats majority class performance?",2020-02-16 07:40:53
What is labeled and unlabeled data?,1,f4bct3,https://www.reddit.com/r/MLQuestions/comments/f4bct3/what_is_labeled_and_unlabeled_data/,10,1581811530.0,,2020-02-16 05:35:30
what distribution type would this histogram be?,0,f4hb91,https://i.redd.it/254uav8646h41.png,4,1581836311.0,,2020-02-16 12:28:31
ML for cyclist to classify tailing motorists,0,f4a6wg,https://www.reddit.com/r/MLQuestions/comments/f4a6wg/ml_for_cyclist_to_classify_tailing_motorists/,2,1581806232.0,"Hi. Am new to Reddit and to ML so pls be gentle. 

I am a long time Linux admin and tinkerer and wanted to tech myself ML. I am also a long time cycle commuter (city and road) thus thought it a good idea to combine the two.

Why tailing motorists? Well, they can be aggressive, attempt a close pass, deviate into your line and a multiple of other issues.

Why not a rear view mirror? I want the images and plates, maybe post nice videos on twitter every now and then.

Can this be done? What kind of battery-powered HW would be necessary? Where to start looking?

Many thanks!!",2020-02-16 04:07:12
"would null count as a cardinality of a feature, if there is missing data?",7,f3urfv,https://www.reddit.com/r/MLQuestions/comments/f3urfv/would_null_count_as_a_cardinality_of_a_feature_if/,3,1581727205.0,,2020-02-15 06:10:05
What to do if dome of your data was bad,0,f3zdmf,https://www.reddit.com/r/MLQuestions/comments/f3zdmf/what_to_do_if_dome_of_your_data_was_bad/,2,1581745611.0,"If some of your feature input data was bad, insorder for it not to effect the model, what would you do? When i mean bad i mean wrong data like minus values, outliers and empty inputs",2020-02-15 11:16:51
Predicting next frame in timeseries of images,12,f3o1mu,https://www.reddit.com/r/MLQuestions/comments/f3o1mu/predicting_next_frame_in_timeseries_of_images/,6,1581689639.0,"I am trying to make a model that predicts cloud movement using a timeseries of images. So far I've tried using convolutions, convlstm2d and just simply flattening the image out and using regular LSTMs to predict the next image, but it doesn't seem to give any remotely useful predictions. It seems like the LSTMs is just remembering the frame at t-2, and giving that as an output. Convolutions meanwhile converge very slowly and their outputs seem quite random.

Been at it for a few days but to no avail. Also, does anyone know how to get keras to flow from directory for images? I know it can be done for categorical data, but not too sure how this should be done for image-to-image regression",2020-02-14 19:43:59
Keras LSTM text classification differing shape for train and test?,1,f3uhy9,https://www.reddit.com/r/MLQuestions/comments/f3uhy9/keras_lstm_text_classification_differing_shape/,6,1581726128.0,"Hello,

I am working on a text classification problem in which I am feeding GloVe embeddings into an LSTM network. I have preprocessed the text and perform the following below:

    max_features = 300  
    tokenizer = Tokenizer(num_words=max_features, split=' ') tokenizer.fit_on_texts(train['text'].values) 
    train_f = tokenizer.texts_to_sequences(train['text'].values) 
    word_index = tokenizer.word_index #used for word embeddings 
    train_f = pad_sequences(train_f) 

The shape of train\_f is: (25000, 1225). I then performed the same on the test set:

    max_features = 300  
    tokenizer = Tokenizer(num_words=max_features, split=' ') tokenizer.fit_on_texts(test['text'].values) 
    test_f = tokenizer.texts_to_sequences(test['text'].values) 
    test_f = pad_sequences(test_f) 

This resulted in a test shape of: (25000, 1223). When going ahead and loaded the embeddings in and fit the network. I am unable to predict on the testing set as I get the error:

    ValueError: Error when checking input: expected embedding_2_input to have shape (1225,) but got array with shape (1223,) 

I cannot seem to spot my mistake. Any help would be much appreciated!",2020-02-15 05:52:08
"Data continuous feature, total number of instances",0,f3ti39,https://www.reddit.com/r/MLQuestions/comments/f3ti39/data_continuous_feature_total_number_of_instances/,6,1581721928.0,"our lecturer gave us an assignment where we fill out a table with calculations, this is the data we were given

&#x200B;

https://preview.redd.it/293hvrfsnwg41.png?width=818&format=png&auto=webp&s=cbd5e2177ed06ba2a717c20e59f4fc3246cfea5c

this is what I have filled in the table so far 

&#x200B;

https://preview.redd.it/4vltagvwnwg41.png?width=897&format=png&auto=webp&s=f2d99bbd25d29b91b3d00e0da970b762458d2d11

my question is what does she mean by ""total number of instances""?",2020-02-15 04:42:08
Finding the criterion of the Features,1,f3r17q,https://www.reddit.com/r/MLQuestions/comments/f3r17q/finding_the_criterion_of_the_features/,2,1581709343.0,"Hi, I have done binary classification using DRF in h2o. I have got the feature importance, then I have asked to find the criterion of each feature. E.g: I have to classify the user which to accept and which to reject and the features are age, salary, work_experience, live city (already decoded of course). So, my boss wanted to know which range of ages is the tendency of users got rejected or accepted, which range of salaries, which cities that have tendency got rejected or accepted.

How to achieve that?",2020-02-15 01:12:23
State-of-the-art NLP,0,f3q1su,https://www.reddit.com/r/MLQuestions/comments/f3q1su/stateoftheart_nlp/,1,1581702812.0,Please what's the best way I can use GPT2 to summarize text,2020-02-14 23:23:32
"I had chosen the title ""To optimize laser machining of PCB using ANN method"". Can anyone tell me how does ANN method helps in optimizing laser machining",0,f3rftd,https://www.reddit.com/r/MLQuestions/comments/f3rftd/i_had_chosen_the_title_to_optimize_laser/,1,1581711745.0,,2020-02-15 01:52:25
"K-Fold Cross Validation, how do I use it to evaluate a single model?",2,f3kpmw,https://www.reddit.com/r/MLQuestions/comments/f3kpmw/kfold_cross_validation_how_do_i_use_it_to/,13,1581673027.0,"I'm doing some images classification and I'm using transfer learning and fine-tuning.  


I'm using a typical 80:20 split for train and test. Then the train set is split 80:20 into train and validate. I'm loading a network pretrained on imagenet without  the top classifcation layer.  I freeze the base network and add a new classifier, then train on my train dataset. Then I retrain the network on the same train data.  


I was getting ok results then someone pointed out that I should verify using kfold cross validation because my split might be what's giving me those results.  


I was reading up on K-fold CV and it seems like its mainly for choosing between different models. But I don't want to test different configurations, I just want to use the same configuration and see how well it works on the different splits.  


I randomly split my data again using an 80:20 split for train and test. Then I split the train data into 10 folds.

  
I then train on k-1 folds and leave one for validation. I repeat the same fine tuning process I described before with the same k-1 folds and one for validation. I record the final training accuracy, validation accuracy and the evaluation metrics on the TEST set such as accuracy, f1 score etc.

The steps above are repeated for all kfolds.

So. I'm kinda stuck here. I've gotten a lot of overfitting after the fine tuning process. Also I'm not sure if what I'm doing makes any sense. And again how do I use my results on each fold to give an estimation of the model's skill?  


Sorry for the long question. Thanks again.",2020-02-14 15:07:07
Installing packages in google colab from a .whl,1,f3n5sh,/r/GoogleColab/comments/f3mzdn/installing_packages_in_google_colab_from_a_whl/,0,1581684873.0,,2020-02-14 18:24:33
Educator interested in the future of text auto-summarization,5,f3dh94,https://www.reddit.com/r/MLQuestions/comments/f3dh94/educator_interested_in_the_future_of_text/,6,1581644013.0,"I'm not sure if this is the right subreddit for me to attain this information, but given how closely auto-summarization is to ML and NLP, I thought it might be a good start.

I am in the process of learning more about auto-summarization and how I can use it to help children with various learning disabilities. While most of what I can find summarizes copy and pasted text from a computer, do you ever see the technology being sophisticated enough to take a picture of text in a textbook and have it summarized?

Is there anywhere that I can read more about where this technology is headed? I am currently putting together a funding proposal and am exploring as much assistive technology as possible.",2020-02-14 07:03:33
GBMs (or alternatives?) for regression of inputs not in the training data.,2,f3di8m,https://www.reddit.com/r/MLQuestions/comments/f3di8m/gbms_or_alternatives_for_regression_of_inputs_not/,0,1581644128.0,"I have data that looks a lot like the following plots (http://download.tuxfamily.org/eigen/btl-results-110323/axpy.pdf) and I am trying to use lightGBM to do a regression on a few categories such as openmp threads, openmp affinity, and vector size. 

LightGBM is able to match the data surprisingly well as long as I have training examples at every vector size in my test set, but if I remove data from the training such as completely dropping a vector size input (unlike the example plot, I can only evaluate my input in large step sizes so I won't necessarily have a training sample close to the missing input), then lightGBM tends to just fit that point with the exact same value as one of the adjacent sizes that was in the training data. This is probably unsurprising giving the way that I understand decision trees to work, but it is not the behavior that I want in my model. I would like it to do something more like a weighted average of the closest training points that it did see, so that more likely than not putting in a larger vector size leads to a larger time or flops estimate

What options do I have to get GBMs to do this and/or what other types of models should I consider (I have played around a little bit with sklearn's Gaussian Processes, but with default parameters I get poor behavior for the missing sizes as well)?",2020-02-14 07:05:28
tensorflow python neural network dataset with PNG files,4,f3a8v9,https://www.reddit.com/r/MLQuestions/comments/f3a8v9/tensorflow_python_neural_network_dataset_with_png/,4,1581630623.0,"hi, just trying to make a machine learning algorithm which can depict between different gestures. i have the datasets in png files. how do i import this into tensorflow? i understand how to use online URL datasets but currently lost when trying to import local files on my machine. is there a link that someone can direct me to? thanks for any input",2020-02-14 03:20:23
State-of-the-Art Network architecture for Semantic segmentation?,3,f39i7r,https://www.reddit.com/r/MLQuestions/comments/f39i7r/stateoftheart_network_architecture_for_semantic/,5,1581627027.0,"Hello, so me and some of my co-students, are working with bin-picking and want to make a neural net which takes in, among other features, a semantic segmented map, which we thus need to ""develop"" and train. The thing is, that reading articles and going through YouTube is seems that there are so many different NNs solving this task with different architectures so picking ones above others is very difficult.

We will have 7 different classes, which are mostly different in terms of colour and they will be randomly placed in a small 30x30 cardboard box.

Do anyone in this subreddit, have some experiences to share? We were thinking about trying U-net and SegNet. Any pros/cons for those?

Any help is greatly appreciated!",2020-02-14 02:20:27
What is appropriate layer for using Grad-CAM with MobileNet and ResNet50?,2,f3as8o,https://www.reddit.com/r/MLQuestions/comments/f3as8o/what_is_appropriate_layer_for_using_gradcam_with/,0,1581633075.0,"From the grad cam paper, the authors suggest to use it with the last convolutional layer of the network e.g. in VGG16 you would use block 5 convolution 3, which is the last convolutional layer before max pooling in the base network.  


With MobileNet and ResNet its not so clear to me which is really the last convolutional layer. MobileNet for example has depthwise and pointwise convolutions. 

  
conv\_dw\_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      

conv\_dw\_13\_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

conv\_dw\_13\_relu (ReLU)       (None, 7, 7, 1024)        0         

conv\_pw\_13 (Conv2D)          (None, 7, 7, 1024)        1048576   

conv\_pw\_13\_bn (BatchNormaliz (None, 7, 7, 1024)        4096      

conv\_pw\_13\_relu (ReLU)       (None, 7, 7, 1024)        0          


 

I'm using tf.Keras and I'm not too sure which one would be more ""correct"":  
 conv\_dw\_13,   
conv\_pw\_13,   
or the output at conv\_pw\_13\_relu which is the last layer of the base of the network.  


Thanks for any suggestions",2020-02-14 04:01:15
What's the current state-of-the-art in Paraphrase Generation?,1,f3due5,/r/learnmachinelearning/comments/f3du6o/whats_the_current_stateoftheart_in_paraphrase/,0,1581645459.0,,2020-02-14 07:27:39
Train a model on a sub-set of the dataset,1,f39xqg,https://www.reddit.com/r/MLQuestions/comments/f39xqg/train_a_model_on_a_subset_of_the_dataset/,1,1581629144.0,"I'm quite a beginner in machine learning and I'm looking for a object detector for detecting people. I've found this PyTorch implementation of EfficientDet ( [https://github.com/toandaominh1997/EfficientDet.Pytorch](https://github.com/toandaominh1997/EfficientDet.Pytorch) ) and a pre-trained model mentioned in the Git repo.

However, the model is trained on PASCAL VOC which contains multiple classes. My intention is to train this model on just persons, so that my detector obviously detects and shows only persons.

The problem is I don't really know how to adjust the solution to train a new model on for example CoCo dataset, but only people. My assumptions are:

1. clean the dataset and leave only people in it and train the model on only that
2. adjust the detector code to only display the detected people

However, I see a few problems with these approaches:

\- with the #1 approach, it obviously takes some time to clean the dataset

\- with the #2 approach, training and detection(inference) takes a lot more time since it has to detect more object classes, even though I only display one.

Also, I need to evaluate the performance of the model on only detecting people. If I use option #1, I think the mAP metric is easy to use. However, with approach #2, mAP will calculate for all classes so, I won't get a reliable score (or can I just find the mAP for ""person"" class?).

Any tips and hints are greatly appreciated.",2020-02-14 02:55:44
What separates amazing ML engineers to good ones,21,f2xqkr,https://www.reddit.com/r/MLQuestions/comments/f2xqkr/what_separates_amazing_ml_engineers_to_good_ones/,7,1581568987.0,"Hey guys, I just recently became a machine learning / computer vision engineer and want to be able to train / perform to my top potential as well as goals that will help me become better. As a result of being a bit inexperienced, I don't have a good eye from good to excellent traits. 

&#x200B;

In your opinion, what separates great/amazing ML engineers that a good one? What makes top ML / CV engineers stand out from the rest?",2020-02-13 10:13:07
T- Test as a feature selection method,1,f396m3,https://www.reddit.com/r/MLQuestions/comments/f396m3/t_test_as_a_feature_selection_method/,7,1581625349.0,"Is it possible to use t-test as a feature selection method for binary classification problems?

I have a dataset of 660 features per 75 patients (to be classified as 0 - 1). In order to reduce the number of features and using only statistically significant one, I was thinking of performing t-test for each feature (the two population would be the 0s and the 1s).

Is there any paper or anyone that could help me understand whether it is doable, or has any scientific literature to support me?",2020-02-14 01:52:29
Help with choice of architecture,1,f38yk7,https://www.reddit.com/r/MLQuestions/comments/f38yk7/help_with_choice_of_architecture/,2,1581624168.0," Hi everyone,

I've decided to learn pytorch and ML, and I have completed andrew ng's course on coursera and after that I read the book about pytorch which they have on their website. After that I tried a couple of tutorials for image recognition/classification.

Now, I would like to make a nn that can ""restore"" old images, so i figured I could get a set of RGB images, turn them to greyscale, add some noise or whatever to make them look like old photos and use that as my train set.

My question is, can I make a NN with 3x more outputs than inputs (rgb having 3 channels vs greyscale having 1), do any of you have any experience with that, and can someone provide me with guidance as to what types of layers/activation functions etc should be used in this case?

Thank you all in advance. Big love

Milorad",2020-02-14 01:32:48
MACHINE LEARNING MODELS HELP,0,f36hdz,https://www.reddit.com/r/MLQuestions/comments/f36hdz/machine_learning_models_help/,11,1581608300.0,"Hey Guys,

Im fairly new to all this machine learning information, I was recently given a task in school where I have to deploy a machine learning model, however, Heroku has rejected the deployment because the package size is frankly too large. I have already tried using an ignore file but the package is simply too big.

Furthermore, all of these packages are computationally expensive and take an absurd amount of time. Its infeasible to run any of the packages in real time.

The ML models take hours to train and while the models assess new customer data the consumers have to wait minutes for this to finish.

Please help a guy out",2020-02-13 21:08:20
A little question about YOLOv3 paper,2,f3266f,https://www.reddit.com/r/MLQuestions/comments/f3266f/a_little_question_about_yolov3_paper/,0,1581586952.0,"In  ""Bounding Box Prediction"" section of the paper, the author said that :

&#x200B;

>*During training we use sum of squared error loss. If the ground truth for some coordinate prediction is t' our gradient is the ground truth value (computed from the ground truth box) minus our prediction: t' − t .* 

( For easy reading, I change the notation. )  


My question is why the gradient is t'-t ? How to derive this result ?",2020-02-13 15:12:32
Keras CNN layers throwing a value error,0,f34b13,https://www.reddit.com/r/MLQuestions/comments/f34b13/keras_cnn_layers_throwing_a_value_error/,6,1581596636.0,"Hi.  


I'm building a 9-layer CNN model for behavioral cloning and my Keras is throwing the following error:

    Using TensorFlow backend.
    ------------------------------
    Parameters
    ------------------------------
    data_dir             := data
    test_size            := 0.2
    keep_prob            := 0.5
    nb_epoch             := 10
    samples_per_epoch    := 20000
    batch_size           := 40
    save_best_only       := True
    learning_rate        := 0.0001
    ------------------------------
    2020-02-12 23:20:23.577149: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
    To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
    2020-02-12 23:20:23.616331: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294715000 Hz
    2020-02-12 23:20:23.617174: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559280481630 executing computations on platform Host. Devices:
    2020-02-12 23:20:23.617204: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
    2020-02-12 23:20:23.618958: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
    Traceback (most recent call last):
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1610, in _create_c_op
        c_op = c_api.TF_FinishOperation(op_desc)
    tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 5 from 1 for 'conv2d_5/convolution' (op: 'Conv2D') with input shapes: [?,1,18,64], [5,5,64,64].
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""/home/onur/Documents/behavirol-cloning-carla/Model.py"", line 91, in <module>
        main()
      File ""/home/onur/Documents/behavirol-cloning-carla/Model.py"", line 86, in main
        model = build_model(args)
      File ""/home/onur/Documents/behavirol-cloning-carla/Model.py"", line 32, in build_model
        model.add(Conv2D(64, (5, 5), activation='elu'))
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py"", line 182, in add
        output_tensor = layer(self.outputs[0])
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 75, in symbolic_fn_wrapper
        return func(*args, **kwargs)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py"", line 489, in __call__
        output = self.call(inputs, **kwargs)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/keras/layers/convolutional.py"", line 171, in call
        dilation_rate=self.dilation_rate)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 3717, in conv2d
        **kwargs)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 917, in convolution_v2
        name=name)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 1009, in convolution_internal
        name=name)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d
        data_format=data_format, dilations=dilations, name=name)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper
        op_def=op_def)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 548, in create_op
        compute_device)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal
        op_def=op_def)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1773, in __init__
        control_input_ops)
      File ""/home/onur/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1613, in _create_c_op
        raise ValueError(str(e))
    ValueError: Negative dimension size caused by subtracting 5 from 1 for 'conv2d_5/convolution' (op: 'Conv2D') with input shapes: [?,1,18,64], [5,5,64,64].

This is the full question: [https://stackoverflow.com/questions/60156911/keras-cnn-layer-throwing-a-valueerror](https://stackoverflow.com/questions/60156911/keras-cnn-layer-throwing-a-valueerror)",2020-02-13 17:53:56
Questions on learning materials for a newbie,7,f2rpqs,https://www.reddit.com/r/MLQuestions/comments/f2rpqs/questions_on_learning_materials_for_a_newbie/,3,1581545236.0,"I’m an undergraduate aerospace engineering major. I’ve grown to learn that there is huge potential in applying Machine learning and AI to aerospace products/manufacturing. I have learned the basic programming skills and can write basic scripts and from my aerospace classes, I believe I have the pre-requisite mathematics (Linear algebra, Vector Calculus, Calculus etc). However, I do not know how to put everything together to create machine learning based systems like voice or image recognition etc. What learning materials did you use or what learning materials do you suggest to help me learn the basics and get started.

I’m not necessarily trying to get my hands into ML/AI as a career as at now (Id probably need a Phd) but I’m just trying to get started on my own projects. If I enjoy it so much and get good at it, then it is what it is.",2020-02-13 03:37:16
What would you use for Keyword-Based Sentence Generation?,2,f2u7kd,/r/LanguageTechnology/comments/f2u1fe/what_would_you_use_for_keywordbased_sentence/,0,1581555433.0,,2020-02-13 06:27:13
"Classify Texts with TensorFlow and Twilio to Answer Loves Me, Loves Me Not",1,f2xnc2,https://www.twilio.com/blog/classify-texts-with-tensorflow-and-twilio-to-answer-loves-me-loves-me-not,0,1581568641.0,,2020-02-13 10:07:21
Multi-Task Learning Literature,1,f2w3fe,https://www.reddit.com/r/MLQuestions/comments/f2w3fe/multitask_learning_literature/,0,1581562702.0,"I was wondering if anyone has any links to papers that describe topics involving Multi-task learning?

I am interested in how SOTA models structure their loss along with general training strategies.",2020-02-13 08:28:22
Multi-Task Learning Literature,0,f2vxfy,https://www.reddit.com/r/MLQuestions/comments/f2vxfy/multitask_learning_literature/,0,1581562044.0,"I was wondering if anyone has any links to papers that describe topics involving Multi-task learning?

I am interested in how SOTA models structure their loss along with general training strategies.",2020-02-13 08:17:24
Multi-Task Learning Literature,0,f2vvga,https://www.reddit.com/r/MLQuestions/comments/f2vvga/multitask_learning_literature/,0,1581561830.0,"I was wondering if anyone has any links to papers that describe topics involving Multi-task learning?

I am interested in how SOTA models structure their loss along with general training strategies.",2020-02-13 08:13:50
Use of dot product instead of element wise multiplication,2,f2rork,https://www.reddit.com/r/MLQuestions/comments/f2rork/use_of_dot_product_instead_of_element_wise/,1,1581545110.0,Why is that during our feed forward of neural network we go for dot product instead of element wise multiplication?,2020-02-13 03:35:10
Implementing Surprise SVD for a Book Recommender,1,f2q2yf,https://www.reddit.com/r/MLQuestions/comments/f2q2yf/implementing_surprise_svd_for_a_book_recommender/,1,1581537162.0,"I'm trying to develop a basic book recommender so I can get my hands on a more complicated project after learning some of the basics.

I have general book information like title, author, genres, publishing date ..., I've used that to make a simple recommender using countVectorizer and cosine similarity, it works pretty well even though it's just recommendations based on certain parameters (genre, author).

I also have certain user information:

Type: indicates if it is a purchase (order) or access to a book file (access)

Number: in case the type is access, how many times has the user accessed that book file.

Username: the user that is performing the actions

Product: basically the book id.

(also order date, price of the book, model of the book).

I'm trying to implement the SVD algorithm but instead of using ratings (as I don't have that parameter) I want to use purchases.

My first step was cleaning the data-frame: I've just kept the orders and discarded the accesses, and I grouped the purchases of the same book by the same user, so now I have a data-frame that is just: username, product and count, where count is the amount of products that username bought.

My doubt here is how can I use that count parameter as a 'rating', I've been thinking of normalizing it but don't really know how (it's my first time working with this kind of algorithm).

My second doubt is I don't really understand the output of SVD and how to return a recommendation based on a username, I've tried this:

\>>> reader = Reader()

\>>> data = Dataset.load\_from\_df(order\_df\[\['username', 'product', 'count'\]\], reader)

\>>> trainset, testset = train\_test\_split(data, test\_size=0.2)

\>>> algo = SVD()

\>>> [algo.fit](https://algo.fit/)(trainset)

\>>> predictions = algo.test(testset)

\>>> print(predictions)

\[Prediction(uid='kerrigan', iid=1023897, r\_ui=1.0, est=2.2, details={u'was\_impossible': False}), Prediction(uid='john5', iid=130365, r\_ui=1.0, est=2.3876092212527076, details={u'was\_impossible': False})\]

But I don't really know how to work with that output to achieve my goal and I'm desperate for some help, I've been searching on google for some articles that might be handy but all of the SVD information I've found is ratings related...",2020-02-13 01:22:42
Is it avised to put BatchNorm everywhere?,0,f2puir,https://www.reddit.com/r/MLQuestions/comments/f2puir/is_it_avised_to_put_batchnorm_everywhere/,9,1581535751.0,"Batchnorm helps (as claimed by the paper) with the internal shift of distributions within layers. No doubt it helps, this has been verified countless times.

However, from a purely practical point of view, i notice that practitioners are putting batchnorm behind every convolution / linear projection.

Considering the significant memory overhead, isn't that a bit exaggerated?",2020-02-13 00:59:11
Using a pretrained CNN for object detection in SSD,1,f2prri,https://www.reddit.com/r/MLQuestions/comments/f2prri/using_a_pretrained_cnn_for_object_detection_in_ssd/,0,1581535298.0,"I have created a CNN that can classify Cars, Cows, Bikes and Humans and now want to use it as part of my object detection with SSD but have no idea how. Any help would be great.",2020-02-13 00:51:38
"Cost Function not being minimized, Cost goes to about 44,000",13,f2evu0,https://i.redd.it/yr7ry3s2zcg41.png,15,1581483442.0,,2020-02-12 10:27:22
Trouble with LSTM input shape,1,f2nkq6,/r/deeplearning/comments/f2nkbb/trouble_with_lstm_input_shape/,2,1581521309.0,,2020-02-12 20:58:29
"Can we try to reduce overfitting by analyzing for ""outliers"" in gradients?",2,f2idj8,https://www.reddit.com/r/MLQuestions/comments/f2idj8/can_we_try_to_reduce_overfitting_by_analyzing_for/,8,1581497115.0,"This is just a hypothetical thought that came across my mind and I was wondering if it has any potential.

TLDR: Skip to the Solution section

TLDR 2: What if instead of performing gradient descent the traditional way, we calculate two gradients g\_A and g\_B from two separate partitions of the training data and backpropagate g\_A⋅g\_B / (norm(g\_A) norm(g\_B)) \* g\_A instead of using just the gradients from one batch.

# Background

Typically, in most deep learning methods, we compute the gradient of some cost function `J` over all samples in a batch, average those gradients, and update our parameters θ by subtracting these gradients (scaled by a learning rate). Obviously, there are many different optimizers that do this update step differently, but irregardless, they're all some form of gradient descent.

# Motivation

When we perform gradient descent, if I understand correctly, we're trying to maximize some form of the log likelihood of the training data (i.e. maximize how well our model parameters explain the dataset). However, we can sometimes overfit the training data if our gradient descent brings us to a solution that's too well fit for the training data, and thus is no longer the optimal solution for ""real world"" data (like the test set).

# Solution...?

What if during our training process, we account for the fact that our training set doesn't completely represent the ""real world"" (test) data; that although we can have very similar distributions between the training data and test data, they're not identical.

More specifically, what I'm proposing is that we could split our training dataset into two partitions. Let's call it training set A and training set B. At each step, we compute the gradients of a batch from A (let's call this g\_A) and gradients of a batch from B (g\_B). Next, instead of just backpropagating these gradients, we analyze the gradients between g\_A and g\_B and discard any gradients that seem ""out of place"". One proposal that I was thinking of is what if we backpropagate g\_A⋅g\_B / (norm(g\_A) norm(g\_B)) \* g\_A, where g\_A⋅g\_B is the inner product of g\_A and g\_B. Therefore, this is kind of like backpropagating g\_A (like normal gradient descent), but scaled by how much this ""conjugate gradient"" g\_B agrees with g\_A (which is the g\_A⋅g\_B / (norm(g\_A) norm(g\_B)) term).

Using this method, let's say we're near the end of training. If we only had one training set, we would just keep getting our model closer and closer to the optimal set of parameters for that training set. With this new method, I believe that the g\_A⋅g\_B / (norm(g\_A) norm(g\_B)) term would prevent the gradients g\_A from overfitting training set A, and maybe it will help with overfitting?

Edit: One other thing that I realized is that if there's the issue of computation cost when calculating g\_A⋅g\_B, we could instead maybe perform this type of update on only a random subset of gradients, while keeping the other gradients updating the same as standard backpropagation.

Edit 2: I was able to code up a short snippet using the MNIST database. Ironically, this method overfits a LOT more than standard SGD. See results [here](https://imgur.com/gallery/lsjtIG0). Basically, I took the first 50000 samples in the MNIST dataset, and trained it with batch size 500 using SGD. Next, I took the same 50000 samples (as set A) and the remaining datapoint (as set B) and retrained using this proposed method. Both methods had the same batch size of 500 and learning rate of 0.5. Both were trained for 100 epochs, and clearly there's overfitting in the proposed method. I guess my new question now is why does this happen and why this drastically?",2020-02-12 14:15:15
ML Server Recommendation,2,f2f8pt,https://www.reddit.com/r/MLQuestions/comments/f2f8pt/ml_server_recommendation/,4,1581484735.0,"My university is looking to spend 20-50k euro on a primarily ML workstation/server. I have been looking at the DXG-1 but am concerned that it isn't good value. What are your thoughts? It unfortunately cannot be self-built, or we won't receive the funding.

Do you have any recommendations? Preferably the workstation would be from Europe.",2020-02-12 10:48:55
ML algorithm for assigning responsible doctor to visit,1,f2iczw,https://www.reddit.com/r/MLQuestions/comments/f2iczw/ml_algorithm_for_assigning_responsible_doctor_to/,8,1581497056.0,"To frame the question in more detail:

Right now for every office/hospital visit, I have a list of potential doctors that could be the ""responsible"" provider for that particular visit. I have information on what was done in that visit and the primary procedure, diagnoses, and each cost that came out of that visit, but I need to always choose one of the providers as the best guess based on the information. Right now, we're doing this with a rule-based approach, but it's getting complicated enough that I have begun investigating ml methods.

I have looked into learning to rank, entity resolution, and classification methods. They all seem to solve a similar problem, but not this exact problem. I'm curious if anyone has any suggestions, either on a way to frame this problem differently or an algorithm that I just am not thinking of.",2020-02-12 14:14:16
ELI5: Deep Gaussian Processes,22,f24mtt,https://www.reddit.com/r/MLQuestions/comments/f24mtt/eli5_deep_gaussian_processes/,7,1581432492.0,"I feel like I have an understanding of Gaussian Processes, but I can't seem to understand what this \[paper\]([http://proceedings.mlr.press/v31/damianou13a.pdf](http://proceedings.mlr.press/v31/damianou13a.pdf)) and this \[talk\]([https://www.youtube.com/watch?v=NHTGY8VCinY](https://www.youtube.com/watch?v=NHTGY8VCinY)) are getting at. From a high level I can see what deep GP's are but I don't feel like I understand it in my bones.

Thanks!",2020-02-11 20:18:12
[Question] What are the top 10 experiment management tools,1,f2f0cs,https://www.reddit.com/r/MLQuestions/comments/f2f0cs/question_what_are_the_top_10_experiment/,2,1581483890.0,"I'm looking to map out comparisons between the major experiment management tools.

What are the top tools (MLflow / W&B / comet / Allegro)?

What are some parameters to compare (integrations / features / maturity / price)?",2020-02-12 10:34:50
Looking for the most recent version of Bishop's textbook,1,f2dfg7,https://www.reddit.com/r/MLQuestions/comments/f2dfg7/looking_for_the_most_recent_version_of_bishops/,2,1581477857.0,"I've studied Bishop's book for a course at uni a while ago, so now I would like to get a version (preferably pdf) to go over it again in depth at my own pace. I remember the book having a lot of typos and I was hoping to find the most recent version with the typos fixed. So far, I've only been able to find a list of these typos on Bishop's website along with a free pdf of an old version. So, I'm wondering if the updated pdf version even exists?",2020-02-12 08:54:17
Active learning,3,f27qc8,https://www.reddit.com/r/MLQuestions/comments/f27qc8/active_learning/,0,1581453411.0,"Hello everyone!
I am doing my PhD working with NN. So, I am interested on implement a NN that includes an active learning part to optimize my database. Did you know any reference that I can use to start?

Cheers!",2020-02-12 02:06:51
MLOps,1,f2auqv,https://www.reddit.com/r/MLQuestions/comments/f2auqv/mlops/,1,1581467798.0,"Does anyone have a good resource for learning more about MLOps? I'm a recent graduate of a Data Science program and have started working full time as a data scientist, and by far our biggest pain point is that no one on the team really has any experience in DevOps/deploying production machine learning code. That being said, I'm hoping to learn more about the field of MLOps. While there are a handful of blogs/articles here and there on the topic, I haven't really found any great resources to teach you the tools/techniques needed to successfully deploy a machine learning project. Any ideas or suggestions?",2020-02-12 06:06:38
Which hyper-parameters of NN are more important to you ?,1,f29euu,https://www.reddit.com/r/MLQuestions/comments/f29euu/which_hyperparameters_of_nn_are_more_important_to/,1,1581461781.0,"I'm currently developing a GUI based app [(Neural Network Sandbox)](https://github.com/imdeep2905/Neural-Network-Sandbox) in python. Which people can use to build and train feed forward networks with only few click of buttons.

As we all know there are dozens of hyper- which you can tweak to make your model better. I'm confused that which parameters should I include in limited GUI space. I'll try my best to include all but if there is need to removing some I should have a rough idea that which parameters should be removed.

So, if anyone can rank hyper-parameters (other than lr , epoch , loss function, optimization technique ) that would be of great help !!!


P.S. The project currently is under development so code can be messy !!",2020-02-12 04:26:21
ASUS ZenBook Duo UX481 or ASUS ZenBook 15 UX534FT-A7621TS which laptop should I get for machine learning?,0,f2ci6e,https://www.reddit.com/r/MLQuestions/comments/f2ci6e/asus_zenbook_duo_ux481_or_asus_zenbook_15/,1,1581474290.0," I am a 1st year CSE undergrad and I have recently started with machine learning and will be getting into deep learning in the next few years.  My current laptop is very old and therefore in the next few months, I  will be getting a new laptop. I am stuck between two choices. The ASUS  Zenbook duo and the ASUS Zenbook 15. The Zenbook duo comes with 16GB  RAM, i7 10th gen CPU, ITB SSD and Mx250 GPU whereas the Zenbook 15 comes with 16GB RAM, i7 8th Gen CPU, 1TB SSD and GTX 1650 MaxQ GPU the  Zenbook 15 has more GPU prowess which would helpful. But the Zenbook duo has ScreenPad Plus, which is a 14-inch screen built into the deck of the laptop, which I think would be very helpful while coding(I would be able to code on one screen and look up documentation at the same time on the other screen) and for general productivity. So, to make a final decision about which one to buy I would like to know, to what extent would the Gtx 1650 MaxQ benefit me over the Mx250?",2020-02-12 07:54:50
Are images suppose to break when channel position is changed?,1,f28v86,https://www.reddit.com/r/MLQuestions/comments/f28v86/are_images_suppose_to_break_when_channel_position/,0,1581459244.0,"so I have images with the format(width,height,channel). My original channel is in rgb. So I Load the images in grayscale

&#x200B;

        for r, d, file in tqdm(os.walk(path)):
          for i in tqdm(file):
            if i[0:2]==""01"":
              dist_one.append(cv2.imread(os.path.join(path,i),cv2.IMREAD_GRAYSCALE))
            else:
              dist_two.append(cv2.imread(os.path.join(path,i),cv2.IMREAD_GRAYSCALE))

&#x200B;

Suppose the images have the shape (187, 187). So I add a channel using the code

&#x200B;

`g = np.expand_dims(dist_one[0], axis=0)`

&#x200B;

But this breaks the images when I try to plot the image.

But it works when the channel is put last. 

`\`g = np.expand_dims(dist_one[0], axis=-1).\`` 

Whats the reason for this?

I need the channel at the first for pytorch",2020-02-12 03:44:04
Help with algorithm approach,2,f26hhy,https://www.reddit.com/r/MLQuestions/comments/f26hhy/help_with_algorithm_approach/,4,1581445292.0,"Hi!

I hope this is the right forum to ask.

I had a client approach me with a demand for a vision system for their assembly line.

The problem they are facing is that the operator sometimes forgets to put all three parts of the product together. They want a vision system that can spot if any of three main components are missing (only missing nothing else).

&#x200B;

I have the knowledge to build a covnet in keras but I think that would be a way to big hammer for this nail and I have to go to the client any produce images myself (ergo I can sit there for a day or two and take photos the products). So I might end up with a data set of maybe 200 images. I will try and make some artificially bad images, taking off the different components and photoing that. I don't think I'm allowed to show what the product looks like but I made a sketch.

https://preview.redd.it/52xwplwvt9g41.png?width=606&format=png&auto=webp&s=31d5722900fb66c7ed7e83b334675a8bee23305d

What algorithm can I read up on that would solve this problem in a good and time efficient manner? Demands on the camera and pc for the suggested algo would also be much appreciated (resolution etc).",2020-02-11 23:51:32
Deep learning. All are welcome. Join us.,1,f28nn5,/r/deeplearning/comments/f05due/undergraduate_collaboration_community/,0,1581458234.0,,2020-02-12 03:27:14
[Research]Research Topic,1,f27n2e,https://www.reddit.com/r/MLQuestions/comments/f27n2e/researchresearch_topic/,1,1581452861.0,"I am doing my Masters in computer science with Machine Learning as specialisation and I have to do research in machine learning as my final year project, so can you please suggest me some topics related to machine learning for my research.
Thank you in advance!!",2020-02-12 01:57:41
How can I generate music based on some preselected emotions/feelings?,1,f2693j,https://www.reddit.com/r/MLQuestions/comments/f2693j/how_can_i_generate_music_based_on_some/,0,1581443684.0,"I want to train a model that could generate/compose music based on some preselected emotions like happiness, sadness, nostalgia etc. I want at least to change the music that is composed based on its ""aggressiveness"". It would be very nice that I could train that model and insert it a game that will generate the music along the gameplay based on some stats? Or some other characteristics.

Thanks a lot. I am kinda new to ML and any help means a lot for me",2020-02-11 23:24:44
Algorithms for topic modeling,6,f1z6qb,https://www.reddit.com/r/MLQuestions/comments/f1z6qb/algorithms_for_topic_modeling/,0,1581406509.0,"Hi everybody, i am working on a NLP topic modeling project.
The idea is to catch topics from a group of reviews and i tried with bow+lda. To catch more semantic meaning, i used trigram so that when i analyze the topics i can find easily interpretable terms.

Sadly the most used trigram are actually the same one but with differente sequence : i.e. ""wait long time"", ""long time wait"" or ""wait time time"", ect.

My actual solution is to create a temporary vocab with the most used trigram and use it as input vocabulary for a new vectorizer. This limits the vocabulary but also restricts the same-meaning trigram, cutting them off.
I use the sklearn CountVectorizer and LDA, and with this escamotage i found better topics.

Hope you guys got some hints for me, even switch to some thing more intriguing as skip-gram or glove, which i dont know how to use for unsupervised clustering.",2020-02-11 13:05:09
Types of Machine Learning: A Beginner's Guide,0,f24qmj,http://brainstormingbox.org/types-of-machine-learning-a-beginners-guide/,0,1581433129.0,,2020-02-11 20:28:49
Lower learning rate leads to longer training time per epoch?,1,f240z2,https://www.reddit.com/r/MLQuestions/comments/f240z2/lower_learning_rate_leads_to_longer_training_time/,2,1581429015.0,"I've found something strange during an experiment involving fine-tuning CNNs in Keras (only updating a custom FC layer on top of other base networks such as MobileNet, Inception, etc.)

While performing a grid-search for optimal learning rate, I found that the training time for lower learning rates was significantly higher, **given the same number of epochs**. Is there any reason (theoretically) that this would happen?

The code is implemented in Keras and uses an ImageDataGenerator (from directory) for augmentation. The experiment was done on a laptop GPU (GTX1070).",2020-02-11 19:20:15
What library should i use???,1,f1wwka,https://www.reddit.com/r/MLQuestions/comments/f1wwka/what_library_should_i_use/,3,1581397528.0,Hello! any simple library of python for a project that consists on predicting real estate pricest based on k-nearest? Thank youu :),2020-02-11 10:35:28
PPO algorithm for Mario - stuck in local optimum(?),3,f1u24w,https://www.reddit.com/r/MLQuestions/comments/f1u24w/ppo_algorithm_for_mario_stuck_in_local_optimum/,0,1581386397.0,"I'm trying to train an agent to play the first level of Super Mario Bros using PPO. Sometimes near the beginning of the training it's starting to look pretty good, with Mario clearing the first three pipes and jumping over the two holes in the ground etc. Even saw it finish the whole level once. Nevertheless, at some point after a few dozen episodes it always starts to get stuck on the second or third pipe. It keeps jumping, but never high enough to clear the obstacle.

When it is stuck there it only gets negative absolute rewards (-5). My theory is that due to reward normalization (subtraction of mean, division by std. deviation) it actually ends up with something like a small net positive reward, reinforcing the wrong behavior (not jumping high enough).

I have tried different reward discount factors (from 0.80 to 0.99) and different learning rates down to 0.00001. In terms of episode lengths I tried a range of 50 to 750. Shorter episodes (around 150) seem to work better. But I can't seem to avoid the agent getting stuck as described.

Any suggestions what I might be doing wrong? Should I be looking at the hyperparameters again? Or is the reward function the culprit? I could imagine shaping the reward such that it gets increasingly negative the longer Mario is stuck might be an option?

The PPO implementation I'm using seems to be working fine for pong. I noticed one difference however: The state value function always has an error (compared to the actual, discounted & normalized rewards) of around 1.0. For Pong, it quickly converges to something like 0.2 instead.",2020-02-11 07:29:57
Looking for feedback about a ML program to scan text invoices and locate a reference number and validate the number in my transaction reports systems.,1,f1yodm,https://www.reddit.com/r/MLQuestions/comments/f1yodm/looking_for_feedback_about_a_ml_program_to_scan/,3,1581404425.0,"I am a small technology company looking to reduce manual data entry, close my margins for errors with human error, eliminate waste and implement an A.I. to be my front desk clerk. I want to hear what the community has to say about this. I know there are services that provide this tool but I would like to make the program myself and with my development team. The invoices feed into a gmail inbox my clerk prints each individual pages of invoices (1000+ transactions per week) after printing the invoices throughout the week the front desk will audit each page of payables and determine the purchase order number on the invoices verifies the information that we have received in our system already. We are running something similar to a drop shipping company based on incentive marketing, we have various programs and suppliers that work together to provide products to our clients customers. The solution of machine learning would tremendously improve our output and quality of business. Anyone with experience in this area would be great to hear your thoughts on this.",2020-02-11 12:30:25
Learning a geometric function (Is this actually not easy or am I doing it wrong?),1,f1ulrw,https://www.reddit.com/r/MLQuestions/comments/f1ulrw/learning_a_geometric_function_is_this_actually/,3,1581388548.0,"I am working on a project where I want to do the inverse kinematics of a robot with a NN. 
For simplicity I wanted to start with a 2D inverse Kinematic of a single limb with 2 motors and 2 limp lengths. I am trying to learn the motor positions based on the y coordinate of the endpoint (=y coordinate as input; 2 angles as output) but I only seem to get really bad results. I have tried different models and activation functions but the best results (to my knowledge) should give: 

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape = data_x[0].shape),
    keras.layers.Dense(100, activation='relu'),
    keras.layers.Dense(2, activation='linear')
])

The mathematical function which should be learned looks like this: 
y = (len1*sin(angle1)+(len2*sin(angle2-90+angle1))
My training data is 10k randomly generated examples and I limited it for angles to be between 0-90° in order to reduce duplicate solutions. 

TLDR: 
Trying to learn angle1+angle2 based on input y from the equations above. Would this be considered a difficult/advanced task? How should one go about this?

Edit: 
So I believe the problem could be that my geometric function has multiple correct solutions to a single input. (e.g. y = len1+len2 will have the same problem len1 and len2 could switch values and the output would be the same) This is probably confusing during training and AFAIK the loss function is applied seperately to each output and will give errors for duplicate correct outputs. I would need a loss function which is applied to all the outputs together (so I could calculate if the output is feasable). Is there any way to do this? 

Also: replaced ""singularities"" with ""duplicate solutions"" since that what I actually meant to say.",2020-02-11 08:05:48
What inductive bias is used by the various algorithms,1,f1tqjs,https://www.reddit.com/r/MLQuestions/comments/f1tqjs/what_inductive_bias_is_used_by_the_various/,0,1581385070.0,Could someone help by telling me which algorithms use what inductive bias or provide a link to a website that does?,2020-02-11 07:07:50
deciding which inductive bias to choose based on the algrythem,0,f1snha,https://www.reddit.com/r/MLQuestions/comments/f1snha/deciding_which_inductive_bias_to_choose_based_on/,0,1581380636.0,can anybody explain or provide a link on a website on how you choose which inductive bias to choose based on the machine learning algorithm?,2020-02-11 05:53:56
CNN training visualization,8,f1ky72,https://www.reddit.com/r/MLQuestions/comments/f1ky72/cnn_training_visualization/,8,1581337156.0,I am looking for a way to make an animation that show how a CNN trains.,2020-02-10 17:49:16
Help with Dictionary Learning,1,f1pn29,https://www.reddit.com/r/MLQuestions/comments/f1pn29/help_with_dictionary_learning/,0,1581366637.0,"Can someone point me to some resources which explain the basics of Dictionary Learning. I am looking for notes from some graduate course, or some detailed blog post/article/paper. Something a dumb grad student would understand. I have done some grad level Linear Algebra, supposedly ""Advanced"" Digital Signal Processing and some ""advanced"" statistical learning courses. But all the resources which come up when I Google are too dense for me to understand.",2020-02-11 02:00:37
Sign Language to speech conversion,1,f1p1y5,https://www.reddit.com/r/MLQuestions/comments/f1p1y5/sign_language_to_speech_conversion/,1,1581363220.0, Is there any solution about Sign language to speech conversion for mobiles. Can anyone suggest me the flow and tools that I can implement the solution for mobiles.,2020-02-11 01:03:40
Lottery Ticket Hypothesis - Table,1,f1oc98,https://www.reddit.com/r/MLQuestions/comments/f1oc98/lottery_ticket_hypothesis_table/,0,1581358441.0,"Hey guys, for the paper [The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635), there is a table on page 3.

https://preview.redd.it/3niopi7dn2g41.png?width=783&format=png&auto=webp&s=64c250d65fa1e2080a1f75f1afc47aa0a52d9a74

Within this table, I have doubts for:

**Iterations** row- Does this mean *step size.* Because step size = (number of training examples / batch size). So, I am not sure how the numbers of 50K, 20K, 25K, 30K, 30K and 112K are possible?

**Pruning Rate** row- But within the paper, it's mentioned that each of the *n* iterative pruning round prunes p\^1/n % of the weights. Then how should I interpret the pruning rates for the different network architectures.

For example, for *Lenet MNIST (300-100-10)* architecture, the pruning rate to achieve 78.9% final sparsity using 5 rounds (p = 78.9% and n = 5), the percentage of weights to be pruned in each of the 5 rounds are-

Round 1 prunes = 26.7418%

Round 2 prunes = 46.3323%

Round 3 prunes = 60.6840%

Round 4 prunes = 71.1978%

Round 5 prunes = 78.9000%

&#x200B;

So, what does *Pruning Rate fc (fully-connected) 20%* mean? Since each round prunes more than 20%

&#x200B;

Thanks!",2020-02-10 23:44:01
Understanding LoGANv2 and StyleGAN with conditions,1,f1mwoi,https://www.reddit.com/r/MLQuestions/comments/f1mwoi/understanding_loganv2_and_stylegan_with_conditions/,0,1581348237.0,"Hi there, I'm reposting a question that I asked on the learningmachinelearning subreddit, realizing that I didn't posted it in the right place.

I'm trying to understand how we can use a GAN as good as StyleGAN with class conditioning. This have been done previously with ""LoGANv2: Conditional Style-Based Logo Generation with Generative Adversarial Networks"" \[[https://arxiv.org/abs/1909.09974](https://arxiv.org/abs/1909.09974)\] and seems to be almost natively included in the original code for both StyleGAN and StyleGAN2 \[[https://github.com/NVlabs/stylegan2](https://github.com/NVlabs/stylegan2)\].I think I understand how it works inside the discriminator and how the loss function is modified, but I'm struggling with the mapping network.

In the implementation for StyleGAN2, these lines should add the labels to the random input (stylegan2/training/networks\_stylegan2.py, line 275 to 280) :

        # Embed labels and concatenate them with latents.
        if label_size:
            with tf.variable_scope('LabelConcat'):
                w = tf.get_variable('weight', shape=[label_size, latent_size], initializer=tf.initializers.random_normal())
                y = tf.matmul(labels_in, tf.cast(w, dtype))
                x = tf.concat([x, y], axis=1)

And it is explicitly said in LoGANv2 (section 4.1.1), that we have to multiply the one-hot-encoded labels to a matrix with random element sampled with the standard normal distribution.To my understanding, it only means that we select a line in the matrix w. However, since this matrix has only random elements, how can we except it to be useful to generate inter-class diversity without intra-class diversity ? Is this w sampled only once or at each time that we enter the labels ? (and why the normal distribution and not one centered around 1 for example ?)

I'm quite puzzled by both the Tensorflow implementation and the mathematics in the article (and the fact that it actually works), so I would appreciate if anyone could give me some insight.",2020-02-10 20:53:57
How could I connect Darknet and Tensorflow models in productution?,1,f1mw3x,https://www.reddit.com/r/MLQuestions/comments/f1mw3x/how_could_i_connect_darknet_and_tensorflow_models/,0,1581348146.0,"Hi,
recently I've been making a simple OCR system, consisting of text locator and recogniser. The problem is that I made locator with Yolo3 on Darknet and recogniser with custom written crnn on Tensorflow (with Keras) and not sure how to combine them in production enviroment. A lot of OCR tutorials use yolo+crnn or tesseract but they totally negect the production part. I asume using tesseract could help me because it has libraries, similarly to Darknet, which could be intgrated in software. But I don't need tesseract - I merely need to recognise some digits. So what advices can you give me? Speed is important to me. Should I use Tesseract after all? Or is it perfectly ok to use Darknet locally to find text and send it to Tensorflow Serving or something like that? Thank you.",2020-02-10 20:52:26
Meta Learning outside of the few shot paradigm,1,f1m7dq,https://www.reddit.com/r/MLQuestions/comments/f1m7dq/meta_learning_outside_of_the_few_shot_paradigm/,0,1581343911.0,"I have heard from others that meta learning can easily be extended outside of the few shot learning paradigm to more traditional datasets, but I am not sure where to find examples of this. Can anyone point me in the right direction?",2020-02-10 19:41:51
What is the difference between episode and epoch in few-shot learning?,1,f1kddr,https://www.reddit.com/r/MLQuestions/comments/f1kddr/what_is_the_difference_between_episode_and_epoch/,1,1581334332.0,"I am currently reading [this paper](https://arxiv.org/pdf/1911.10371.pdf) about few-shot segmentation, and in the ""Implementation Details"" section, they claim to train on PASCAL Voc with 40 epoch & 1000 episodes each, and train on COCO with 80 epoch & 500 episodes each.

I'm kinda confused, as 40 x 1000 = 80 x 500?

What really is the differende between epoch and episode? 

* Does episode simply calculate the loss but doesn't update the network at all?
* Is epoch were the all update happens (because updates happen not epoch-wise but batch-wise in generic problems)?",2020-02-10 17:02:12
How is it possible that validation MSE is low while test MSE is really high?,4,f1blyi,https://www.reddit.com/r/MLQuestions/comments/f1blyi/how_is_it_possible_that_validation_mse_is_low/,17,1581297259.0,"I'm having the following problem. I'm training a neural network LSTM using keras with the following architecture:

```python
model = keras.Sequential()
model.add(keras.layers.LSTM(units=64, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))
model.add(keras.layers.LSTM(units=128, input_shape=(x_train.shape[1], x_train.shape[2])))
#model.add(keras.layers.Dropout(rate=0.5))
model.add(keras.layers.Dense(units=1))
model.compile(loss='mse', optimizer=Adam())
```

The training phase goes pretty smoothly: the training loss begins at around 12000 and descreases a lot in the first epoch to around 10-*ish*. 

My data is a time-series with 5 variables and I'm trying to predict one of these variables. My data is sampled at second-rate. This data consists of sensor readings of an industrial machine. 

I'm using the following function to generate the datasets (previously divided into train, valid and test):

```python
def create_dataset(X, y, time_steps):
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        v = X.iloc[i:(i + time_steps)].values
        Xs.append(v)
        ys.append(y.iloc[i + time_steps])
    return np.array(Xs), np.array(ys)

```

From the 5 variables of the original data, three of those variables are scaled between maximum and minimum value. **The target variable is not scaled**.

First of all, this is the loss and valid_loss plot after 10 epochs of training:

https://i.stack.imgur.com/C1qqA.png

This behaviour is weird right? I would say the model is overfitting. 

Now, to the main problem:

Although the validation metrics are reasonably good, when I make predictions this is happening:

Predictions:

https://i.stack.imgur.com/InjdK.png


Predictions with true value for the test set:

https://i.stack.imgur.com/PTtcx.png


I would say that my network is capable of understanding the ""pattern"", but its not working in the same scale. Why is this happening?
1
When I measure the test MSE I got, as expected quite a high value - 82.",2020-02-10 06:44:19
Discussion: mlops and training set uniqueness,1,f1d9bg,https://www.reddit.com/r/MLQuestions/comments/f1d9bg/discussion_mlops_and_training_set_uniqueness/,0,1581303878.0,"What do people think about duplicated training records?  does this make any sense in the context of model training?  I've trained and implemented a few production models, and having reflected on the adventures of that effort, one of the biggest issues i had was the amount of time it would take to wrangle large amounts of redundant data.  i'm wondering whether more efficient mlops couldn't have been achieved by working out a robust solution to collect training data uniquely from the get-go, thereby circumventing delays associated with unnecessarily processing large numbers or redundant data.",2020-02-10 08:34:38
Recommend me a book about neural network please,0,f1akyd,/r/neuralnetworks/comments/f1ahnv/recommend_me_a_book_about_neural_network_please/,2,1581293025.0,,2020-02-10 05:33:45
Uses of Neural Networks for VA?,0,f1acps,https://www.reddit.com/r/MLQuestions/comments/f1acps/uses_of_neural_networks_for_va/,6,1581292037.0,"Hey, quick question.
If/when coding a virtual assistant that can control systems (eg. computer) with speech recognition, can you see how neural networks can be used? Like for more accuracy/performance?

I’m new to ML and have a hard time grasping the concepts, uses and other details..

Cheers",2020-02-10 05:17:17
Hardware Suggestions,1,f17uil,https://www.reddit.com/r/MLQuestions/comments/f17uil/hardware_suggestions/,7,1581279016.0,"I know this might be unrelated, but I am purchasing a new laptop for college that I believe is supposed to last for a long time, maybe 4 to 5 years at least. I prefer the ultrabook form factor, as still, I am learning all things related to ML and AI. I have plans to purchase the Tensorbook by Lambda labs sometime down the line, but till then I need a workable Laptop for a learner. I narrowed it down to two choices within my budget of 1 Lac INR (1390 USD) 

they are the specter x360 with 8gb of RAM and the Dell Inspirion 7000 series with 16 GB of RAM, technically they both are trash for hardcore ML, but if you guys were in my position which one would you choose. I already run a few of my projects on GCS and Collab anyways, but still, need an opinion.

Here are the product links for your review. 

[https://store.hp.com/in-en/default/hp-spectre-x360-13-aw0204tu-9jb01pa.html](https://store.hp.com/in-en/default/hp-spectre-x360-13-aw0204tu-9jb01pa.html)

[https://www.compuindia.com/new-inspiron-13-7391-2-in-1-laptop-7391716512ibt.html](https://www.compuindia.com/new-inspiron-13-7391-2-in-1-laptop-7391716512ibt.html)

I am inclined to get the HP one but scared as 8GB of RAM might be a little on the lower side right? personally I code on the Acer Nitro 5 and the X220 right now.",2020-02-10 01:40:16
Can I take photos for training an image classifier on different cameras?,5,f0ykfs,https://www.reddit.com/r/MLQuestions/comments/f0ykfs/can_i_take_photos_for_training_an_image/,2,1581228309.0,"Looking at making an image classifier that is, once complete, going to read images from one particular kind of camera. Does all the training data need to be gathered with that same camera? Or would any camera, given that the resolution is the same, work fine? Will the mix of different FOV angles and different megapixels affect the classifier?

For example, using a mix between SainSmart IMX219 vs using a GoPro capturing 1280x720 for gathering training data and then running the system only with SainSmart?",2020-02-09 11:35:09
Regularizing theta by removing first row,0,f14n7a,https://www.reddit.com/r/MLQuestions/comments/f14n7a/regularizing_theta_by_removing_first_row/,1,1581257263.0,"I'm doing week 4 couple of months after completing my week 2 (I really want to finish this course this time!) and I really cannot understand why I have to delete the first row of theta (always the first, no matter what values) and add a row of zeros to it in order to regularize it. Is there some detail I'm missing here? why would I want that specific piece of data removed?",2020-02-09 19:37:43
Using softmax as an intermediate layer,9,f0rya0,https://www.reddit.com/r/MLQuestions/comments/f0rya0/using_softmax_as_an_intermediate_layer/,11,1581199372.0,"I have a network that I am using for semantic segmentation, but then further using the label inference for a reconstruction loss.  In other words I have an autoencoder with a softmax intermediate layer.  The label targets training is interleaved with reconstruction loss training over a larger non-labeled dataset, as an approach to semi-supervised learning.

It works fairly well, but I have noticed that the reconstruction stage can ""cheat"" and make use of the continuous information of the softmax, which encourages the non-hot labels to stay high and carry ""analog"" information that would not be available after an argmax.  (I hope I am explaining well.)

Are there any techniques for ""hiding"" a bit better the continuous information of the softmax?  I am thinking of something that sort of collapses the largest value to 1 and other values to zero, but obviously this is non-differentiable.  Not sure if there are any tricks available that could help.  I briefly read up on Gumbel Softmax but I am not clear on whether it applies to this problem.  I might try min-max rescaling, but maybe there is something more clever.",2020-02-09 03:32:52
Seek advice on On-device streaming ASR/STT,2,f0vsms,https://www.reddit.com/r/MLQuestions/comments/f0vsms/seek_advice_on_ondevice_streaming_asrstt/,0,1581216513.0," Hey all,

At first, I am actually an Integrated Circuit and System grad student. I want to design a streaming on-device ASR ASIC and work on End-to-End streaming ASR now. After plenty of paper survey, I found that there are a few ways to implement streaming ASR.

1. RNN-T
2. CTC
3. MoChA
4. Hybrid(CTC/Attention)

RNN-T seems great but there are only [Google](https://arxiv.org/pdf/1811.06621.pdf) and [Facebook](https://arxiv.org/pdf/1911.01629.pdf) doing research on RNN-T. I am worried that RNN-T needs huge training data to achieve good performance.

CTC is popular but there are saying that it also needs big data to achieve good performance.

MoChA is an evolution from LAS, like small range attention. There is not much discussion. Also attention-based method usually require some future frames so that the latency is actually not low.

Hybrid model jointly decodes with CTC+attention but I don't think it would be easy to train.

There are some limitation on me.

1. only LibriSpeech training data (but I may apply [SpecAug](https://arxiv.org/pdf/1904.08779v3.pdf))
2. Not enough computing resource (only 2 GPUs)
3. End-to-End model is needed because of smaller model size
4. Latency < \~500ms

I am a newcomer in ML so sorry if this post is too ignorant. Any advice would be appreciate cause I have stuck on this for like 2 months. Thanks!",2020-02-09 08:18:33
How to generate independent(X) variable using Word2vec?,1,f0uzcw,https://www.reddit.com/r/MLQuestions/comments/f0uzcw/how_to_generate_independentx_variable_using/,0,1581213088.0,"I have a movie review data set which has two columns Review(Sentences) and Sentiment(1 or 0).

I want to create a classification model using word2vec for the embedding and a CNN for the classification.

I've looked for tutorials on youtube but all they do is create vectors for every words and show me the similar words. Like this-

    model= gensim.models.Word2Vec(cleaned_dataset, min_count = 2,  size = 100, window = 5)      
    words= model.wv.vocab 
    simalar= model.wv.most_similar(""bad"")

I already have my dependent variable(y) which is my 'Sentiment' column all I need is the independent variable(X) which I can pass on to my CNN model.

Before using word2vec I used the Bag Of Words(BOW) model which generated a sparse matrix which was my independent(X) variable. How can I achieve something similar using word2vec?

Kindly correct me if I'm doing something wrong.",2020-02-09 07:21:28
Project recommendations,1,f0s4ix,https://www.reddit.com/r/MLQuestions/comments/f0s4ix/project_recommendations/,6,1581200267.0,"Guys, please suggest us some good deep learning
projects to kick start our resume.They should be such
that they have some unique value and should have
some practical importance.We are well equipped with DL
and planning to do a good project.

Thanks in advance....",2020-02-09 03:47:47
Help with Anime Recommendation Machine Learning Project,1,f0rgbg,https://www.reddit.com/r/MLQuestions/comments/f0rgbg/help_with_anime_recommendation_machine_learning/,2,1581196654.0,"Hello, I am starting to get into machine learning after wanting to for a while, so sorry if some of these questions seem kinda basic, dumb, or too broad.

The idea for my project is to have a machine learning type program be able to recommend anime to people based on the ratings on a site called anime-planet from their users and comparing it to what the user rated the anime. Then either given an anime it will predict where the user will rank it, or it will recommend anime that the user hasn't seen and might like.

I've already written a program that gets data from the site (link at the bottom), but now I am lost as to what to do with it. The data gathered is *Anime title, Anime rank, Media type, Year, Studio, Rating out of 10, Number of users that have rated it, \[Similar anime the site recommends\], \[Tags\]*. Now that I have this data, I don't know how to manipulate it into something that is useful. Most of the tutorials I have been reading use strictly numerical values, but I have quite a bit of non-numerical data. I know I probably need the data manipulation first, but how I am going to train it is also very confusing to me. I am going to have around 10,000ish anime, and I have only watched 118 of those. I haven't started any code or anything since I need to figure out the data and training sets first.

I know I don't have much done, but I'm not really looking for a full answer just kind of a push in the right direction since I have no idea where to start or go from where I am now, so anything at all (tutorials, videos, questions, code, etc) will be greatly appreciated! I'm happy to answer any questions that may help you help me.

Link to the csv (this is only part of the data, the actual will be around 5 times more): [https://drive.google.com/file/d/118VkJeA2s3D8OBu0bEgAqQITygtEjadJ/view?usp=sharing](https://drive.google.com/file/d/118VkJeA2s3D8OBu0bEgAqQITygtEjadJ/view?usp=sharing)",2020-02-09 02:47:34
Tutorial for transfer learning on YOLOv3?,12,f0fg5g,https://www.reddit.com/r/MLQuestions/comments/f0fg5g/tutorial_for_transfer_learning_on_yolov3/,4,1581132441.0,"Hey guys, i am looking for a tutorial in KERAS for retraining the yolov3 neural network for custom classes. All i have found python files written with pytorch that i am just supposed to run without understanding. I want to understand how the code actually works and i unfortunately do not know pytorch. Do you guys have any suggestion? Anytjing including text tutorials, articles, videos or githib repos would work.
Thank you so much.",2020-02-08 08:57:21
Help with Deep Q-Learning algorithm with a Tetris game,3,f0jhx4,/r/learnmachinelearning/comments/ezijy4/help_with_deep_qlearning_algorithm_with_a_tetris/,0,1581149464.0,,2020-02-08 13:41:04
Difference between adam and sgd,3,f0gu47,https://www.reddit.com/r/MLQuestions/comments/f0gu47/difference_between_adam_and_sgd/,3,1581138113.0,Is the only difference between adam and sgd that adam tries to adjust learn rate per parameter whereas sgd has the same learn rate for all parameters?,2020-02-08 10:31:53
Faceid for text => textid?,3,f0966g,https://www.reddit.com/r/MLQuestions/comments/f0966g/faceid_for_text_textid/,14,1581103440.0,"Hello,
I would like to know if it's possible to build a NN to like Apples FaceID, were they use 30k unique points to identify your Face, for text. The goal would be to figure out if the text is written by a specific person (by comparing some written words with a ""live"" text)?",2020-02-08 00:54:00
"I ran into a roadblock Learning about self attention and Decoder Transformers, could someone take a look at my model?",1,f0bgjf,/r/learnmachinelearning/comments/ezzunf/i_ran_into_a_roadblock_learning_about_self/,2,1581115735.0,,2020-02-08 04:18:55
Overview of Reinforcement Learning and Implementation of Proximal Policy Gradient using RLKit,10,ezz3yt,/r/DecisionTheory/comments/ezysxw/overview_of_reinforcement_learning_and/,0,1581052038.0,,2020-02-07 10:37:18
CNNs with nonzero padding?,1,f085gy,https://www.reddit.com/r/MLQuestions/comments/f085gy/cnns_with_nonzero_padding/,1,1581096316.0,"Here is the thing. Every time I used padding in my CNNs, or have seen someone use padding, like in tutorial or a paper, I have seen 0 being used to pad the input. Now sometimes it's not symmetrical, but still always the 0. Even Keras docs only list 0 as an option.

&#x200B;

Now in image processing you have a lot of options for padding. Even numpy offers lot of variety, linear ramp, edge, reflect etc.

&#x200B;

So it got me thinking. Did anyone ever try to train models with nonzero padding for CNNs?",2020-02-07 22:55:16
Undergraduate Enthusiasts for Deep Learning,1,f07f3n,/r/deeplearning/comments/f05due/undergraduate_collaboration_community/,1,1581091079.0,,2020-02-07 21:27:59
Is there hardware specifically designed for training neural networks? Like how ASIC miners are specifically designed for mining cryptocurrencies.,1,f04kp5,https://www.reddit.com/r/MLQuestions/comments/f04kp5/is_there_hardware_specifically_designed_for/,1,1581075245.0,"I'm starting to get into more resource intensive training processes, and my laptop just isn't cutting it anymore. Currently looking into Xesktop/Garagefarm GPU RDPs, but I was curious if there is any other more cost effective method of training computationally expensive models, like maybe some kind of specialized hardware?

Whether there is or isn't specialized hardware for this task - does anyone have any general tips for keeping material costs down?",2020-02-07 17:04:05
Need ideas regarding approaching a ML/DL problem?,1,ezxwut,https://www.reddit.com/r/MLQuestions/comments/ezxwut/need_ideas_regarding_approaching_a_mldl_problem/,11,1581047669.0,"Assume we have all the info regarding a candidate like previous organizations end-start dates, skills, locations etc.. all details. How would you approach the problem to predict when will a person will quit his job and switch to another. What type of architecture/training approach would you consider?

Need ideas on how to approach this problem? What are the info about a candidate would we require for such a task? Please share some insights.",2020-02-07 09:24:29
Any experienced/senior data engineers have any tips or advice for an senior undergraduate interested in data engineering roles?,14,ezbw3a,https://www.reddit.com/r/MLQuestions/comments/ezbw3a/any_experiencedsenior_data_engineers_have_any/,8,1580948187.0,"In NYC, experience with Java and Python. I have conceptual knowledge of Hadoop and Spark. What should I know/learn for entry-level data engineer roles?",2020-02-06 05:46:27
Mechanical engineer on an AI team?,0,ezijaw,https://www.reddit.com/r/MLQuestions/comments/ezijaw/mechanical_engineer_on_an_ai_team/,3,1580973427.0,"Hi.

Im pretty set on getting a mechanical engineering degree. Im not good with coding but I’m super interested with AI which means i retain lots of things that I learn about it. If i contribute even the smallest percent to the singularity I would be very proud of myself and thats what a career is ultimately all about in my eyes.

Design, material science, creative problem solving, and digital interfacing are my sharpest skills. Would this be of any use to a team working on a smart computer? 

If yes, how would one go about contacting people that need my help? 

Thanks.",2020-02-06 12:47:07
Resources for implementing a model trained in pytorch or matlab on an FPGA?,1,ezhm40,https://www.reddit.com/r/MLQuestions/comments/ezhm40/resources_for_implementing_a_model_trained_in/,0,1580969876.0,"I was hoping to implement a QNN for generic object tracking by quantising a model in pytorch with brevitas and exporting to ONNX as per the [description on this webpage.](https://xilinx.github.io/finn/2019/10/02/rebuilding-finn-for-open-source.html)

However, it doesn't seem to be compatible as I can't export the model when I've implemented the brevitas methods.

I.E Instead of (doesn't export):

    class AlexNetV1(_AlexNet):
        output_stride = 8
    
        def __init__(self):
            super(AlexNetV1, self).__init__()
            self.conv1 = nn.Sequential(
                qnn.QuantConv2d(3,96,11,2,
                                weight_quant_type=QuantType.INT,
                                weight_bit_width=4),
                _BatchNorm2d(96),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(3, 2))
            self.conv2 = nn.Sequential(
                qnn.QuantConv2d(96, 256, 5, 1, groups=2,
                          weight_quant_type=QuantType.INT,
                          weight_bit_width=4),
                _BatchNorm2d(256),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(3, 2))
            self.conv3 = nn.Sequential(
                qnn.QuantConv2d(256, 384, 3, 1,
                          weight_quant_type=QuantType.INT,
                          weight_bit_width=4),
                _BatchNorm2d(384),
                nn.ReLU(inplace=True))
            self.conv4 = nn.Sequential(
                qnn.QuantConv2d(384, 384, 3, 1, groups=2,
                          weight_quant_type=QuantType.INT,
                          weight_bit_width=4),
                _BatchNorm2d(384),
                nn.ReLU(inplace=True))
            self.conv5 = nn.Sequential(
                qnn.QuantConv2d(384, 256, 3, 1, groups=2,
                          weight_quant_type=QuantType.INT,
                          weight_bit_width=4))

This (exports):

    class AlexNetV1(_AlexNet):
        output_stride = 8
    
        def __init__(self):
            super(AlexNetV1, self).__init__()
            self.conv1 = nn.Sequential(
                nn.Conv2d(3, 96, 11, 2),
                _BatchNorm2d(96),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(3, 2))
            self.conv2 = nn.Sequential(
                nn.Conv2d(96, 256, 5, 1, groups=2),
                _BatchNorm2d(256),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(3, 2))
            self.conv3 = nn.Sequential(
                nn.Conv2d(256, 384, 3, 1),
                _BatchNorm2d(384),
                nn.ReLU(inplace=True))
            self.conv4 = nn.Sequential(
                nn.Conv2d(384, 384, 3, 1, groups=2),
                _BatchNorm2d(384),
                nn.ReLU(inplace=True))
            self.conv5 = nn.Sequential(
                nn.Conv2d(384, 256, 3, 1, groups=2))

When I try to run this method in the main class with the brevitas methods:

        def export_onnx(self):
            batch_size = 1
            self.net.eval()
            
            x = torch.randn(batch_size,3,255,255,requires_grad=True)
            z = torch.randn(batch_size,3,127,127,requires_grad=True)
            torch_out = self.net(z,x)
            
            # Export the model
            torch.onnx.export(self.net,               # model being run
                      (z,x),                         # model input (or a tuple for multiple inputs)
                      ""alexnet_e50.onnx"",   # where to save the model (can be a file or file-like object)
                      export_params=True,        # store the trained parameter weights inside the model file
                      opset_version=10          # the ONNX version to export the model to
                      )

I get:

    RuntimeError: r ASSERT FAILED at C:\w\1\s\tmp_conda_3.7_055306\conda\conda-bld\pytorch_1556690124416\work\aten\src\ATen/core/jit_type.h:142, please report a bug to PyTorch. (expect at C:\w\1\s\tmp_conda_3.7_055306\conda\conda-bld\pytorch_1556690124416\work\aten\src\ATen/core/jit_type.h:142)
    (no backtrace available)

Like I said, I am assuming this isn't working because exporting to onnx isn't compatible with QuantConv2D method of brevitas. If this is the case, does anyone have another resource for quantising and attaining the model weights in integers and then implementing them in an FPGA?

Thanks for your time.",2020-02-06 11:47:56
Need help for my thesis with ML algorithm for feature-based priorization of n-paths,1,ezg48p,https://www.reddit.com/r/MLQuestions/comments/ezg48p/need_help_for_my_thesis_with_ml_algorithm_for/,0,1580964358.0,"Hey guys,

I need a little bit of help with a machine learning algorithm I have to design for my bachelor thesis.

My thesis is roughly about multipath app workflows like this one: [link to sample workflow](https://i.imgur.com/VUiDw3m.png). The shown workflow is about pairing a smart bed and contains different views the user has to complete to successfully pair his bed. In the workflow, the user has to choose if he wants to pair his bed via BLE or via entering codes, these are the two paths in the picture. At the end of the workflow, the user can rate his experience on a star rating. ('Good', 'Ok', 'Bad'). 

While executing the workflow I collect hardware-related data like the phone model. So my dataset contains features like the phone model used and the OS version, as well as the path the user chose (path 1 or path 2). Then I label each of the user's feature set with the rating of the user.

In the end, I want an algorithm that tells developers how to prioritize their workflow paths. For example, the algorithm should tell something like: Users with a device with Bluetooth version above 3 should take path 1 and all others should take path 2.

My first idea was to generate decision trees for each of the n-path by separating the dataset into n datasets each containing only the information of users choosing the associated path n. Then I try to train decision trees for each path and get the smallest decision tree with a good enough precision. So I can extract ""rules"", for example, this [decision tree](https://i.imgur.com/s1Wzp8W.png) (filtered 'Okay' ratings out). From this tree, I can tell that path 1 is most likely liked if the user has Bluetooth version above 3. If I find out that there is no decision tree with a good precision for a path I can only tell that the path is rated independently of hardware and the only information I have is the label distribution (e.g. 50% think it's good 30% think it's okay and 20% think it's bad).

Another similar idea I had was to create a decision tree with a target vector containing the rating and the path the user chose instead of separating the data set into n sets. For instance, a good rating and path 1 could be the vector \[3,1\].

I'm do not have a lot of machine learning background, therefore I would be really happy to get some feedback on my attempt to solve the problem or a suggestion for a better approach.

Thank you very very much!  <3",2020-02-06 10:15:58
The difference between distribution of data vs actual data,4,ez98em,https://www.reddit.com/r/MLQuestions/comments/ez98em/the_difference_between_distribution_of_data_vs/,6,1580936576.0,"How can I picture the difference between the distribution of data vs the actual data. Would be great if anyone could take image datasets as an example and explain me. There are people who talk about distribution of data at one instant and immediately switch into the actual data, it almost seems like they are the same thing, but I have a strong doubt that I am missing a link. Can anyone help me solve it? When people are talking about data vs its distribution, what do they actually mean? Please kindly explain in as easy way as you can, referencing image dataset would be flavor to fragrances!",2020-02-06 02:32:56
continue training styleGAN model?,1,ezepqh,https://www.reddit.com/r/MLQuestions/comments/ezepqh/continue_training_stylegan_model/,1,1580959079.0,"i'm trying to train styleGAN in google colab and i get that i run train.py to train, but how do i start from an existing .pkl and continue training?",2020-02-06 08:47:59
If you could help me out I’d be very appreciative!,0,eze0mb,/r/learnmachinelearning/comments/ezdez7/explain_cnn_layer_input_and_output_sizes_please/,2,1580956408.0,,2020-02-06 08:03:28
"After training, testing and validating, how do to make actual predictions?",7,ez2siv,https://www.reddit.com/r/MLQuestions/comments/ez2siv/after_training_testing_and_validating_how_do_to/,10,1580901620.0,"I've trained a classifier to predict fight results, the model is trained with past fights history and uses several features that aren't available before a fight happens, how do i predict some future fight using it?

I'm having trouble understanding how to input two different fighters and having some predicted output.",2020-02-05 16:50:20
Word abbreviation expansion using machine learning,1,ez0sci,https://www.reddit.com/r/MLQuestions/comments/ez0sci/word_abbreviation_expansion_using_machine_learning/,4,1580893439.0,Has anyone tried to automatically expand abbreviated word using hmm or other techniques in python.please share your views,2020-02-05 14:33:59
Complex Movement Classification,2,eyvf46,https://www.reddit.com/r/MLQuestions/comments/eyvf46/complex_movement_classification/,1,1580873021.0,I’m working on a side project using 9-DOF IMU’s at 1-2 points (hands) to try to get feedback on whether a persons full body movement is  correct or what they did wrong. What I don’t know is how to deal with continuous accelerometer data to build a classifier or something else. Any help much appreciate in advance!,2020-02-05 08:53:41
Predicting degenerate output,1,eyrx5x,https://www.reddit.com/r/MLQuestions/comments/eyrx5x/predicting_degenerate_output/,0,1580859953.0,"I'm trying to figure out if I can apply any technique where there is not a one-to-one mapping between input output pairs. 

My problem relates to predicting machine parameters in radiotherapy. Given a radiotherapy dose distribution, can I predict the machine parameters that would produce that dose distribution. The problem is that there are many machine configurations that will produce a given dose, some of which are close together (i.e. they're effectively the same) and some of which are further apart (they're different, but give the same dose). 

Are there any techniques for handling this type of degeneracy? All I can think of is projecting into a higher dimensional space where the degeneracy is not apparent and working there. Does that sound sensible? Are there any tools to do that kind of thing?",2020-02-05 05:15:53
"People who have self studied ML and landed a job, What path did you follow ?",30,eyc0gu,https://www.reddit.com/r/MLQuestions/comments/eyc0gu/people_who_have_self_studied_ml_and_landed_a_job/,18,1580785626.0,"Hello,

I am graduate in Computer Applications with no emphasis on Python or ML from college, I have self studied the language and try my best to work up my skills in Machine Learning, with few projects (or scripts if you will) that had given me insights about the field also a little bit of Online courses and studying from books.

I am never comfortable in looking for a job as I have no clue of the problems that are solved in a real life scenario, also most of the jobs require 2+ years of experience. So I am on a lookout for a descent internship to begin with.

Despite doing what I can to improve myself, I constantly feel like I am wasting too much of my time. I need people who had landed a job through self education to advice me a path to follow in order to at least be skilled enough to be able to contribute in some real life problems.

Also, How long should I be patient with myself to know enough to be able to do this ?",2020-02-04 08:37:06
Is there a way to normalise hidden layer output in keras? (Which is also fed recurrently),1,eypeyy,https://www.reddit.com/r/MLQuestions/comments/eypeyy/is_there_a_way_to_normalise_hidden_layer_output/,6,1580848572.0,"Im training a lstm, when i use sigmoid or tanh activation the learning is too slow (maybe gradients are vanishing).
So i switch to relu, it performs better but often the error becomes nan, my timesteps are 200 so maybe the values are exploding as relu is not bounded. My hypothesis if i normalise output of hidden layer it might solve the prob but i couldn't find a way to do it

> Is there a way to normalise output of hidden layer (ie. Use relu + normalise as recurrent activation)?
> Should i try something else?",2020-02-05 02:06:12
How number of different selections that contain the given item is calculated,1,eypasy,https://i.redd.it/f7x3f73hhwe41.jpg,7,1580847964.0,,2020-02-05 01:56:04
[Discussion] Is it possible to get a ML/AI -related job in Lugano for junior master?,1,eyo7dg,/r/MLjobs/comments/eyo6rk/discussion_is_it_possible_to_get_a_mlai_related/,2,1580841422.0,,2020-02-05 00:07:02
Does this count as a neural network?,1,eym0fq,https://www.reddit.com/r/MLQuestions/comments/eym0fq/does_this_count_as_a_neural_network/,3,1580827440.0," Background: I have no background in computing or education on how these things work, I just enjoy toying around with logic in LittleBigPlanet 3.

I made a pathfinding machine that would send a signal from node to node on a grid (trying to reach the end node), with each node starting with a 1/4 chance of transmitting the signal to any adjacent neighbor. If the signal reaches the end in an improved number of steps over its best run, each node that was part of that path becomes more likely to choose the same step it took during that run. If it doesn't beat its best run it simply tries again and no path is potentiated. It was kind of buggy, but I think it ""learned"". Is this machine learning?",2020-02-04 20:14:00
Is it dumb to choose a CV or NLP for semester project (Without prior knowledge in these fields)?,1,eyl0km,https://www.reddit.com/r/MLQuestions/comments/eyl0km/is_it_dumb_to_choose_a_cv_or_nlp_for_semester/,5,1580822365.0, I just started learning data analytics and we need to choose a semester project. We are going to learn CNN during the end of the semester. I am willing to put in the extra effort.,2020-02-04 18:49:25
Results of Implementing a Paper,3,eyc9rt,https://www.reddit.com/r/MLQuestions/comments/eyc9rt/results_of_implementing_a_paper/,4,1580786589.0,"I have been working on implementing a paper that diagnosis Autism based on f-MRI data. I have achieved results close but is less by 1% in accuracy.

I am asking people who have recently implemented papers. Do your metrics usually line up with that detailed in the papers or are off by a bit.",2020-02-04 08:53:09
[D] Is that possible for someone who doesn't have any computer science background to study Machine Learning by themselves?,2,eydrzo,https://www.reddit.com/r/MLQuestions/comments/eydrzo/d_is_that_possible_for_someone_who_doesnt_have/,10,1580792133.0,"Hi community, my major is in communication but I am fascinated by the development of Machine learning, extremely NLP. I finished Andrew's *AI for Everyone,* keep watching AI-related youtube channels, keep following AI publications such as Towards Datascience and Synced Review. I also have read some papers recommended by my friend in AI field in my spare time.  

I have no idea where to start and how to learn this systematically. Do you guys have any suggestions for good books or videos or other resources for an AI ""outsider"" to start their self-learning journey?",2020-02-04 10:25:33
[Discussion] What is the difference between SVR with linear kernel and linear regression?,2,ey8k5e,https://www.reddit.com/r/MLQuestions/comments/ey8k5e/discussion_what_is_the_difference_between_svr/,5,1580771798.0,How we can select the classifier either SVR with linear kernel or linear regression for own datasets?Which scenario's or datasets both are useful ? Can anyone explain this or any resources or links please?,2020-02-04 04:46:38
How do you feel about cloud GPU rental platforms?,1,eyabah,https://www.reddit.com/r/MLQuestions/comments/eyabah/how_do_you_feel_about_cloud_gpu_rental_platforms/,2,1580778958.0,"Would you use/need online web services for your projects? 

I'm doing market research for an early stage web service product. Right now we are focusing on b2b GPU renting, but now we are thinking maybe providing AI/ML solutions might have a bigger market?  Before we make any decisions (that could lead this baby product to probably a fatal death), we'd like to hear what people who actually use/need cloud web services have to say...

So if you deal with projects that require intense computing power, please take this survey(which will take about 1 minute) or just leave a comment, your advice would be invaluable for me! Link to the survey👉https://ntlabs.typeform.com/to/Hpjz2i",2020-02-04 06:45:58
Reinforcement learning using Transformer seq2seq model,1,ey8ii3,/r/reinforcementlearning/comments/ey3ifr/reinforcement_learning_using_transformer_seq2seq/,0,1580771598.0,,2020-02-04 04:43:18
After which convolution layer should i put dropout?,1,ey6yvm,https://www.reddit.com/r/MLQuestions/comments/ey6yvm/after_which_convolution_layer_should_i_put_dropout/,3,1580764386.0,"There are lot of conv2d layers in my network if suppose my model overfits sometime in future, how should one know where to apply Dropout?

[Model architecture : UNET](https://images.app.goo.gl/kATxuuwCDjkrmzW7A)",2020-02-04 02:43:06
Could someone explain to me how the sigmas are generated in this paper?,5,ey1wbe,https://www.reddit.com/r/MLQuestions/comments/ey1wbe/could_someone_explain_to_me_how_the_sigmas_are/,1,1580735396.0,"I am referring to this paper https://arxiv.org/abs/1705.07115 and more specifically, to this equation.

https://github.com/ranandalon/mtl/blob/master/images/multi_loss.PNG

I feel like it is supposed to be something very simple but I can't figure out if these sigmas are manually set or if they are the outputs of a neural network.",2020-02-03 18:39:56
How to evaluate texte generated by GPT-2 model?,1,ey3ef6,https://www.reddit.com/r/MLQuestions/comments/ey3ef6/how_to_evaluate_texte_generated_by_gpt2_model/,1,1580743499.0,,2020-02-03 20:54:59
loss does not improve after a certain point.,2,ey0e9l,https://www.reddit.com/r/MLQuestions/comments/ey0e9l/loss_does_not_improve_after_a_certain_point/,7,1580728348.0,"I am training a Unet for image segmentation of a person. My neural network seems to improve till a certain point after that it just stays constant. 

Dice coefficient improves till a certain point in my case its 0.34 and it is constant since more than 2 hours. 

Please suggest me methods to improve it.

[model architecture](https://images.app.goo.gl/t7eiKmFPz2LNKsuv9)",2020-02-03 16:42:28
Does anyone has dataset labelled for to do sentiment analysis for chatroom?,0,ey2te9,https://www.reddit.com/r/MLQuestions/comments/ey2te9/does_anyone_has_dataset_labelled_for_to_do/,2,1580740298.0,,2020-02-03 20:01:38
What should I do?,4,exuqtn,https://www.reddit.com/r/MLQuestions/comments/exuqtn/what_should_i_do/,5,1580704579.0,"Hi.

I have created an algorithm for general intelligence (by ""general"" I mean simply general, not human-level). I think that the algorithm can be useful. The algorithm is complex and I need a lot of time to describe and implement it. As far, I have created a description of that algorithm (a paper describing the algorithm and why it works) and some really basic implementation of it which took me a lot of time. But I still need to spend a lot of time on it because the paper needs to be improved and implementation is really basic. The problem is that I have a 9 to 5 job and I can work on that only after hours and weekends. But doing that on weekends, it will take me really lots of time to finish that work (too long time), I need to work on it full time to finish it in some reasonable time. For that reason, I'm looking for some grant opportunities like this one: [https://aigrant.org/](https://aigrant.org/) (currently inactive).

What would you do in that situation? Do you know any grant opportunities like the above one or anything that could help me (I live in UK, if that makes any difference)? If you do, please share.

Another problem is that, if I finally create that paper, then nobody will read it and the potential of the algorithm will be wasted. Nobody will read it because it's long and nobody will know if it's worth reading because I don't have any credibility and I don't have resources (computational power) to produce impressive empirical evidence proving the full potential of the algorithm. Having the resources I have, I can prove the potential of the algorithm only through theoretical justification, but that requires someone to read that theoretical justification which nobody will do (for the reason I explained above). The solution to that problem is that I need to submit that paper to a peer-review journal or conference and if it successfully goes through review process, then the paper will gain credibility and maybe someone will pay attention to this algorithm. Presuming that reviewing process is perfect and my algorithm is correct, then that should work (reviewing process is not 100% perfect, so it has some probability of not working). But if you have any thoughts on that, I would welcome them in the comments section.",2020-02-03 10:06:19
Question about Transformer Implementation,1,exy8v8,https://www.reddit.com/r/MLQuestions/comments/exy8v8/question_about_transformer_implementation/,0,1580718463.0,"There's a tutorial on the Pytorch website that involves implementing a Transformer Model for sequence to sequence learning:
https://pytorch.org/tutorials/beginner/transformer_tutorial.html
In the implementation, the encoder/decoder weights are explicitly initialized by randomly drawing from a Uniform distribution between [0.1,0.1].

My question is, why is this done? Pytorch initializes weights by default in some random manner. Is there something special about U[0.1,0.1]?
Am I missing something about how Transformers are implemented? 
Or was this simply for educations sake, to show you that you could initialize the weights yourself?",2020-02-03 13:57:43
New to ML-generated Art,3,exs0oe,https://www.reddit.com/r/MLQuestions/comments/exs0oe/new_to_mlgenerated_art/,1,1580694409.0,"Hello, I'm looking to explore generating art with ML. Particularly, I want to teach a model to generate vaporwave art (most likely with style transfer models). I've start curating a dataset of vaporwave landscapes and skylines. To dip my toes in, I tried RunwayML this weekend but it's too costly and limited considering I know I could be doing the tech side myself.

I have programming experience and know the basic concepts of ML. I just need to know which guide / setup is the most sustainable before dedicating my time to diving in head first. Where do you recommend I begin? Any suggestions would be helpful.",2020-02-03 07:16:49
Is there a good principled way of choosing a network structure?,2,exqsiv,https://www.reddit.com/r/MLQuestions/comments/exqsiv/is_there_a_good_principled_way_of_choosing_a/,2,1580689359.0,"So, working on a class assignment to classify some set of images with at least 65% accuracy using a CNN. I'm basically doing a very slow trial and error, throwing stuff at the wall and seeing what seems to work better and what worse. Other than being time-consuming, it also seems a bit theoretically suspect to repeatedly look at the performance on the test data in order to tweak my hyperparameters...

Ideally, there'd be some algorithm I could tell ""I want this classified with a CNN with at least x% accuracy"", and it'd in some sensible way try various things until it found a good-enough choice of structure and hyperparameters, and report back. Then I could test its output once on a separate test data from what it was given, and not run into multiple-tests issues.

So, is there such a thing, or am I stuck constantly waiting twenty minutes to see a three percent shift in performance? I'd much prefer waiting twenty hours to see the problem solved...",2020-02-03 05:52:39
Looking for a way to compress large vectors to input into a NN,1,extqu7,https://www.reddit.com/r/MLQuestions/comments/extqu7/looking_for_a_way_to_compress_large_vectors_to/,8,1580700907.0," Hey!

So, this is my first time doing something of this scale, and I have a vector with 1024 dimensions, I don't want to input such a huge vector into a nn, for obvious reasons. I am looking for some way to reduce the dimensions while still retaining the data. Preferably I don't want to use autoencoders, rather some other mathematical method, not a nn.",2020-02-03 09:05:07
Post-processing of node activations at inference (test) time,1,exrf3q,https://www.reddit.com/r/MLQuestions/comments/exrf3q/postprocessing_of_node_activations_at_inference/,0,1580691944.0,"Is there any existing literature to point me towards that deals with increasing test accuracy by trimming/screening/removing/filtering some activations in deep layers of DNNs?  The idea is that only the most important/salient features remain after the filtering process.  The other activations would be set to 0. 

There may be parallels with this idea and batch normalization, however the big differences are this filtering would only be done at inference time (not during training) and this filtering would be on an image-by-image basis (not batch). 

Another potential parallel would be an adaptive relu function that sets more activations to 0 in a dynamic and adaptive way. 

Even some keywords to help the search could be useful.",2020-02-03 06:35:44
Caregiving and Robotics,0,exra0v,https://www.reddit.com/r/MLQuestions/comments/exra0v/caregiving_and_robotics/,0,1580691370.0,"Hellou this is my first post si Hellou ppl, 

 What do you think will be the future of robots in health and caregiving jobs?

 I see it as a great way to help whit the loneliness whit senior citizens. 

What do you think ?",2020-02-03 06:26:10
Cloud Service: Which one is the best for small scale deployment?,4,exjf1q,https://www.reddit.com/r/MLQuestions/comments/exjf1q/cloud_service_which_one_is_the_best_for_small/,3,1580648914.0,I wanted to know your opinions on which of Cloud ML providers I should go with if I want to develop and deploy an Image Classification model which should get roughly 1000 API requests per day,2020-02-02 18:38:34
Lottery Ticket Hypothesis - Iterative Pruning,9,ex7cdn,https://www.reddit.com/r/MLQuestions/comments/ex7cdn/lottery_ticket_hypothesis_iterative_pruning/,2,1580598312.0,"Hey guys, I was reading about the [Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635) and it was mentioned in the paper:

&#x200B;

>we focus on iterative pruning, which repeatedly trains, prunes, and resets the network over **n** rounds; each round prunes (**p\^(1/n))%** of the weights that survive the previous round.

Can someone please explain this say for each round with numbers, when n = 5 (rounds) and the final sparsity desired (p) = 70%.

In this example, the numbers I computed are as follows:

Round    (p\^(1/n))% of weights pruned

1              0.93114999

2             0.86704016

3             0.80734437

4             0.75175864

5             0.7

According to these calculations, it seems that the first round prunes 93.11% (approx) of the weights, whereas, the fifth round prunes 70% of the weights. It's as if as the rounds progress, the percentage of weights being pruned decreases.

What am I doing wrong?

&#x200B;

Thanks!",2020-02-02 04:35:12
Autonomous Drone Scenarios with Reinforcement Learning,1,ex9xtc,https://www.reddit.com/r/MLQuestions/comments/ex9xtc/autonomous_drone_scenarios_with_reinforcement/,6,1580608716.0,"Hi everyone,
I am a 4th-grade bachelor student and I have a final project about Autonomous Drone Scenarios. Technologies I should use are ROS, Gazebo, Reinforcement Learning, Agile Maneuvering.

At the moment, I have some basic information about ROS and Deep Learning.

I need help about the path I should follow to complete my project. If you could give me ideas about it, I would be appreciated.

Thanks for your time 😊",2020-02-02 07:28:36
Running GPT-2 help needed!,1,ex9erd,https://www.reddit.com/r/MLQuestions/comments/ex9erd/running_gpt2_help_needed/,1,1580606652.0,"This is where I have gotten to so far...

Shrink Windows 10 drive to make room for some space.

Installed UBUNTU, dual boot

**Then ran the following commands**

sudo apt update

sudo apt -y upgrade

python3 -V

sudo apt install -y python3-pip

sudo apt install build-essential libssl-dev libffi-dev python3-dev

sudo apt install software-properties-common

sudo apt-get install software-properties-common

sudo apt install git

sudo apt install python-pip

pip install --upgrade pip

pip install regex==2017.4.5

pip install requests==2.21.0

pip install tqdm==4.31.1

pip3 install fire regex requests tqdm

python3 -m pip install tensorflow

git clone [https://github.com/openai/gpt-2.git](https://github.com/openai/gpt-2.git)

Change directory to gpt-2

pip3 install -r requirements.txt

python3 -m pip install tensorflow

python3 download\_model.py 774M

python3 download\_model.py 1558M

How do I train my model?

I have a temp text file with a couple of books.

**command:** python [encoder.py](https://encoder.py/) learnfromme.txt learnex.npz

**result:**

File ""[encoder.py](https://encoder.py/)"", line 19

SyntaxError: Non-ASCII character '\\xc2' in file [encoder.py](https://encoder.py/) on line 19, but no encoding declared; see [http://python.org/dev/peps/pep-0263/](http://python.org/dev/peps/pep-0263/) for details

&#x200B;

I am stuck after this.

This is my folder structure... ""old"" is my username

&#x200B;

**This is my GPT-2 folder**

drwxr-xr-x 2 old old  4096 Feb  1 11:27 1558M

drwxr-xr-x 2 old old  4096 Feb  1 11:18 774M

\-rw-r--r-- 1 old old   551 Feb  1 11:06 [CONTRIBUTORS.md](https://contributors.md/)

\-rw-r--r-- 1 old old  2188 Feb  1 11:06 [DEVELOPERS.md](https://developers.md/)

\-rw-r--r-- 1 old old   279 Feb  1 11:06 Dockerfile.cpu

\-rw-r--r-- 1 old old   548 Feb  1 11:06 Dockerfile.gpu

\-rw-r--r-- 1 old old 14754 Feb  1 11:06 domains.txt

\-rw-r--r-- 1 old old  1063 Feb  1 11:06 download\_model.py

drwxr-xr-x 3 old old  4096 Jan  3 21:06 gpt-2-master

\-rw-r--r-- 1 old old  1403 Feb  1 11:06 LICENSE

\-rw-r--r-- 1 old old  4989 Feb  1 11:06 model\_card.md

drwxr-xr-x 2 old old  4096 Feb  1 11:33 models

\-rw-r--r-- 1 old old  2827 Feb  1 11:06 [README.md](https://readme.md/)

\-rw-r--r-- 1 old old    58 Feb  1 11:06 requirements.txt

drwxr-xr-x 2 old old  4096 Feb  1 11:44 src

**This is my src folder**

\-rw-r--r-- 1 old old    4242 Feb  1 11:06 [encoder.py](https://encoder.py/)

\-rwxr-xr-x 1 old old    2870 Feb  1 11:06 generate\_unconditional\_samples.py

\-rwxr-xr-x 1 old old    3412 Feb  1 11:06 interactive\_conditional\_samples.py

\-rw-r--r-- 1 old old 3041890 Feb  1 11:44 learnfromme.txt

\-rw-r--r-- 1 old old    6503 Feb  1 11:06 [model.py](https://model.py/)

\-rw-r--r-- 1 old old    3166 Feb  1 11:06 [sample.py](https://sample.py/)

**This is my 1558M folder**

\-rw-r--r-- 1 old old    4242 Feb  1 11:06 [encoder.py](https://encoder.py/)

\-rwxr-xr-x 1 old old    2870 Feb  1 11:06 generate\_unconditional\_samples.py

\-rwxr-xr-x 1 old old    3412 Feb  1 11:06 interactive\_conditional\_samples.py

\-rw-r--r-- 1 old old 3041890 Feb  1 11:44 learnfromme.txt

\-rw-r--r-- 1 old old    6503 Feb  1 11:06 [model.py](https://model.py/)

\-rw-r--r-- 1 old old    3166 Feb  1 11:06 [sample.py](https://sample.py/)

Any help is appreciated.

Thanks!",2020-02-02 06:54:12
How would you approach this document cluster problem?,1,ex7xi7,https://www.reddit.com/r/MLQuestions/comments/ex7xi7/how_would_you_approach_this_document_cluster/,1,1580600825.0,"I am new to the machine learning field but I have 4+years of spark experience. I should be able to easily do all needed feature engineering. I just don’t know what direction to go to get the results I am looking for. 

So I am looking for the steps you would take to solve this problem.

I have document. On the document I have a bunch of meta data like location, created date, document type etc. I also have the entire documents text in paragraphs. In addition, each document can reference many other documents. I have the exact paragraph and document Id the original document is referencing.

I am hoping to cluster these documents and label them. Hoping to find relationships outside of these direct relationships.

So if document 1 is talking about cats and references document 2 and 3 about cats. And document 2 references document 3 and 4 about cats. We also have a 5th document about cats not referenced by any of these other documents by is semantically similar. We would assume that document 1-5 are about cats",2020-02-02 05:17:05
Input vector ---> path in a 2D square world using Reinforcement Learning. What model should I use?,2,ex4wgl,https://www.reddit.com/r/MLQuestions/comments/ex4wgl/input_vector_path_in_a_2d_square_world_using/,9,1580585632.0,"I want to solve this particular problem using RL. I have many different vectors, and with each of them is associated a different path in a 2D square. 


I'd like to train an agent so that, given a new vector of that kind, it will know what path to walk in the 2D world. 


Is it possible to do this?",2020-02-02 01:03:52
Estimating number of 1 vs 0 labels,1,ex42n7,https://www.reddit.com/r/MLQuestions/comments/ex42n7/estimating_number_of_1_vs_0_labels/,2,1580580439.0,"If I have N pics which are either a bird or a dog, and a machine learning algorithm outputting the probability a certain pics is a bird, how do I compute the expected number of birds among all of my pics?

In this problem, the number of pics can be very high (millions, even higher), but the number of birds will always be low - lower than 1% of the total.

Approaches I'm considering:
1) Sum up the probabilities that a pic is a bird, therefore getting the mathematical expected value
2) Take a representative random sample (of, say, 10k pics) and have it labelled otherwise (through a more expensive method, such as manually looking at each pic)",2020-02-01 23:37:19
Project on NLP,1,ex0ls2,https://www.reddit.com/r/MLQuestions/comments/ex0ls2/project_on_nlp/,3,1580559074.0," I want to develop a website, real time database with an implementation of nlp to detect cyber bullying. how difficult it would for a 3rd year engineering student?",2020-02-01 17:41:14
Choosing a machine learning algorithm,8,ewnb3s,https://www.reddit.com/r/MLQuestions/comments/ewnb3s/choosing_a_machine_learning_algorithm/,7,1580500026.0,How do you decide on what machine learning algorithm to use on a given use case?,2020-02-01 01:17:06
Error while applying to Facebook AI Residency,0,eww9pa,https://www.reddit.com/r/MLQuestions/comments/eww9pa/error_while_applying_to_facebook_ai_residency/,2,1580538926.0,"I see this error repeatedly: Hey there! This is embarrassing. There was an error saving or processing your application. Before you post a status or sticker describing your deep sadness, maybe you can do us the favor of applying again? We would really appreciate it.

Does anyone have any idea about this?",2020-02-01 12:05:26
how to format my data for analysis of sensor data,1,ewulkv,https://www.reddit.com/r/MLQuestions/comments/ewulkv/how_to_format_my_data_for_analysis_of_sensor_data/,15,1580532105.0,"I have a 400 x 100 matrix of frequency values that is in the format of a intensity map. 

This data relates to frequency of pixels on a sensor. The map looks like this:

https://stackoverflow.com/questions/33610420/creating-a-color-map-heatmap-in-matlab-octave

I'm new to machine learning and I've seen examples that have 3 features such as XYZ values of a gyro but I only have 1 feature (frequency). 

I want to classify certain sensors as not being good enough to pass by using data I have from failing devices. What would be the best way to represent my data in ML? 

This is a real world problem for automating the analysis of sensors so I really appreciate any help :)",2020-02-01 10:11:45
Working with sentinel p5 data to detect air pollution hotspot,3,ewoaw7,https://www.reddit.com/r/MLQuestions/comments/ewoaw7/working_with_sentinel_p5_data_to_detect_air/,0,1580505266.0,"Hello guys I am working on a project to detect air pollution hotspot and predict the trajectory of the hotspot.
I don't know completely how to achieve this goal.
I am currently reading ""Spatial clustering detection of regression coefficients in a mixed-effects model"".
I would like to know how to achieve the goal.
Any help is greatly appreciated !",2020-02-01 02:44:26
Effective image recognition,1,ewrpiy,https://www.reddit.com/r/MLQuestions/comments/ewrpiy/effective_image_recognition/,4,1580520361.0,"So I was wondering if it is possible to train an application to recognize specific images with a useful level of accuracy or is that too early if development of ML ?

I'm speaking as a beginner but wanted to know before i begin building something. 

if it IS possible, could you build it in python and what library would be useful ?

Thank you for your help",2020-02-01 06:56:01
Pre-trained VGG16 Model Overfitting on Stanford Cars dataset,7,ewdwa4,https://www.reddit.com/r/MLQuestions/comments/ewdwa4/pretrained_vgg16_model_overfitting_on_stanford/,9,1580453187.0,"I have been looking at trying to remove overfitting in my VGG16 model when fine-tuned on the Stanford Cars dataset. I am using the pre-trained VGG16 model and only changing the final layer to output 196 classes. I have noticed that the validation accuracy start to plato between 67 and 75 percent racy but the training keeps going up past 95%, then it platos. This occurs when I used different learning rates and give it enough time to converge.

[Train and Loss of the model training over 150 Epochs \(LR:1e-4\)](https://preview.redd.it/gqwfs2tauzd41.png?width=2012&format=png&auto=webp&s=be1c9e137e4bbeef1a72842952679d8b4241fe7c)

I then went to on add dropout near the end of the model. I created tests where I duplicates layer 2 and 5.The first test has both layers duplication, the second had just the second layer duplicated and the third had just the fifth layer duplicated

[Test1:Added 2 new dropouts layers\/with linear](https://preview.redd.it/ivnoa0tnuzd41.png?width=2064&format=png&auto=webp&s=6fac1781da20f20211df5ba042f9d3d815cb2b4c)

[Test2:Added dropout\/linear at classification\[2\]](https://preview.redd.it/nysvuvogvzd41.png?width=2072&format=png&auto=webp&s=f30b7d18a55a7e215bce607c561bd57d7a18574c)

[Test3:Added dropout\/linear at classification\[5\]](https://preview.redd.it/jxvp7augvzd41.png?width=2078&format=png&auto=webp&s=2f98eeca12e25620d69328a4969d8c9b3b406c5d)

[Code to add in the new layers for Test1. Test2 only has the \[2\] added where as Test3 has the \[5\] added. The passed in base is torchvision.models.vgg16\(pretrained=True\) from pytorch](https://preview.redd.it/cyjqu96hvzd41.png?width=834&format=png&auto=webp&s=a90631e6b316dccbe0d43101b18a94f73f203450)

I am still getting used to this but from my knowledge both the training and validation accuracy and loss should follow the same trend. Could anyone help with this or signpost me somewhere? Thanks",2020-01-31 12:16:27
Can someone explain in more laymen's term what is going on here with this bayesian optimization?,12,ew5xz1,https://www.reddit.com/r/MLQuestions/comments/ew5xz1/can_someone_explain_in_more_laymens_term_what_is/,2,1580422046.0,"    self.gpr.fit(x, y)
    
    def _upper_confidence_bound(x):
        x = x.reshape(1, -1)
        mu, sigma = self.gpr.predict(x, return_std=True)
        return mu - self.beta * sigma
    
    optimal_val = float('inf')
    optimal_x = None
    num_restarts = 50
    bounds = self._get_hp_bounds()
    x_seeds = self._random_state.uniform(bounds[:, 0], bounds[:, 1], size=(num_restarts, bounds.shape[0]))
    
    for x_try in x_seeds:
    
        result = scipy_optimize.minimize(_upper_confidence_bound, x0=x_try, bounds=bounds, method='L-BFGS-B')
    
        if result.fun[0] < optimal_val:
            optimal_val = result.fun[0]
            optimal_x = result.x

So far i see that we are basically fitting a GaussianProcessRegressor. Then we define a function that we are trying to minimize.

I'm not sure what x\_seeds is, is this just randomly chosen configurations?

We loop the the configurations and try to minimize this function for each one?

At the end i see we end up with an optimal configuration to test.

the self-beta attribute at the top is supposed to be how we balance exploration for exploitation. The larger the number, the more explorative. Can someone explain why that is",2020-01-31 03:37:26
Regression using Neural Networks- Help needed about some decisions,1,ewhdkz,https://www.reddit.com/r/MLQuestions/comments/ewhdkz/regression_using_neural_networks_help_needed/,3,1580467176.0,"So I have a project that involves neural networks and regression. I have multiple design variables and multiple target values. All are real numbers and the number of outputs are different from the number of the inputs (design var). As I am reading form Ian Goodfellow's book, my thought are to reshape all the data and put them in an array X for the inputs and Y for the outputs. Will that be a mistake?

Also, as a loss function I am going to use the cross-entropy function based on Gaussian distribution but would be better to use MDNs or another distribution?

I am really new to those stuff and I dont know how to continue. I'm pretty sure I know the basic understanding of everything however I cant find many information on NN and regression.

Any help would be welcome",2020-01-31 16:09:36
need help for my ml final work,0,ewfr31,https://www.reddit.com/r/MLQuestions/comments/ewfr31/need_help_for_my_ml_final_work/,2,1580460290.0,"So for my final work i have the following question:

Is a platformer a platformer for an AI?

the idea behind this is to apply transfer learning to an AI that learned Mario and make it play other 2D platformers like Sonic with as minimal extra training possible.

I plan to use a curiosity driven cnn as it seems rather suited for this task.

&#x200B;

One of my most pressing issues is that my final work has no unique special approach that hasnt been tried or something like that , theres not enough ""me""...

&#x200B;

so does anyone have suggestions of things i can add to this question? i know i shouldve researched better and all that but honestly ml is rather complicated (not to mention first semester was heavy af with 4 extra projects on top of my courses so i barely did stuff for my final work)

&#x200B;

ps : tutorials on how to decide on the neural network size and layers would be awesome cuz im pretty much going in blind (we' ve literally had 1 small semester on what is ai? some basic supervised and unsupervised search algorithems and a very basic dqn)

&#x200B;

ps2: any experience i have with ai and ml comes strictly from copy pasting, changing some variables and guess what it does (i dont have any clue wtf im doing)",2020-01-31 14:14:50
Computer Vision or Natural Language Processing? Which has better career opportunities for a freelancer?,2,ewbpip,https://www.reddit.com/r/MLQuestions/comments/ewbpip/computer_vision_or_natural_language_processing/,4,1580444940.0,,2020-01-31 09:59:00
How to determine a pass/fail criteria and then categorize new tests as pass/fail?,1,ewebef,https://www.reddit.com/r/MLQuestions/comments/ewebef/how_to_determine_a_passfail_criteria_and_then/,1,1580454760.0,"I want to use ML to determine a pass/fail criteria and then categorize new tests as pass/fail. For my test I have several text fields and several data fields. The text fields are categorical data related to the test configuration. The data fields are stats that get collected during the test. 

I want to be able to determine, given a particular configuration (multiple text and number fields), what is a normal range of values for the stats. 

Then, given a new test with same ( or similar ) configuration, did it fall within an acceptable range. 

So I think this would be unsupervised multi variate regression model to determine what the pass/fail criteria is? and then a categorization algorithm for determining pass/fail on new tests?   


I am fairly new to ML. I have taken probability and statistics in college, as well as several other math and programming courses but nothing ML specific. Some guidance would be greatly appreciated. Thank You.",2020-01-31 12:42:40
Unsupervised Machine learning - Text fields?,2,ewa3g8,https://www.reddit.com/r/MLQuestions/comments/ewa3g8/unsupervised_machine_learning_text_fields/,4,1580438516.0,"Hello everyone,

&#x200B;

let's me start by saying that i am NEW to ML i.e i understand the basics concepts but i have never actually programmed something. Here is my scenario:

&#x200B;

I have point of sales \[POS\] in the world (i.e \~1000). At each point of sales, i send every week someone to evaluate that POS without the manager of the POS knowing.

&#x200B;

Each person going to the POS to evaluate it, provides a report after each visit. In the report, i have free text fields where they describe the issues they have witnessed so for example:

&#x200B;

POS1 - USA - Issue #1 : The floor was dirty  
POS1 - USA - Issue #2 : The manager didn't not greet me when i entered the shop  
POS1 - USA - Issue #3 : The door of the fridge was open for more than 2 minutes which triggered the alarm but nobody responded immediately

&#x200B;

POS2 - GBR- Issue #1 : The employee didn't wash his hands after emptying the garbage  
POS2 - GBR - Issue #2 : The coffee was too hot - Bad temperature set at the machine  
POS2 - GBR - Issue #3 : The insurance certificate was not displayed on the door  
POS2 - GBR - Issue #4 : Fridge alarm bell on

&#x200B;

POS3 - GBR- Issue #1 : The employee didn't wash his hands after emptying the garbage  
POS3 - GBR - Issue #2 : Missing insurance certificate  
POS3 - GBR - Issue #4 : Alarm triggered

&#x200B;

So i want to identify patterns or trends so for example in this simple data set, i can see that i have two:

&#x200B;

1. Globally (i.e around the world) i have a an issue with the Alarm bell of the fridge
2. In GBR only, i have a recurring issue with the insurance certificate not being displayed

&#x200B;

How can ML help here? I understood that it has to be Unsupervised ML : clustering? classification? How can i get a meaningful and actionable output like the one i can derive when looking at the data?

Which visual representation could help me?

&#x200B;

Any sample python to run on this small data set would be very useful for to understand the mechanics of ML

&#x200B;

&#x200B;

&#x200B;

THANK YOU!!",2020-01-31 08:11:56
Your experience in data labeling,0,ew55bj,https://www.reddit.com/r/MLQuestions/comments/ew55bj/your_experience_in_data_labeling/,4,1580418347.0,"I am building a crowdsourcing platform for data labeling. 

Please share your opinion with me and you will help significantly!

[https://forms.gle/gkCeBfbTE7uCoQwC6](https://forms.gle/gkCeBfbTE7uCoQwC6)

\+1 Karma to everyone who finish or share",2020-01-31 02:35:47
Custom MNIST classifier seems to take way longer to train than with Keras,7,evxxwr,https://www.reddit.com/r/MLQuestions/comments/evxxwr/custom_mnist_classifier_seems_to_take_way_longer/,3,1580379438.0,"I'm trying to learn lower level tensorflow, so I tried to write a MNIST classifier in tensorflow 2.0 based off a 1.x sentdex tutorial that does not use keras.

[https://drive.google.com/open?id=1Gr9Ya9DbeQcV-jVURsgxhWjGL0B0A2xM](https://drive.google.com/open?id=1Gr9Ya9DbeQcV-jVURsgxhWjGL0B0A2xM)

The model updates the weights using GradientTape and gradient descent.

&#x200B;

It took me 8 hours to run through 25 epochs, but when I try google's premade MNIST colab using Keras, the model seems to burn through an epoch every 3 seconds. Enabling colab GPU seems to make things 10x slower for my model.

Am I doing something wrong? How is keras training so much faster than stock tensorflow?

&#x200B;

EDIT: model definition and training loop in comment

EDIT: I have yet to try tf.function, but I have gotten it to work *exponentially* faster by giving it 10,000 images per gradient update instead of doing gradient descent on image. Instead of a 60,000 length for loop per epoch, running a 6 length for loop with x\_t containing a 10,000 batch size makes it pop out epochs once every few seconds.

Thanks for any suggestions",2020-01-30 15:47:18
Is BatchNorm useful for sparse binary Input?,1,ew2fys,https://www.reddit.com/r/MLQuestions/comments/ew2fys/is_batchnorm_useful_for_sparse_binary_input/,1,1580402778.0,"Hi,

&#x200B;

I have a question regarding the usefulness of Batchnorm layers, when my inputs to the net are vectors of length 1024 with only 1 or zeros. They are also quite sparse so maybe 90% zeros per vector.  


It seem to me that the model has a problem to adequately map the distribution of the activation. And in .eval() mode my loss just goes through the roof.",2020-01-30 22:16:18
ML Workshops and Conferences,5,evu6di,https://www.reddit.com/r/MLQuestions/comments/evu6di/ml_workshops_and_conferences/,2,1580364248.0,How do you guys keep track of ML conferences and workshops going on over the world?,2020-01-30 11:34:08
Selecting appropriate feature granularity,1,evzyz3,https://www.reddit.com/r/MLQuestions/comments/evzyz3/selecting_appropriate_feature_granularity/,0,1580388567.0,"Let's say I'm trying to build a model to predict the rating (1-10) of a picture containing some animals. I have reason to believe that the number of certain types of animals is important. My features are derived from metadata about each animal  in the picture, e.g. its color, species, size, etc.

How should I approach determining the appropriate feature granularity? For example, I could have features like:

* number of cats
* number of dogs
* number of white animals
* number of brown animals

where a single animal will be represented in multiple features, or features like:

* number of large white cats
* number of small white dogs
* number of small brown cats
* number of medium brown dogs etc....

where a single animal will only be represented in one feature. Or, I suppose I could combine these feature sets and perform some sort of regularization.

Any suggestions or recommended topics to read up on would be greatly appreciated. Thanks!",2020-01-30 18:19:27
How to start,3,evpybe,/r/ArtificialInteligence/comments/evo1n0/how_to_start/,2,1580347603.0,,2020-01-30 06:56:43
Gender classification from username?,1,evte2x,https://www.reddit.com/r/MLQuestions/comments/evte2x/gender_classification_from_username/,3,1580361187.0,"Hi, I'm trying to use gender as a variable in my research and only have usernames, not real names. Real names have had a good bit of research done with regards to gender classification, but I haven't found research done regarding usernames and gender classification. Am I out of luck or is there a method you would suggest I use?",2020-01-30 10:43:07
How to squash regression output when feature isn't present?,1,evsqat,https://www.reddit.com/r/MLQuestions/comments/evsqat/how_to_squash_regression_output_when_feature_isnt/,0,1580358700.0,"I have two CNN heads of which one outputs 3 linear regression values, and the other outputs 3 softmax values. I want to build a loss function that looks like :

loss = C_n * MSE_n(y_pred_n, y_true_n) and where and n = 1..3.

The idea is I want to use each of the n softwax outputs as weights on each of the n MSE terms. Basically, I want to capture the scenario where the feature isn't present at all, and therefore the regression isn't meaningful.

Any thoughts on how I can implement that in keras? I know you can concatenate outputs as Model(outputs=[X1, X2]) but its not clear to me how how to index the resulting y_pred terms in the loss function (like, do I get two ""sets"" of y_preds, from each of X1 and X2?)


Or if you have any thoughts on just a plain better way to do this, that would be helpful too!",2020-01-30 10:01:40
Fastest supervised learning algorithms for speed and accuracy over a large binary classified dataset - sklearn,2,evoy46,https://www.reddit.com/r/MLQuestions/comments/evoy46/fastest_supervised_learning_algorithms_for_speed/,1,1580343261.0,"I have a binary classified dataset with around 150,000 entries. I'm doing text classification so it would be converted to a bag of words matrix. 

System resources are an issue for me. I have 16GB RAM as well as a good GPU, but I don't think sklearn makes use of the GPU. Anyways Which algorithms perform the best in terms if accuracy and speed.",2020-01-30 05:44:21
How things work in company?,7,evkm7p,https://www.reddit.com/r/MLQuestions/comments/evkm7p/how_things_work_in_company/,12,1580318318.0,"Hello,
 I am starting to learn Machine Leaning. I have some experience with ML in Jupyter notebook, like creating models to predict kWh or diabetes. But all this work was made on a single PC and I can't imagine how things works real development system.

I am curious how machine learning engineers works in company/on large-scale projects where are multiple engineers needed. How they share, co-work on a single problem (In a single jupyter notebook?).

What tools I need to check before applying into ML job? Like what tools are used in real workflows (SK-learning, python, etc.).

Next I want to pick up some experience in TensorFlow is it good next step in ML learning?

Thanks for help!",2020-01-29 22:48:38
Pattern recognition on categorical sequences?,5,evk7p5,https://www.reddit.com/r/MLQuestions/comments/evk7p5/pattern_recognition_on_categorical_sequences/,4,1580315324.0,"Say I have a dataset that contains sequences of categorical labels. Can anyone recommend some algorithms or papers that can detect patterns within the sequences? For instance, say in a dataset example we have

AB - O - BA - O - O - O - CD (where AB, BA and CD are categorical labels of the sequence).

as a sequence, left to right. I'm interested in generating insight from said sequences such as,

a.) Are there some generalized specific order of categories (assuming O to be a null category) in the sequences present in the dataset? That is, does this dataset tend to follow a specific patern?

b.) Does BA necessarily or generally follow after AB (in general) or other way around?  and so on for different combinations of the categorical element in the sequences.

c.) Are there some groups or clusters of particular smaler sequences, and what are those patterns?

&#x200B;

Idk if this is correct but as a starting point, I reckon I can feed these sequences into an RNN of some sort (GRUs, LSTM, or bi-LSTM + CRF). But after that, I'm not sure what I can do to discern these patterns. I've also thought of using hierarchical clustering analysis on the dataset as well to determine the general hierarchy of sequences (if that is possible).  But ultimately, I'm more interested to see what sorts of patterns are present in my sequential dataset.

PS. Am I correct in understanding that this sort of sequential pattern recognition approach is also used in mapping genomes?  


EDIT: I'm not sure also if clustering with HMMs would work here.",2020-01-29 21:58:44
What types of real world problems are Probability-based algorithms used for?,1,evn466,https://www.reddit.com/r/MLQuestions/comments/evn466/what_types_of_real_world_problems_are/,3,1580334616.0,,2020-01-30 03:20:16
"Query regarding feature engineering, I want to use a feature which is made from 2 feature non-linearly, will it be feasible? Let's say F1 and F2 are 2 features that I am using already. And I want to generate a third feature F3 = F2/F1. Does, it causes redundancy of feature?",2,evj05v,https://www.reddit.com/r/MLQuestions/comments/evj05v/query_regarding_feature_engineering_i_want_to_use/,3,1580307590.0,"I was working on Research paper for Application of Machine Learning in Nuclear Physics.

So the problem statement was to find the particle emitted from a source, the source emits 2 particles- Neutron and Gamma. Hence, it's a binary classification.

In Layman's terms- the particle generates a pulse and currently the Phd student with whom I am working have told that using tail and total area is feasible. {Tail area - From Maxima of a pulse to final zero of a pulse and Total area - from 1st zero of a pulse to final zero. For sake of representation you can take pulse to be [like this](https://cams.llnl.gov/content/assets/images/competencies/growing-season-graph.png), yeah bit more gaussiany}. Now on a general pattern the ratio of tail/total area of a pulse is higher for neutron that gamma, as mass of neutron is more hence the graph falls slowly. As the graph falls slowly so the area under the graph is a bit more.

Coming to Neural Network, I wanted to have a 3rd feature also along with total area and tail area which will be ratio. I have to keep the total area and tail area as feature as suggested by supervisor and Phd. I wanted to keep the third feature so to emphasis heavily that higher ratio kinda means neutron and lower ratio means gamma. But obviously don't want to overfit it.",2020-01-29 19:49:50
Gaussian process with null values?,2,evfnh0,https://www.reddit.com/r/MLQuestions/comments/evfnh0/gaussian_process_with_null_values/,9,1580290734.0,"I am doing bayesian hyper parameter optimization using the sklearn GPR

https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html

My parameter space is conditional. Is there a way to set parameters as null as to have them not affect the distribution when they are absent from a configuration?",2020-01-29 15:08:54
How to calculate mfcc volume coefficient?,2,evbueo,https://www.reddit.com/r/MLQuestions/comments/evbueo/how_to_calculate_mfcc_volume_coefficient/,0,1580275300.0,"I was trying to recreate this paper called Audio to Body Dynamics ( [https://arviolin.github.io/AudioBodyDynamics/ARmusic\_paper\_final.pdf](https://arviolin.github.io/AudioBodyDynamics/ARmusic_paper_final.pdf) ) where they describe the input to their model being audio features represented as MFCC coefficients and their derivatives. They state: 

>The final audio feature size is 28-D which includes the 13-D feature vector, their temporal derivative, and log mean energy for volume.

But I am confused about how I would calculate the log mean energy for an MFCC array. I understand using a library like python\_speech\_features to calculate MFCC but am unsure how to actually calculate the log mean energy they describe in their paper. Any help is appreciated!",2020-01-29 10:51:40
[Decision trees] Bias-variance trade-off with pruning a decision tree?,4,ev51lv,https://www.reddit.com/r/MLQuestions/comments/ev51lv/decision_trees_biasvariance_tradeoff_with_pruning/,8,1580243768.0,"I understand that pruning a decision tree will lead to a reduction in variance and also a reduction of the tree complexity, but how is the bias affected?
I'm guessing the bias will increase as the variance decreases, but is there any way to think about this intuitively? 
I tried googling this but couldn't find any concrete information about this particular topic.


Thanks in advance!",2020-01-29 02:06:08
Neural Network predict FFT,3,ev3pgp,https://www.reddit.com/r/MLQuestions/comments/ev3pgp/neural_network_predict_fft/,14,1580234915.0,"I would like suggestions on a better way to solve this problem. I would especially like to know how to create a single neural network to solve this problem instead of one model per FFT value.

I would appreciate any network design ideas to investigate.

I made a posting before to make a surrogate model for a complex simulator. ( [https://www.reddit.com/r/MLQuestions/comments/e1dcdx/how\_to\_model\_a\_time\_series\_not\_forecasting/](https://www.reddit.com/r/MLQuestions/comments/e1dcdx/how_to_model_a_time_series_not_forecasting/) )

One of the ideas suggested was to predict the FFT of the time series instead of predicting the time series. 

I have managed to get something to work okay using

model = xg.XGBRegressor(objective=""reg:squarederror"", n\_estimators=100, max\_depth=50)  
model = sklearn.multioutput.MultiOutputRegressor(model, n\_jobs=-1)

The problem is that this is slow since it creates one model for each FFT target (about 1000-1500 values in most cases) and the results are okay but not great. 

I tried to make a simple deep fully connected network with 3 layers and about 500 neurons per layer with reLU activation and the results were much worse.

Thanks",2020-01-28 23:38:35
Automatic Relevance Determination help,1,ev8mmk,https://www.reddit.com/r/MLQuestions/comments/ev8mmk/automatic_relevance_determination_help/,0,1580261903.0,"Hi there,

I’m pretty new to Gaussian Processes, but one of the things that I’m really interested in looking at for my own research is Automatic Relevance Determination (ARD). 

I can see the theoretical explanation in Rasmussen and the scikit-learn implementation, however it’s still not clear how I might translate from the sklearn implementation to that found on page 294 of the Bergstra & Bengio paper on random search (http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf). To achieve the boxplots shown they mention varying the data used to fit the independent length scales, which is easy enough to understand, however they also mention randomly initializing the length scale parameter l, which it doesn’t look like there’s an interface to do in scikit-learn. Am I missing something? Is scikit-learn’s implementation not exactly what they use in this paper? Am I misunderstanding what scikit-learn’s exposed variables represent? Really appreciate any guidance you guys can provide.",2020-01-29 07:08:23
Have task to create classificator for classification road sign images,0,evap46,https://www.reddit.com/r/MLQuestions/comments/evap46/have_task_to_create_classificator_for/,0,1580270592.0,"Have any ideas from where to create. Would be nice to create in matlab or tensorflow.

Guess first step is to get data and make it ready for model, but what model shoud i use ? Would like to do it with neural networks. Any help is welcome",2020-01-29 09:33:12
stupid quistion,2,ev1sn0,https://www.reddit.com/r/MLQuestions/comments/ev1sn0/stupid_quistion/,6,1580221718.0,What book or class can you recommend for the pure beginners of  machine learning,2020-01-28 19:58:38
How necessary is feature scaling/mean normalization in KNN/NNS?,5,euwi32,https://www.reddit.com/r/MLQuestions/comments/euwi32/how_necessary_is_feature_scalingmean/,4,1580196241.0,"Newcomer to ML algorithms, was thinking about a model I am building.

If I have two features, one of which is scaled 0-100 and the other scaled 0-1, but both similarly representing a percentage value and neither having any data points outside those bounds, will the lack of scaling/normalization interfere with the performance of the model?

For example, a point at [0.50, 50.0] might be closer in relative terms (if the model were smart enough to understand scale) to a point at [0.50, 55.0], but may instead return [0.60, 50.0] as it finds this to be only 0.10 distance compared to a distance of 5.0.

Keep in mind I'm using AWS SageMaker/scikit-learn implementations of Nearest Neighbor Search. I was thinking maybe they handle for this sort of thing by understanding the bounds of the data, but that may be wishful thinking.",2020-01-28 12:54:01
How to compare learning and non-learning method with cross-validation with a correlation metric?,4,eunkn5,https://www.reddit.com/r/MLQuestions/comments/eunkn5/how_to_compare_learning_and_nonlearning_method/,0,1580158800.0,"I have a learning method for a task that is working pretty well. I want to compare it to a non-learning based method.  
I can't just decide on a test set because it would seems very fishy (Would look like engineered to make my model better).
So a cross-validation seems to be the way to go. Problem is : my metric to compare the two methods to the ground truthes has to be the Spearman Rank Order Correlation (the problem would be the same with a linear correlation).  

The method I'm evaluating against has no need for split. So should I :  
Compare average SROCC across splits with global SROCC for the non learning one? (Not really comparing the same thing I think?)  

Average the SROCC for the non-learning method as well (But does it makes sense to use the folds for this method ?)  

Compute the SROCC for all data with the prediction when they are in the test set for the learning method (but then I'm using different models, seems weird)  

What would you do ? Thanks",2020-01-28 02:30:00
Best way to leverage 10K binary survey responses,5,euniui,https://www.reddit.com/r/MLQuestions/comments/euniui/best_way_to_leverage_10k_binary_survey_responses/,3,1580158503.0,"I've survey from users where they saw some content and were asked if it was a great match or not. I'm using a tf.estimator.LinearClassifier with Vizier for feature selection and hyperparameter tuning. (I've about 50 features). The responses are not really imbalanced, about 2/3 responses were positive and 1/3 negative.

My current AUC is about 0.65 which leaves scope for improvement.

I'm fairly new to this, am I missing something, what else could I try? (Given the only constraint is the dataset size, I can get some more but it will always be in the same order of magnitude)

Thanks!",2020-01-28 02:25:03
hi this might be a stupid question but how can i make a text neural network,1,eup8la,https://www.reddit.com/r/MLQuestions/comments/eup8la/hi_this_might_be_a_stupid_question_but_how_can_i/,11,1580167116.0,i want to make a text neural network (basicly i want it to be able to recieve text as input and to output text) i found that there are things like character based lstms but i havent figured out how to make one can someone suggest a solution that does not require a lot of programing and can be preferably be done in something like visual studio on my machine,2020-01-28 04:48:36
Using machine learning to predict a benchmark given past data ingestion times?,3,euijxn,https://www.reddit.com/r/MLQuestions/comments/euijxn/using_machine_learning_to_predict_a_benchmark/,2,1580126876.0,"I have a series of past start and end times for when my team was assigned an ingestion task along with when they actually completed it in Excel.

My job is to determine an appropriate benchmark for how long an ingestion task should take based on this
past data. 

Would this be possible to do via machine learning? What should I use and how exactly can I do it?

Also, if there's a better approach, then I completely understand and I'd appreciate knowing what the ideal solution to this is.",2020-01-27 17:37:56
Is this learning curve good?,1,eumpm1,https://www.reddit.com/r/MLQuestions/comments/eumpm1/is_this_learning_curve_good/,6,1580153177.0,"Hi, (not sure if this is the place to post) I've been getting to grips with deep learning using Keras (in R), while applying it to some work projects. However, I'm a bit uncertain about the learning curves my model is spitting out. This link (https://imgur.com/gallery/qLVoYlJ) is an example. While the overall trend of the curve seems to be improving, at times the validation loss and acc are worse than the train loss and acc. Is this normal? The curve tells me that both val and train are converging to the same value, but I am a bit concerned about the fluctuations in the validation data. Should I be concerned? Thanks",2020-01-28 00:56:17
